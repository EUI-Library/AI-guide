---
title: Writing calls, grants, abstracts, and intelligent automations 
format: html
lang: en
---

::: {.callout-note icon="false" title="<span style='font-size:1.2em; color: #133869ff;'>Content</span>"}
##### Prompt chaining for titles and abstracts (*title generation, abstract draft, stylistic revision*)
##### Script/API for bibliographic metadata extraction and normalisation, format conversion, summaries
##### Proactive workflows: reminders, dynamic checklists and periodic reports on new papers
##### Quick quality metrics (*clarity, methodological rigour, appeal*)
:::

## Introduction  

In the context of growing pressure for continuous and measurable scientific productivity, accompanied by the proliferation of competitive calls for proposals and increasingly tight deadlines, the strategic integration of AI-based tools represents a concrete opportunity to <u>streamline</u> and <u>enhance</u> editorial practices in academic research.   
In this scenario, where the needs for *clarity of expression, thematic relevance and persuasiveness* converge, AI can act as a lever to combine <u>operational efficiency</u> and <u>argumentative quality</u>.  

The conscious use of intelligent systems in Academic writing flows ‚Äì from design to revision ‚Äì makes it possible to **lighten the executive load** associated with the most repetitive phases of intellectual work, allowing researchers to focus their attention on activities with high cognitive value, such as **critical analysis**, **argumentation** and **theoretical construction**.

üëâüèª *This results in greater reflectiveness in decision-making processes and better communication in the texts produced*.

In particular, the writing of **calls for papers** (project proposals for competitive grants and scientific abstracts) can be significantly facilitated by **intelligent automation**, capable of <u>supporting the entire text production cycle</u> from *title generation to logical structuring, from stylisation to quality control.*  

**Five priority areas** can be identified in which GAI finds effective application in the Social Sciences and Humanities (SSH), promoting not only the **acceleration of processes**, but also their **conceptual and epistemic refinement**:  

1. *Prompt chaining for titles and abstracts*  
2. *Scripts/APIs for bibliographic metadata and automatic summaries* 
3. *Proactive workflows and automated reminders*  
4. *Rapid text quality metrics*  
5. *Cognitive offloading to optimise mental resource management*  

<div style="text-align: center;">
![Scheme of text production verification areas](images/npl2.png){width=75%}
<p style="text-align: center; font-size: 1.2em; color:black; font-style: italic; margin-top: 0.3em; color: black;">
<p>
</div>

## 1. Prompt chaining for titles and abstracts

In the process of generating titles and abstracts, one of the most effective applications of GAI is **prompt chaining**, i.e. the <u>structured concatenation of text commands</u>.

Through the use of **progressive sequences of controlled prompts**, the researcher can guide the linguistic model through distinct but interconnected phases, which *simulate the iterative reasoning* typical of academic writing.

a. *We start with a **simple thematic statement** to generate a list of titles consistent with the disciplinary domain and style required by the editorial context*.  

b. *Next, the selected titles are **developed into draft abstracts**, structured according to the specific rhetorical conventions of the field (objectives, method, expected results, implications)*.  

c. *Finally, again using targeted prompts, the text is **stylistically revised** and **linguistically optimised** to improve readability, impact and adherence to formal requirements*.

::: {.callout-tip}
## For example, a typical flow might look like this:
- Prompt 1: "*Generate 5 Academic titles for a project on the relationship between AI and political discourse analysis*."  
- Prompt 2: "*Write a draft abstract for title X, using a formal style and no more than 150 words*."  
- Prompt 3: "*Reformulate the text with a more persuasive tone, maintaining the academic register*."  
:::

In the context of SSH, *prompt chaining* is particularly useful for <u>exploring different interpretative angles</u>, <u>verifying consistency between the formulation of the problem and the proposed approach</u>, and <u>refining the tone according to the target audience</u> (Scientific committee, Funder, Journal).

üëâüèª [To reducing the time needed to produce a satisfactory version, this methodology encourages **greater reflection on the editorial process**, transforming the AI tool into an **intellectually stimulating interlocutor** and not just a mere automated assistant.]{.mark}

## 2. Scripts and APIs for metadata and formats

Within the Academic writing workflow, certain tasks such as **managing bibliographic metadata**, **converting document formats** and **generating automatic summaries** are operationally intensive yet cognitively low-impact.

In this context, the integration of **custom scripts** and [APIs (Application Programming Interfaces)](https://www.ibm.com/think/topics/api) enables the automation of <u>repetitive processes</u>, facilitating standardisation and reducing the risk of errors.

API-based tools such as [Zotero](https://www.zotero.org/), [CrossRef](https://www.crossref.org/), [Semantic Scholar](https://www.semanticscholar.org/) or [OpenAI](https://openai.com/it-IT/) can be queried to **extract**, **normalise**, and **reformat** bibliographic metadata according to *specific citation styles* (APA, MLA, Chicago, etc.), ensuring coherence and accuracy even during the final revision stages.

Similarly, **Python scripts** or **plug-ins for editorial environments** (such as Word or [LaTeX](https://it.overleaf.com/)) allow for <u>rapid document conversion</u> between formats (e.g., *from Word to PDF with embedded metadata or from LaTeX to XML for online submission*).

> See [Python Scripts For Web Scraping Metadata From Descriptions About The Datasets Of The International Scenario Of Research Data Repositories](https://www.scielo.br/j/eb/a/Rp4XmcdL6Nntks4ZWtNDWQH/?lang=en)  
> See [pybliometrics: Scriptable bibliometrics using a Python interface to Scopus](https://www.sciencedirect.com/science/article/pii/S2352711019300573)    
> See [The Modern Methods of Data Analysis in Social Research: Python Programming Language and its Pandas Library as an Example- a Theoretic Study](https://www.ajol.info/index.php/sej/article/view/274626)  
 
In particular, the <u>combined use of APIs and scripts</u> allows you to automate:

- The **generation of complete bibliographic references** (in APA, MLA, Chicago, etc.);
- The **retrieval of scientific article abstracts**
- The **conversion of files** (PDF ‚Üí text, BibTeX ‚Üí JSON);
- The **creation of summaries** of the state of the art.
- The generation of **automatic summaries** of scientific articles or regulatory acts, to be used as study material, as a basis for developing original abstracts, or as support for the literature analysis phase, with significant savings in time and cognitive load.

[In the SSH, where researchers often work with heterogeneous sources and multi-methodological approaches, these automations facilitate more robust information management, making it easier to organise sources, track references, and prepare materials ready for submission.]{.mark}


## 3. Proactive workflows and intelligent time management

In today's Academic environment, characterized by increasing organizational complexity and a multitude of simultaneous tasks (*teaching, research, dissemination, planning*), the ability to effectively manage time and priorities is a strategic skill.

üëâüèª  In this scenario, AI offers concrete tools for building **proactive workflows**, i.e. *organisational processes in which technologies*, often based on AI automation, *are able to anticipate user needs and intervene before problems or explicit needs arise*.

::: {.callout-tip}
## These systems not only optimize individual organization, but also build an information ecosystem that reduces the impact of the executive load and stimulates continuous reflection on scientific priorities.
:::

üëâüèª[Through the integration of *advanced language models*, *task management systems*, and *personal productivity tools*, it is possible to design **semi-automated workflows** that do not merely react to deadlines but help to anticipate them and distribute them in a sustainable manner.]{.mark}

The adoption of **prompt scheduling systems**, designed to proactively generate contextualised reminders and preliminary drafts in relation to Academic deadlines (e.g. *calls for papers, project submissions or article reviews*), is an effective strategy for mitigating procrastination and supporting the continuity and regularity of scientific output.  

In addition, some AI platforms allow the **integration of smart calendars** which, in addition to simply recording events, provide personalised suggestions on the most suitable time slots for activities such as *writing*, *data analysis or reading*, taking into account both the estimated cognitive load and individual productivity patterns.  

Integrated with **time tracking tools**, these systems promote more conscious *management of time resources*, facilitating an optimal balance between *high cognitive value activities* (writing, design, reflection) and *repetitive operational tasks* (formatting, data entry, uploading to platforms).

Finally, proactive workflows can be used to **schedule periodic text reviews** and incorporate **automatic feedback** on consistency, readability, and style.  
An incremental approach, distributed in short, planned sessions, helps mitigate the mental overload typical of production concentrated around deadlines, promoting a measurable improvement in the overall quality of Academic output.

## 4. Rapid metrics for text quality  

In the context of the SSH, where text production is not only a means of communication but also an  expression of theoretical argumentation, critical analysis and conceptual density, **linguistic and rhetorical quality control** takes on strategic importance.  

Unlike disciplinary fields characterised by more standardised textual structures, the SSH field is distinguished by <u>stylistic variety</u>, <u>semantic complexity</u> and a plurality of <u>rhetorical registers</u>.

In this context, the adoption of **automated text quality metrics**, based on linguistic models or Natural Language Processing (NLP) tools, allows for the insertion of an intermediate phase of analysis and revision into the writing process, which is useful for identifying latent critical issues and opportunities for improvement.    

::: {.callout-warning icon=false}
## These metrics have no prescriptive or evaluative value in the strict sense, but can act as ‚Äúreflective aids‚Äù, increasing stylistic awareness and promoting greater adherence of the text to the expectations of the academic audience or evaluation committee.
:::

**Text quality assessment metrics** can be divided into <u>four main areas</u>:

**a.** *Clarity and readability*  
These include parameters such as average sentence length, frequency of passive voice, density of subordinate clauses, and readability indices (e.g. [Flesch-Kincaid](https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/) or [Gunning Fog Index](https://readable.com/readability/gunning-fog-index/)). These measures are particularly relevant when the text is written in a language other than the author's mother tongue.  

**b.** *Textual consistency and cohesion*  
These relate to the recurrence and distribution of key concepts, semantic consistency between different sections, and the presence and variety of logical and discursive connectives (*furthermore*, *in contrast*, *consequently*), which are essential indicators for ensuring a solid flow of argumentation.

**c.** *Lexical richness and terminological density*  
These assess lexical diversity, the balance between specialist terminology and the accessibility of the text, and the frequency of rare terms. The latter aspect is useful for identifying phenomena of hyper-specialisation or, conversely, excessive generality.

**d.** *Tone, register and epistemic markers*  
These consider the appropriateness of the academic tone, the use of attenuating formulas ("*it is possible to hypothesise that*...""), intensifiers (‚Äú*clearly*‚Äù, "*without doubt*") and implicit evaluations, elements that are of significant argumentative relevance in the social sciences and humanities.

::: {.callout-warning icon="false"}
## Some digital tools, including advanced language models, can provide concise but detailed assessments based on these criteria, operating both in real time and on demand. Among other things, these tools allow you to compare different versions of the same text or evaluate multiple abstracts, making it easier to choose the most suitable wording for a specific call.
:::

#### <u>Examples of tools for rapid text quality analysis</u> 

- [Hemingway Editor](https://hemingwayapp.com/)  
Measures readability, flags complex or passive sentences, and suggests stylistic simplifications. It is particularly useful for *clarifying argumentative passages* and *introductory sections*.  

- [Writefull for Overleaf](https://www.writefull.com/writefull-for-overleaf)  
AI-based plugin that analyses scientific texts, providing feedback on academic vocabulary, correct use of prepositions and sentence structure. It is a great support for those who *write in English as a non-native language*.   

- **GPT-based Quality Assessment** (*GPT-based assessment through targeted prompts*)  
Through calibrated instructions, models such as ChatGPT or Claude can return:  
‚Ä¢ *an analysis of tone and rhetorical effectiveness*  
‚Ä¢ *an assessment of logical and argumentative coherence*  
‚Ä¢ *a summary score based on predefined criteria* (clarity, relevance, impact)   

- [TextStat](https://textstat.org/) or [Linguakit](https://citius.usc.es/transferencia/software/linguakit)   
They are open-source NLP tools and provide quantitative analyses relating to:  
‚Ä¢ *average sentence length*  
‚Ä¢ *frequency and distribution of keywords*  
‚Ä¢ *terminological variety*  
‚Ä¢ *internal cohesion and coherence of the text*    

- [LanguageTool](https://languagetool.org/dev)  
Multilingual grammar and style checker that detects spelling, grammar and syntax errors, flags complex or overly long sentences, repetitions and excessive use of the passive voice. Useful for *improving the clarity and readability* of Academic and popular texts, with add-ons available for browsers, Word, Google Docs and various text editors.

::: {.callout-note icon="false"}
## In the field of SSH, where textual quality is an integral part of scientific authority and where argumentative rhetoric carries decisive weight, <u>these metrics represent an opportunity to systematise formal revision</u> without flattening stylistic originality.They can be adopted not only for individual production, but also in collaborative contexts, serving as a neutral interface for stylistic negotiation and the construction of a shared voice within research groups or collective editorial teams.
:::


## 5. Cognitive offloading and selective attention

In the Academic production cycle of the SSH, traditionally characterised by a high incidence of <u>iterative activities</u>, such as *annotation, source verification, syntactic editing and terminological standardisation*, **cognitive offloading** to GAI tools represents a targeted strategy for reallocating attentional resources.   

Delegating low-epistemic operations to automated systems not only preserves cognitive load, but also allows researchers to focus their attention on <u>conceptually dense phases</u>: *defining research questions, constructing theoretical frameworks*, and *validating arguments*.

Among the most significant uses of GAI in SSH are:

- **Controlled semantic reformulation**, used to test the conceptual soundness of a paragraph by subjecting it to lexical variations that do not alter its propositional content.  

- **Automatic pre-annotation of qualitative texts** (e.g. *interviews, historical documents, literary sources*), aimed at facilitating manual coding according to specific theoretical models, such as [Grounded Theory](https://journals.sagepub.com/doi/10.1177/2050312118822927) or [Frame Analysis](https://scholar.ufs.ac.za/items/b0653889-5985-4981-b442-9c1dfa53925d).  

- **Selective verification of intertextual consistency**, using models capable of mapping the logical connection between text sections (e.g., *between abstracts and conclusions*, or *between hypotheses and data*).  

- **Performing meta-editorial tasks**, including checking readability, converting to standard editorial formats (APA, MLA) and analysing syntactic dependencies to identify opaque constructions.  

üëâ [In such applications, AI acts as an **attentional amplifier**: it does not make interpretative decisions, but creates the conditions for a more targeted selection of cognitively salient stimuli.]{.mark}  

This approach embodies the logic of <u>selective attention scaffolding</u>, in which the algorithm provides a neutral, interference-free context, encouraging the emergence of critical thinking in a clearer form.  

Evidence from learning sciences and human‚ÄìAI interaction studies indicates that the ability to orchestrate distributed cognitive environments, integrating artificial agents, digital resources and human skills, is a qualifying indicator of **advanced epistemological literacy**.  

::: {.callout-note icon="false"}
## Strategic allocation of structural operations to AI not only increases productivity but also strengthens the quality of conceptual processing and metacognitive awareness throughout the entire research cycle.
:::

