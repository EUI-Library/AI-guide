% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}
\usepackage{xcolor}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother

\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi

% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}



\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={AI training},
  pdfauthor={Daniela Marzano},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{AI training}
\author{Daniela Marzano}
\date{2025-12-16}
\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\bookmarksetup{startatroot}

\chapter{Introduction}\label{introduction}

This is a book created from markdown and executable code.

See Knuth (1984) for additional discussion of literate programming.

\part{Part 1: Fundamentals of Generative AI e Tools}

\chapter{The Evolution of Generative Artificial Intelligence and its
Application in Academic
Research}\label{the-evolution-of-generative-artificial-intelligence-and-its-application-in-academic-research}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Content}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\begin{itemize}
\tightlist
\item
  Introduction to Generative Artificial Intelligence
\item
  Current applications of GAI in the research
\item
  Towards a new scientific literacy
\end{itemize}

\end{tcolorbox}

\section{1. Introduction to Generative Artificial
Intelligence}\label{introduction-to-generative-artificial-intelligence}

Generative Artificial Intelligence (GAI) represents one of the most
transformative developments in contemporary science and technology.\\
Its evolution has accelerated significantly since 2018, with the birth
of \textbf{Large Language Models (LLMs)} based on the Transformer
architecture.

To could find more information about Transformers to these links:\\
-
\href{https://web.stanford.edu/~jurafsky/slp3/9.pdf}{\textbf{Introduction
to the Transformer}}\\
-
\href{https://www.datacamp.com/tutorial/how-transformers-work}{\textbf{How
Transformers work}}

Unlike earlier technologies, these models can deeply understand
linguistic and conceptual context, generating content that is coherent,
well-structured, and often hard to tell apart from what a human might
produce.

Its evolution can be schematically articulated through 3 key phases:\\
- \textbf{Symbolic AI and supervised machine learning} (until
\textasciitilde2010): systems relied on hand-coded rules and labeled
datasets. They were effective for specific tasks like prediction or
classification but were rigid and hard to adapt to new situations.\\
- \textbf{Deep learning and distributed representations} (2010--2018):
deep neural networks enabled computers to learn hidden patterns in data.
This led to major breakthroughs in fields like image recognition,
natural language processing, and bioinformatics.\\
- \textbf{Autoregressive and multimodal generative AI} (2018 onward):
Large language models (LLMs) began learning language and concepts from
massive text datasets. New models emerged that can handle multiple
formats---text, images, audio, and code---at the same time, opening up a
wide range of applications.

\pandocbounded{\includegraphics[keepaspectratio]{images/AIevo.png}}\\
\emph{Source:
\href{https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DI2EPFaj10nkR3fO9CjVJQ.png}{Medium}.}\\
The image shows the relationships between AI, ML, DL, NLP, LLM, and
Conversational AI.''*

Academic research has played a crucial role in this evolution (think of
models such as \href{https://arxiv.org/abs/1810.04805}{BERT} developed
by Google Research or T5), but it is also being profoundly impacted
methodologically and operationally by these tools.

\section{2. Current applications and dissemination of GAI in
research}\label{current-applications-and-dissemination-of-gai-in-research}

GAI is progressively permeating academic workflows, with differentiated
uptake across disciplines. Its impact is notable in the following
domains:

\subsection{2.1 Literature conception and
review}\label{literature-conception-and-review}

\begin{itemize}
\tightlist
\item
  Assisting in literature search using specialized AI agents (e.g.,
  Elicit, Scite);
\item
  Generation of exploratory research questions;
\item
  Automatic synthesis of articulated corpora, useful for systematic and
  narrative reviews.
\end{itemize}

\subsection{2.2 Scientific text production and
revision}\label{scientific-text-production-and-revision}

\begin{itemize}
\tightlist
\item
  Preliminary drafting of text sections (e.g., abstract, methodology);
\item
  Automated linguistic revision for non-English speaking authors;
\item
  Controlled rewriting for stylistic adaptation and expository clarity.
\end{itemize}

Methodological note: Any content generated should always be reviewed and
validated, as models may introduce bias, errors or conceptual
``hallucinations.''

\subsection{2.3 Data analysis support and code
automation}\label{data-analysis-support-and-code-automation}

\begin{itemize}
\tightlist
\item
  Generation of scripts in R, Python, MATLAB from natural language
  descriptions;
\item
  Help in preliminary interpretation of results (e.g., graphs, output of
  statistical models);
\item
  Simulation of scenarios or data transformation via NLP-to-code
  interfaces.
\end{itemize}

\subsection{2.4 Dissemination and
Communication}\label{dissemination-and-communication}

\begin{itemize}
\tightlist
\item
  Creation of popular content for websites, presentations, infographics;
\item
  Linguistic and multilingual adaptation of materials for different
  audiences;
\item
  Assistance in preparing grant, pitch or open access articles.
\end{itemize}

\subsection{2.5 Diffusion and acceptance in the academic
context}\label{diffusion-and-acceptance-in-the-academic-context}

The adoption of generative AI is now heterogeneous across disciplines.

\begin{itemize}
\tightlist
\item
  Widely adopted in computational sciences, engineering, computational
  linguistics, biomedicine;
\item
  In exploratory stage in the social sciences and humanities, with
  increasing experimentation;
\item
  Still being debated in high-end journals, especially in relation to
  authorship attribution and transparency of use.
\end{itemize}

Many universities are developing internal guidelines to regulate its
use, in parallel with an evolving ethical and regulatory framework.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{{Towards a new scientific literacy}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\paragraph{The introduction of generative AI into research is not
neutral. It requires a rethinking of methodological skills as well as an
updating of scientific ethics.Researchers are called to
develop:}\label{the-introduction-of-generative-ai-into-research-is-not-neutral.-it-requires-a-rethinking-of-methodological-skills-as-well-as-an-updating-of-scientific-ethics.researchers-are-called-to-develop}

\paragraph{- Prompt engineering skills, or the art of formulating
effective and replicable
input;*}\label{prompt-engineering-skills-or-the-art-of-formulating-effective-and-replicable-input}

\paragraph{- Ability to critically evaluate generated content, to
identify errors, omissions and
bias;}\label{ability-to-critically-evaluate-generated-content-to-identify-errors-omissions-and-bias}

\paragraph{- Awareness of epistemological limitations: AI generates
plausible content, but does not verify the truth of
claims;}\label{awareness-of-epistemological-limitations-ai-generates-plausible-content-but-does-not-verify-the-truth-of-claims}

\paragraph{- Transparent documentation of tool use, useful for
reproducibility.*}\label{transparent-documentation-of-tool-use-useful-for-reproducibility.}

\section{4. Adoption of new research
methodologies}\label{adoption-of-new-research-methodologies}

GAI also enables novel experimental paradigms:

\begin{itemize}
\tightlist
\item
  \textbf{Language-driven conceptual simulations};
\item
  \textbf{Automated meta-analyses of scientific literature};
\item
  \textbf{Multimodal encoding and decoding} (text, image, numerical
  data) to represent complex phenomena.
\end{itemize}

When employed responsibly, generative AI does not replace scientific
inquiry, but \textbf{amplifies its reach and efficiency}.

\chapter{Updated Overview of Generative AI
Tools}\label{updated-overview-of-generative-ai-tools}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Content}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\begin{itemize}
\tightlist
\item
  Practical introduction to GAI Tools
\item
  Large Language Models (LLMs) for research
\item
  Specialized tools for bibliographic and document research
\item
  Plugins and APIs for SSH and STEM: when and why to use them
\item
  Operational recommendations for researchers in Social Sciences
\end{itemize}

\end{tcolorbox}

\section{1. Practical introduction to GAI
Tools}\label{practical-introduction-to-gai-tools}

The integration of Generative AI (GAI) tools into research activities
requires an informed and conscious selection of the available resources.
It is essential for a researcher to distinguish between different types
of operational tools and to understand how they work in relation to
specific research goals.

We can classify tools into three main categories:

\begin{itemize}
\tightlist
\item
  \textbf{General-purpose Language Models (LLMs)}: mainly used for
  writing, editing, and language support tasks.
\item
  \textbf{Specialized Documentary Tools}: focused on the collection,
  synthesis, and analysis of scientific literature.
\item
  \textbf{Integrated Automation Systems}: plugins, APIs, or hybrid
  platforms that extend basic capabilities, adapting them to customized
  workflows.
\end{itemize}

The effective use of these tools requires not only technical knowledge
but also the ability to assess their suitability based on:

\begin{itemize}
\tightlist
\item
  \emph{Transparency and traceability of results}
\item
  \emph{Data source currency and validity}
\item
  \emph{Level of customization allowed (advanced prompting, proprietary
  data training)}
\item
  \emph{Compliance with ethical and regulatory requirements specific to
  academic research}
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={{Particularly in \emph{SSH (Social Sciences and Humanities)}, these
aspects are critical due to risks such as methodological biases,
ambiguities in intellectual property management, and sensitive data
handling issues.}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\section{2. Large Language Models (LLMs) for
research}\label{large-language-models-llms-for-research}

LLMs currently represent some of the most widely adopted AI tools in
academic research. These models rely on deep learning architectures
trained on extensive volumes of textual data and are designed to
generate coherent linguistic content, supporting activities such as
drafting, summarization, and data analysis.

\subsection{2.1 ChatGPT-4}\label{chatgpt-4}

\textbf{Developed by:} \href{https://openai.com}{\textbf{OpenAI}}

ChatGPT-4 is a language model developed by OpenAI owned by Sam Altman,
which was made available to the public in November 2022. It is based on
state-of-the-art deep learning architectures and is designed for the
production of textual content and human-machine interaction in a natural
language.

\textbf{Key Features:}\\
- The ability to generate multilingual texts, with a high level of
semantic and syntactic coherence even on very articulated and
specialized texts;\\
- The use in conversational mode optimized to be able to sustain
prolonged dialogues while maintaining thematic and contextual coherence,
progressively adapting the answers according to the user's requests;\\
- Integration with pre-configured APIs and platforms to allow the
incorporation of the model into custom software and workflows, although
deep customization of the model (fine-tuning) remains reserved for
authorized parties with regulated access.\\
- A wide availability of tools and ancillary resources, thanks to the
wide diffusion and presence of a consolidated ecosystem of third-party
applications, extensions and interfaces.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3611}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6389}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Strengths}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Limitations}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High versatility in writing, editing, translation tasks & No native
real-time data access except through plugins or external systems \\
Large user community & Outputs always require researcher validation to
avoid the risk of inaccuracies or \textbf{hallucinations} \\
Extensive documentation & \\
\end{longtable}

\textbf{Recommended uses cases:}\\
- Preliminary drafting of articles, abstracts, and project proposals\\
- Linguistic and stylistic revision\\
- Support in formulating research questions.

\subsection{2.2 Claude}\label{claude}

\textbf{Developed by:}
\href{https://www.anthropic.com/}{\textbf{Anthropic}}

Claude is developed by Anthropic, known for its explicit orientation
towards AI models called ``\emph{constitutional}'', i.e.~designed to
privilege security, transparency and respect for ethical principles
defined a priori. The first model was released in March 2023.

\textbf{Key Features:}\\
- It prioritizes robustness and control of the content generated,
reducing the risk of inaccurate or inappropriate responses, particularly
on complex or ethically sensitive topics. - It is very versatile, as it
can be applied in diversified activities, from the drafting of texts to
the analysis of complex data, therefore suitable for academic tasks or
for structured business uses. - It demonstrates a high capacity for
contextual comprehension, being able to grasp nuanced contexts and
nuances of human language, also being able to manage very extensive
conversation contexts, revision of long documents, transcriptions, legal
acts or articulated reports. In fact, it is designed to maintain
consistency on higher text sequences than other LLMs, being able to
contain up to 200 thousand tokens (equivalent to about 500 pages of
text) in the basic version without losing the logical thread. - It
allows regulated access, as it is accessible through APIs and
proprietary platforms with a less widespread usage model than other LLMs
and a fine-tuning policy reserved exclusively for entities with advanced
security requirements, such as public bodies and universities. - It was
developed with a strong focus on AI ethics and safety . During his
training, careful and controlled sources were privileged, with limited
exposure to open data, reducing the risk of bias and information biases.
- The owner company guarantees regular updates of the model, aimed at
the progressive improvement of capabilities, precision and operational
safety, with the aim of keeping Claude always aligned with market and
research needs.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.6111}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.3889}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Strengths}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Limitations}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High safety and ethical standards, particularly suited to contexts
involving sensitive data management & No direct access to real-time
data; less widespread in Europe \\
& Higher average operating costs compared to other LLMs \\
\end{longtable}

\textbf{Recommended uses cases:}\\
- Drafting texts in fields governed by ethical codes\\
- Critical review of content generated by other models\\
- Interactions involving sensitive or highly specific data

\subsection{2.3 Gemini}\label{gemini}

\textbf{Developed by:} \href{https://deepmind.google/}{\textbf{Google
DeepMind}}

Gemini is a multimodal language model developed by Google DeepMind,
designed to integrate the processing of text, images, structured data,
and other input modalities within a single architecture. Released during
2024, it represents one of the most recent evolutions in the field of
Large Language Models (LLMs) with extensive applications in both
academic and industrial settings.

\textbf{Key Features:}\\
- It has a multimodal architecture, as it has been designed to
simultaneously process text, images, tabular data and other forms of
input. This ability distinguishes it from models focused exclusively on
natural language, expanding the application possibilities in
interdisciplinary contexts, such as Digital Humanities or the analysis
of complex datasets. - It has an advanced multilingual language
capacity, comparable to that of ChatGPT-4, with the possibility of
generating articulated content, summaries, translations and analysis of
specialized texts. - It has native integration with the Google
ecosystem: it has been designed to work in synergy with Google Workspace
and other services of the Google Cloud platform, facilitating
integration into the research and document management workflows already
in use at many academic institutions. - Allows access via APIs and cloud
tools. The model is available to users through Google Cloud Platform,
with access and customization policies that provide specific
configurations for universities, public bodies and companies.
Fine-tuning personalization is only allowed in authorized environments,
in line with Google's security and compliance policies. Gemini benefits
from constant updates, both at the data and architecture level, keeping
the model aligned with evolving language, knowledge sources, and
regulatory needs.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5139}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4861}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Strengths}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Limitations}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Advanced multimodal data analysis & Not a real-time information
retrieval system \\
linguistic capabilities suited to specialized text analysis & Requires
substantial infrastructure \\
& Less documentation available within SSH academic contexts \\
\end{longtable}

\textbf{Recommended uses cases:}\\
- Projects involving multimodal source analysis\\
- Development of integrated educational and communication materials\\
- Support in building complex datasets

\subsection{2.4 Perplexity AI}\label{perplexity-ai}

\textbf{Developed by:}
\href{https://www.perplexity.ai/}{\textbf{Perplexity AI}}

Perplexity AI is a language model-based query system designed to
complement the capabilities of LLMs with document search and source
verification capabilities. Launched in 2022 and further developed until
2025, it differs from traditional LLMs for the combination of text
generation and retrieval of updated information, with transparent
indication of the sources consulted.

\textbf{Key Features:}\\
- Avere una architettura ibrida LLM + motore di ricerca. Combina
l'elaborazione linguistica tipica dei modelli generativi con un sistema
di interrogazione su database e fonti online, restituendo risposte
accompagnate da riferimenti bibliografici o collegamenti diretti alle
fonti originali. - E' stato concepito specificamente per supportare
attività di revisione della letteratura, fact-checking e interrogazioni
esplorative, risultando quindi particolarmente utile in ambito
giornalistico e accademico, essendo anche ottimizzazione per la ricerca
bibliografica. - Possiede una capacità linguistica focalizzata perché
pur basandosi su modelli linguistici comparabili a quelli di altri LLM,
Perplexity AI privilegia risposte concise e orientate all'informazione
piuttosto che alla generazione di testi lunghi o articolati. - E'
disponibile sia come applicazione web sia integrabile in sistemi di
gestione documentale tramite API, con configurazioni specifiche per
istituzioni di ricerca e aziende. La possibilità di personalizzazione
mediante fine-tuning è limitata e subordinata ad accordi specifici. - A
differenza di modelli addestrati su dati statici, Perplexity AI si
aggiorna automaticamente grazie alla componente search integrata,
garantendo risposte basate su fonti recenti. - Possiede una elevata
trasparenza nel processo di generazione delle risposte.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4028}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5972}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Strengths}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Limitations}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Automatic updating via integrated search components & Less suitable than
other LLMs for drafting extended content or managing complex
documents \\
High transparency in the response generation process & The quality and
relevance of answers depend on the availability and reliability of the
queried sources. \\
\end{longtable}

\textbf{Recommended uses cases:}\\
- Preliminary research and verification\\
- Exploratory bibliographic research\\
- Fact-checking activities

\subsection{2.5 DeepSeek}\label{deepseek}

\textbf{Developed by:}
\href{https://www.deepseek.com/en}{\textbf{DeepSeek AI}}

\textbf{Key Features:}\\
- Specifically designed with an emphasis on long-context understanding
and multilingual processing, offering optimized performance for both
general-purpose and domain-specific academic tasks.\\
- Built on transformer architectures and trained on an extensive
multilingual corpus (including scientific and technical texts),
enhancing its applicability in research settings that require high
linguistic precision.\\
- Capable of handling extended input sequences beyond the standard
limits of many mainstream LLMs, allowing for the processing of large
documents, legal texts, or comprehensive datasets without
fragmentation.\\
- Provides configurable access through both web interfaces and APIs,
with customization options such as proprietary dataset integration and
specialized vocabulary training, particularly relevant for academic and
institutional use.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4583}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5417}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Strengths
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Limitations
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
High reliability in multilingual academic writing and translation tasks,
with particular attention to terminological consistency. & As of now,
DeepSeek is less widespread in Western academic institutions compared to
models like ChatGPT‑4 or Claude, partly due to access policies and
licensing restrictions. \\
Enhanced performance in long-document summarization, literature review
synthesis, and complex query handling within structured academic
frameworks. & Real-time data retrieval capabilities are not natively
embedded; reliance on external plugins or customized configurations is
necessary for up-to-date information access. \\
Integration with knowledge base systems and research management
platforms, supporting structured data extraction and semantic analysis
workflows. & Requires higher computational resources than standard LLMs,
especially when operating at full capacity for long-context
processing. \\
\end{longtable}

\textbf{Recommended uses cases:}\\
- Drafting and reviewing multilingual academic papers, particularly in
contexts involving technical or regulatory terminology.\\
- Summarization and synthesis of large volumes of research literature,
including legal or policy documents.\\
- Integration into academic platforms for semantic search, knowledge
extraction, and multilingual document management.

\section{3. Specialized Tools for bibliographic and document
research}\label{specialized-tools-for-bibliographic-and-document-research}

Beyond general-purpose LLMs, there are AI tools designed specifically to
support bibliographic and document research. They integrate querying,
classification, and synthesis functions aimed at optimizing literature
review phases.

\subsubsection{\texorpdfstring{\href{https://elicit.com/}{\protect\includegraphics[width=0.16\linewidth,height=\textheight,keepaspectratio]{images/elicit.png}}}{Elicit}}\label{elicit}

Elicit is a tool specifically developed to \textbf{support bibliographic
and document research activities} by leveraging LLMs applied to
structured academic corpora.\\
Unlike traditional search engines, Elicit is capable of automatically
extracting structured information from scientific articles, such as
research questions, methods, key results, and citations.

Its core functions include:\\
- \emph{Automatic identification and extraction of research-relevant
elements from articles (e.g., title, authors, research questions,
methods, results, citations)}.\\
- \emph{Synthesis of responses through thematic clustering and semantic
categorization, facilitating the formulation of research hypotheses
already informed by the state of the art}.\\
- \emph{Export of structured data in CSV or JSON formats, allowing
integration with qualitative analysis software or reference management
systems}.

For example, using Elicit, researchers can generate summary tables
containing:\\
- \emph{Main articles identified based on a query}\\
- \emph{Automatically synthesized abstracts}\\
- \emph{Extracted research questions and primary findings}\\
- \emph{Structured citation metadata}.

These features make Elicit particularly suitable for preparing
systematic reviews and meta-analyses, offering researchers not only a
list of sources but also structured overviews that can directly inform
project design, grant proposal drafting, and academic writing processes.

Compared to generic LLMs, Elicit provides:\\
- \textbf{Focused output}: responses are oriented towards factual and
structured information rather than general linguistic generation.\\
- \textbf{Source verification}: results are derived from curated
academic databases, enhancing the reliability and validity of the
information obtained.\\
- \textbf{Workflow integration}: data produced by Elicit can be
incorporated into existing academic workflows, including qualitative
analysis platforms and reference management systems.

However, it is important to note that Elicit does not replace the
critical evaluation of sources by the researcher. While the tool offers
substantial support in reducing the time needed for literature search
and data extraction, \textbf{each piece of information should be
validated} according to the standards of academic rigor and methodology.

\subsubsection{\texorpdfstring{\href{https://scite.ai/}{\protect\includegraphics[width=0.14\linewidth,height=\textheight,keepaspectratio]{images/scite.png}}}{Scite}}\label{scite}

Scite is a specialized platform designed to \textbf{support bibliometric
analysis and literature evaluation} by focusing on the citation context
of academic publications.\\
Unlike traditional bibliographic databases, which report citation counts
without specifying their nature, Scite enables researchers to assess not
only the number but also the type and content of citations received by a
given article.

Its principal functionalities include:\\
- \emph{Analysis of citation context, distinguishing between supportive
citations, contrasting citations, and neutral mentions}.\\
- \emph{Integration with academic databases to provide comprehensive and
structured citation data across multiple disciplines}.\\
- \emph{Visualization of citation patterns through interactive
dashboards, facilitating both individual article assessment and broader
literature mapping}.

For each publication, Scite provides:\\
- \emph{The total number of citations, classified into supportive,
contrasting, and mentioning categories}.\\
- \emph{Detailed reports including the text surrounding each citation,
allowing for qualitative evaluation of the citing sources}.\\
- \emph{Metrics that can complement traditional bibliometric indicators,
offering a more nuanced understanding of a publication's impact}.

These features make Scite particularly valuable in phases such as:\\
- \textbf{Literature review}, where researchers need to identify not
only frequently cited works but also those that are positively or
negatively discussed within the academic community.\\
- \textbf{Research assessment and evaluation processes}, where citation
context can inform more sophisticated performance metrics.\\
- \textbf{Grant proposal preparation and institutional reporting}, where
evidence of scholarly impact requires qualitative as well as
quantitative support.

While Scite enhances citation analysis capabilities, \textbf{it does not
substitute for in-depth content analysis by domain experts}. The
interpretation of citation types and their implications remains the
responsibility of the researcher. Additionally, coverage may vary
depending on discipline and database integration, making it advisable to
verify source completeness and relevance in each specific research
context.

\section{4. Plugins and APIs for SSH and STEM: when and why to use
them}\label{plugins-and-apis-for-ssh-and-stem-when-and-why-to-use-them}

In Academic research contexts --- whether in Social Sciences and
Humanities (SSH) or STEM discipline --- the use of plugins and
\textbf{APIs associated with GAI models plays a crucial role} whenever
functional integration with existing information systems or automation
of recurring tasks is required.\\
Unlike general-purpose tools,
\href{https://www.ibm.com/think/topics/api}{\textbf{APIs (Application
Programming Interface)}} allow direct incorporation of language model
capabilities or specialized platforms into workflows already established
within institutional or corporate environments.

Typical applications include:\\
- Automated classification and organization of textual data, achieved by
integrating language models within document management systems or
digital archives, allowing for more efficient handling and retrieval of
large volumes of unstructured information.\\
- Automated generation of metadata and descriptors for datasets, which
facilitates the management and curation of research archives,
bibliographic repositories, or complex digital collections by
systematically assigning structured information to each resource.\\
- Controlled multilingual content translation, through the use of AI
integrated into editorial platforms or academic repositories. This
approach enables not only the automatic translation of content but also
the application of customized dictionaries or specialized glossaries to
ensure terminological consistency and accuracy across different
languages.\\
- Semantic querying of complex databases, allowing researchers to submit
natural language queries that surpass the limitations of traditional
keyword-based search systems, thereby improving the precision and
relevance of retrieved results.

In \textbf{STEM fields}, plugins are commonly adopted to extend
functionalities such as:\\
- \emph{Statistical analysis}\\
- \emph{Symbolic computation}\\
- \emph{Code generation}\\
- \emph{Data visualization}.

In \textbf{SSH contexts}, plugins are particularly useful for:\\
- \emph{Extending bibliographic database and historical archive querying
capabilities}\\
- \emph{Integrating text mining and sentiment analysis tools}\\
- \emph{Automating the production of reports or summaries from complex
linguistic corpora}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{{Important Considerations}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

The adoption of plugins and APIs involves \textbf{specific evaluations
concerning security, sensitive data management, and regulatory
compliance, especially within the European academic context where
regulations such as GDPR apply}.\\
You can choose between plugins and APIs depending on your project's
nature.\\
Plugins are easier to use because they come ready-made and already
integrated. APIs, on the other hand, let you customize things more, but
they require more technical skills to set up and manage.

\end{tcolorbox}

\section{5. Operational recommendations for researchers in Social
Sciences}\label{operational-recommendations-for-researchers-in-social-sciences}

Integrating GAI tools into social research processes requires a
\textbf{rigorous methodological approach and careful assessment of
operational and ethical implications}.\\
Below are some key recommendations to guide their effective and ethical
integration:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 0\tabcolsep) * \real{1.0000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Recommendations}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Clearly define the scope of LLM and AI tool usage \\
Systematically verify content reliability---AI outputs always require
critical review. \\
Prefer tools with transparent source referencing (e.g., Perplexity AI,
Scite). \\
Ensure data adequacy, favoring SSH-specific corpora. \\
Document all AI tool usage explicitly in reports and publications. \\
Address ethical and legal profiles, ensuring compliance with GDPR, AI
Act, and institutional policies \\
\end{longtable}

It is advisable for Research Institutions and Groups to
\textbf{establish clear internal AI use policies}, updated regularly
according to technological and regulatory evolution, ensuring adequate
training for team members.

\chapter{Prompt Engineering for Research: Techniques, Workflows, and
Evaluation}\label{prompt-engineering-for-research-techniques-workflows-and-evaluation}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\subparagraph{Introduction to Prompt
Engineering}\label{introduction-to-prompt-engineering}

\subparagraph{Few-shot and zero-shot prompting: inline examples and
template
selection}\label{few-shot-and-zero-shot-prompting-inline-examples-and-template-selection}

\subparagraph{Complex and reproducible prompt chaining and pipelines
(e.g.~bibliography → topic modeling →
synthesis)}\label{complex-and-reproducible-prompt-chaining-and-pipelines-e.g.-bibliography-topic-modeling-synthesis}

\subparagraph{Advanced prompts: metadata extraction, outline generation,
stylistic
paraphrasing}\label{advanced-prompts-metadata-extraction-outline-generation-stylistic-paraphrasing}

\subparagraph{Iterating and assessing the quality of
responses}\label{iterating-and-assessing-the-quality-of-responses}

\subparagraph{Guidelines for Creating Academic
Prompts}\label{guidelines-for-creating-academic-prompts}

\end{tcolorbox}

\section{1 Introduction to Prompt
Engineering}\label{introduction-to-prompt-engineering-1}

\subsection{1.1 What is a prompt?}\label{what-is-a-prompt}

In the context of Generative Artificial Intelligence (GAI), a prompt is
a textual instruction given to the model to generate an output. It is
not simply a question, but a \textbf{structured linguistic command} that
defines \emph{objectives, constraints, register, and output format}.\\
In academic research, prompt design is a crucial methodological moment,
as the quality of the generated content largely depends on it.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={Important}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

In SSH research (Social Sciences and Humanities), a well-crafted prompt
typically:\\
- Clearly defines the task objective (\emph{e.g.''Analyze the sentiment
of\ldots{}``\emph{)\\
- Specifies the desired output format (}e.g.''Return a bullet list
of\ldots{}``\emph{)\\
- Provides examples or constraints, when needed (}e.g.''Use formal
Italian register''})

\end{tcolorbox}

\subsection{1.2 The Prompt Engineering}\label{the-prompt-engineering}

Large Language Models (LLMs) respond to textual input with variable
linguistic articulation depending on \emph{training}, \emph{context},
and \emph{prompt structure}. The way the request is formulated directly
influences the type of output. The same question can produce very
different results depending on form, specificity, or presence of
examples.

Prompt Engineering is the discipline of designing and optimizing prompts
to guide AI models---particularly LLMs---toward the desired output. It
involves \textbf{methodological principles} such as \emph{clarity},
\emph{relevance}, \emph{structure}, \emph{logical progression} and
\emph{iteration}.

\subsection{1.3 Hallucinations and how to prevent
them}\label{hallucinations-and-how-to-prevent-them}

``Hallucinations'' occur when the model generates unverified or entirely
fabricated statements, often attributing fictitious details to
nonexistent sources.\\
These errors stem from the statistical nature of Machine Learning and
\textbf{require strategies of cross-validation and guided
reinforcement}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{{Anti-hallucination strategies}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\hl{- \textbf{Cross-source validation}: ask the model for references,
citations, or URLs and manually verify them.\\
- \textbf{Confirmation queries}: include a verification clause such as:
*``Are you sure?* \emph{Please briefly validate this data.}''\\
- \textbf{Few-shot learning}: provide 2--3 examples distinguishing
between accurate and incorrect responses in order to guide its behavior
and improve its accuracy.\\
- \textbf{Iterative refinement}: generate a first draft and request
successive revisions to address inaccuracies, documenting each
iteration.}

\end{tcolorbox}

\subsection{1.4. Foundational principles for effective and reliable
prompts}\label{foundational-principles-for-effective-and-reliable-prompts}

\subsubsection{Clarity and Specificity}\label{clarity-and-specificity}

\begin{itemize}
\tightlist
\item
  Frame the task unambiguously. Avoid vague requests like \emph{``write
  something about\ldots{}''}. Always indicate the desired result
  (e.g.,\emph{``return a table with columns X, Y, and Z''}).
\item
  Explicitly define the output format (e.g., \emph{bullet list, 100-word
  paragraph, numbered list}).
\end{itemize}

\subsubsection{Full Context}\label{full-context}

\begin{itemize}
\tightlist
\item
  Provide all relevant information, such as text excerpts, definitions
  of technical terms, methodological constraints, or the target audience
  (e.g., \emph{``text aimed at SSH researchers''}).
\item
  Specify tone and register (\emph{formal, didactic, expository}) to
  ensure stylistic consistency.
\end{itemize}

\subsubsection{Guided Iteration}\label{guided-iteration}

\begin{itemize}
\tightlist
\item
  Do not settle for the first draft. Test small variations to observe
  how each affects the output.
\item
  Test A/B versions, saving each version for comparative analysis and
  preserve the various iterations for later benchmarking.
\end{itemize}

\section{2. ``Few-shot'' and ``Zero-shot'' prompting: inline examples
and template
selection}\label{few-shot-and-zero-shot-prompting-inline-examples-and-template-selection-1}

Prompt design plays a crucial role in output quality when using LLMs for
academic purposes.\\
In particular, \textbf{zero-shot} and \textbf{few-shot} prompting
strategies represent two distinct but \emph{complementary approaches},
aimed at orienting the behavior of the model in the absence or presence
of explicit examples.\\
The choice between zero-shot and few-shot prompting must be guided by
the nature of the task, the degree of formalization expected and the
need to control the variability of the output.\\
Both modes can be adopted within more complex pipelines, integrated with
validation, review and iterative refinement tools.

\subsubsection{Zero-shot Prompting}\label{zero-shot-prompting}

Zero-shot prompting uses explicit instructions without concrete
examples. It assumes the model can infer the task solely from a clear
command. This is useful for standard or generic tasks but more prone to
ambiguity or result variability.

\subsubsection{Few-shot Prompting}\label{few-shot-prompting}

Few-shot prompting embeds one or more examples within the prompt,
guiding the model to replicate a demonstrated pattern. In academic
contexts, it is especially effective for standardizing formats (e.g.,
\emph{abstracts, bibliographic entries, methodological summaries}) and
maintaining stylistic coherence.

\subsubsection{Template Use}\label{template-use}

Template selection and adaptation are central to this strategy.
Recurring structures --- e.g., \emph{``Question → Extract → Summary'' or
``Title → Objective → Methodology → Results''} ---facilitate comparable
outputs and enhance compatibility with archival and analytical systems.

\section{3. Prompt chaining and complex pipelines: a modular approach to
output
construction}\label{prompt-chaining-and-complex-pipelines-a-modular-approach-to-output-construction}

Academic tasks involving progressive information processing --- such as
\emph{literature reviews}, \emph{thematic analysis} or \emph{argument
construction} --- benefit significantly from complex pipelines based on
prompt chaining.\\
This approach entails sequential execution of multiple prompts, each
serving a specific function within a structured workflow.\\
The output from each stage becomes the input for the next, following a
modular, cumulative logic.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Complex pipelines}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Complex pipelines differ markedly from the isolated use of LLMs, as they
aim to \emph{structure a distributed cognitive process}, in which each
step contributes to the construction of a coherent, documentable and
verifiable final result.\\
Their adoption makes it possible not only to divide cognitively dense
tasks into more manageable units, but also \emph{to improve
methodological control and transparency of automatic processing
processes}.

\end{tcolorbox}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.1919}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.8081}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Application example}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
``Systematic review of the literature''
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Retrieving relevant sources} & \emph{Using a prompt to query
databases or tools such as Elicit or Perplexity AI, in order to identify
relevant articles on a given topic.} \\
\textbf{Structured metadata extraction} & \emph{Prompts aimed at
extracting and organizing information such as title, authors, date,
methodology, type of study, subject area.} \\
\textbf{Theme recognition and clustering} & \emph{Application of prompts
aimed at identifying recurring concepts, semantic classification and
building thematic maps.} \\
\textbf{Comparative synthesis of results} & \emph{Synthesis command to
produce an integrated view of the evidence, with comparison between
approaches, results and theoretical positions.} \\
\textbf{Generation of the final output} & \emph{Last prompt to transform
the collected material into a finished product, such as a thematic
overview, a bibliographic annotation or an articulated abstract.} \\
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{Complex pipelines differ from isolated prompt use: they aim to construct
a distributed cognitive process.}\vspace{3mm}

Benefits include: \emph{Modularity} - \emph{Reproducibility} -
\emph{Methodological transparency} - \emph{Output traceability}.

\end{tcolorbox}

\section{4. Advanced prompts: metadata extraction, outline generation,
stylistic
paraphrasing}\label{advanced-prompts-metadata-extraction-outline-generation-stylistic-paraphrasing-1}

The use of LLMs in Academia is not limited to the simple production of
texts, but can be extended to more sophisticated functions through the
use of \textbf{advanced prompts}.\\
These allow you to guide the model in carrying out structured,
analytical or transformative tasks, which require a more precise
configuration of the prompt and a greater awareness of the semantic
capabilities of the model.

Among the most relevant applications are:\\
- The automatic extraction of metadata from scientific articles or other
structured documents.\\

\emph{Through targeted prompts, it is possible to isolate information
such as author, year of publication, methodological context, reference
discipline or type of study. This type of operation is particularly
useful for the construction of bibliographic datasets, the compilation
of structured repertoires and the automated analysis of literature.}\\
- The generation of outlines.\\
\emph{During the planning or drafting of scientific contributions, it is
possible to ask the model to build logical schemes, argumentative
structures or section plans consistent with disciplinary standards.
These outlines can then be integrated, modified or expanded by the
researcher, acting as a support for the design of articles, reports,
project proposals or theses.}\\
- Targeted stylistic paraphrases.\\
\emph{These are reformulations of existing content according to a
specific style: formal, technical, popular, or compliant with certain
disciplinary registers. This functionality is used in the revision of
texts, in the linguistic adaptation for international publications or in
the production of multiple versions of the same content for teaching,
editorial or communication purposes}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{Applications include:}\vspace{3mm}

\begin{itemize}
\tightlist
\item
  Structured metadata from PDFs (author, date, methods).\\
\item
  Academic outlines following disciplinary logic.\\
\item
  Stylistic rewriting (formal → plain, Italian → English, etc.).\\
\end{itemize}

\end{tcolorbox}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1221}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5344}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3435}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\textbf{Obiettivo:}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\emph{Scrivere una sintesi tematica a partire da un corpus
bibliografico}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& \textbf{Funzione} & \textbf{Tecnica} \\
1 & Inserimento articoli & prompt + upload PDF / DOI \\
2 & Estrazione metadati (autore, anno, metodo) & prompt strutturato \\
3 & Riconoscimento dei temi ricorrenti & prompt di classificazione \\
4 & Sintesi comparativa dei risultati & prompt di sintesi con vincolo
stilistico \\
5 & Output finale in formato accademico & template APA o report
Markdown \\
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Effective use of advanced prompts \textbf{requires a fine understanding
of the model's capabilities and limitations}, as well as a design
ability geared toward controlling the output.\\
This is a particularly promising area of experimentation for the world
of research, in which AI is used not to replace writing, but to enhance
its preparatory, analytical and stylistic phases.

\end{tcolorbox}

\begin{quote}
See:
\href{https://doi.org/10.1007/s10439-023-03272-4}{\textbf{Giray,L.''Prompt
Engineering with ChatGPT: A Guide for Academic Writers''}.}.\\
See:
\href{https://intranet.icar.cnr.it/wp-content/uploads/2025/01/RT-ICAR-NA-2024-05.pdf}{\textbf{Generative
Artificial Intelligence Prompt Engineering Overview}}.
\end{quote}

\section{5. Iteration and Evaluation of output
quality}\label{iteration-and-evaluation-of-output-quality}

The effectiveness of a prompt cannot be considered a \emph{static
datum}, but the result of an iterative optimization process.\\
The interaction with the model requires an \emph{experimental and
progressive logic, in which the answers obtained must be constantly
subjected to verification, reformulation and comparison}.\\
\textbf{Iteration} consists of the targeted repetition of the prompting
with incremental changes as variations in the vocabulary, in the
instructions order, in the level of specificity or in the structure of
the expected format.\\
This process refines the quality of the output, \emph{reducing the
interpretative ambiguities of the model and improving consistency with
the researcher's objectives}.\\
More than a simple linguistic refinement, it is a \emph{methodological
mechanism that allows you to explore the sensitivity of the model to the
different input parameters}.

The \textbf{evaluation of the quality of the answers} requires clear and
shared criteria.\\
In the academic field, the analysis includes not only formal and
grammatical correctness, but also other aspects such as:\\
- \emph{conceptual accuracy (absence of factual errors or unjustified
inferences)}\\
- \emph{relevance to the demand}\\
- \emph{argumentative cohesion}\\
- \emph{adherence to stylistic or disciplinary standards}\\
- \emph{transparency of sources and implicit assumptions (where
relevant)}.

Evaluation cannot be entrusted to generic indicators or intuitive
judgments, but must be based on grids or reference models compatible
with scientific research and communication practices.\\
\emph{In particular, when the results are used as preliminary materials
for publications, systematic reviews or teaching support, it is
advisable to document the choices made, justify any reformulations and
point out the limits of the output generated.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{In summary, employing LLMs in the academic field means applying
reflective and responsible logic to ensure the reliability and relevance
of the content produced.Prompt Engineering in research must be treated
as a methodological discipline, not a casual interaction. It supports
transparency, reproducibility, and epistemic control in AI-assisted
scholarship.:::}\vspace{3mm}

\end{tcolorbox}

\section{6. Guidelines for creating academic
prompts}\label{guidelines-for-creating-academic-prompts-1}

Below a structured in 6 steps useful for obtaining maximum results in
academic research.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={1 - Precise definition of the purpose of the research}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

You need to be transparent about what you want to achieve. A vague
prompt leads to vague answers, and you have to turn the search questions
into direct instructions for the AI model.\\
The goal must be clear:\\
(incorrect) \emph{``Give me an overview of X.''}\\
(corrected) \emph{``Identify the most recent peer-reviewed articles on
topic X.''}\\
The question must be transformed into an instruction.\\
To the question \emph{``What is the role of AI in qualitative
research?''}, the prompt should be:\\
\emph{``List the 5 peer-reviewed articles published from 2022 to 2024 on
the role of AI in qualitative research, indicating title, authors,
journal, and DOI.''}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={2 - Provide context and selection criteria}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Artificial intelligence needs the necessary context to focus the search
and provide relevant results.\\
It is important to include the following parameters:\\
- \emph{Disciplinary scope}: \emph{e.g., ``in the context of social
sciences'' or ``with a focus on bioinformatics''.}\\
- \emph{Time range}: \emph{e.g., ``from the last three years'' or
``before 2020''.}\\
- \emph{Type of output desired}: \emph{``Return a CSV table with
columns: Title, Authors, Year, DOI.''}\\
- \emph{``Generate a bulleted list.''}\\
- \emph{``Provide a detailed explanation.''}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={3 - Provide examples (Few-Shot prompting)}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Showing the AI one or two examples of the desired output, as if it were
a model to follow, allows for a more accurate and coherent response.\\
Examples must be clear, promptly including a few pre-filled rows in the
desired format: \emph{Title, Authors, Year, DOI}\\
``AI in Social Sciences: A Review'', Rossi et al., 2023,
10.1234/ai.socsci.2023.01\\
``Qualitative Artificial Intelligence Methods'', Smith \& Lee, 2022,
10.5678/qual.ai.2022.02\\
Then ask:\\
\emph{``Now continue with three more articles following the same
format.''}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={4 - Break the task into multiple steps (Chain of Thought)}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

For complex or multidisciplinary tasks, break the workflow into
sequential steps to help the model reason and reduce hallucinations.\\
How to guide AI reasoning:\\
\emph{step 1) ``Search for articles using keywords X, Y, Z.''}\\
\emph{step 2) ``Filter for high-impact journals (Q1/Q2).''}\\
\emph{step 3) ``Sort results in reverse chronological order.''}\\
\emph{step 4) ``Summarize the main findings of each article in 50
words.''}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={5 - Implement subsequent consistency checks}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

It is advised not to blindly trust the outputs received from AI. You can
ask the model to verify its own results or justify its choices.\\
You may proceed as follows:\\
- \emph{Request for justification}: \emph{``Briefly explain why each
article is relevant to my research on X.''}\\
- \emph{Fact-Check}: \emph{``For each DOI, confirm its existence and
validity on CrossRef.''}\\
- \emph{Cross-Review}: \emph{``Review the table and flag any
inconsistencies or potential hallucinations.''}

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={6 - Iterate and document}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Building effective prompts can be considered an iterative process, as it
is unlikely to achieve the desired result on the first try.\\
- \emph{Track versions}: record each prompt variant with date and
changes to identify best practices.\\
- \emph{Compare results}: keep only the prompts that produce the most
accurate and complete outputs.\\
- \emph{Analyze errors}: when hallucinations occur (\emph{e.g.,
non-existent articles, incorrect DOIs}), refine your prompt by adding
specific constraints (\emph{e.g., ``use only Scopus or PubMed
databases'' or ``exclude predatory journals''}).

\end{tcolorbox}

\chapter{Use Cases in Social Sciences and Humanities (SSH)
Research}\label{use-cases-in-social-sciences-and-humanities-ssh-research}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\subparagraph{Text Mining and Topic Modeling applied to textual corpora
in
SSH}\label{text-mining-and-topic-modeling-applied-to-textual-corpora-in-ssh}

\subparagraph{Assisted Qualitative Analysis: Automatic Coding and
Sentiment
Analysis}\label{assisted-qualitative-analysis-automatic-coding-and-sentiment-analysis}

\subparagraph{Multilevel Translation and Linguistic Adaptation for
Academic
Environments}\label{multilevel-translation-and-linguistic-adaptation-for-academic-environments}

\subparagraph{Practical Examples and Implementation
Scenarios}\label{practical-examples-and-implementation-scenarios}

\end{tcolorbox}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{1. Text Mining and Topic Modeling applied to textual corpora in
SSH}\label{text-mining-and-topic-modeling-applied-to-textual-corpora-in-ssh-1}

The application of AI-based tools --- particularly language models and
automated language processing techniques --- has opened new perspectives
for textual analysis within the social sciences and humanities.\\
Unlike STEM disciplines, where computational tools are well established,
\textbf{integrating AI into SSH} research processes requires
\emph{careful and contextualized methodological reflection}.\\
A primary area of application concerns \textbf{text mining} and
\textbf{topic modeling} on textual corpora.\\
These techniques \emph{enable the automatic identification of latent
thematic structures within large volumes of text}, allowing researchers
to explore \emph{discursive patterns, lexical frequencies, and semantic
co-occurrences}.\\
Automatic text analysis through computational methods is increasingly
relevant in SSH research, especially when dealing with \emph{large,
unstructured, and heterogeneous textual sources}.\\
In this context, text mining and topic modeling emerge as two distinct
but complementary tools for the systematic exploration of linguistic
corpora.\\
The analysis can be conducted on different sources (\emph{interviews,
newspaper articles, administrative documents, parliamentary
proceedings}) and yields interpretable visual outputs (\emph{thematic
maps, dendrograms, conceptual networks}).\\
\textbf{However, it is essential that these tools be employed not as
substitutes but as complements to theoretically grounded analysis}.

\subsection{1.1 Text Mining: structured extraction from textual
data}\label{text-mining-structured-extraction-from-textual-data}

\textbf{Text mining} refers to the set of computational techniques aimed
at the automatic extraction of structured information from natural
language text.\\
In \textbf{SSH contexts}, the goal of text mining is to transform
textual documents into quantitative, interpretable representations that
can feed \emph{exploratory, descriptive, or inferential analyses}.

Typical \textbf{applications} include:\\
- Analysis of political language in parliamentary speeches.\\
- Study of rhetoric in media or institutional communication.\\
- Exploration of collective narratives in historical, memorial, or
literary sources.\\
- Thematic mapping of open-ended interview datasets.

This approach relies on
\href{https://www.ibm.com/think/topics/natural-language-processing}{\textbf{Natural
Language Processing (NLP)}} tools such as:\\
- \emph{Tokenization}\\
- \emph{Lemmatization}\\
- \emph{Part-of-speech (POS) tagging}\\
- \emph{Named Entity Recognition (NER)}\\
- \emph{Lexical co-occurrence analysis}\\
- \emph{Construction of Document-Term Matrices (DTM)}

\begin{quote}
See:
\href{https://web.stanford.edu/~jurafsky/slp3/old_oct19/8.pdf}{\emph{``Part-of-speech
(POS) tagging'' - Stanford University}}.\\
See:
\href{https://www.ibm.com/it-it/think/topics/named-entity-recognition}{\emph{``Named
Entity Recognition (NER)'' - IBM}}.
\end{quote}

\subsection{1.2 Topic Modeling: identifying latent
structures}\label{topic-modeling-identifying-latent-structures}

\textbf{Topic modeling} encompasses statistical methods that
automatically uncover the principal themes within a large collection of
documents without prior specification.\\
It operates by identifying groups of words that frequently co-occur,
presumed to represent a common topic. \emph{Each document is viewed as a
mixture of topics, and each topic is represented by a distribution of
semantically related terms}. In practice, the model does not
``understand'' meaning as a human would but computes word co-occurrence
patterns and infers thematic presence accordingly. The researcher then
interprets each word cluster and assigns a label or meaning.

The most widely adopted model is
\href{https://dl.acm.org/doi/pdf/10.5555/944919.944937}{\textbf{``Latent
Dirichlet Allocation (LDA)}}, which assumes each document to be a
mixture of topics and each topic a distribution over terms.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{In \textbf{SSH} topic modeling allows to:}\vspace{3mm}

\begin{itemize}
\tightlist
\item
  Highlight primary themes in a corpus without a priori coding.\\
\item
  Track thematic evolution over time (e.g., \emph{temporal topic
  modeling}).\\
\item
  Compare thematic emphasis across document groups (e.g.,
  \emph{governmental vs.~civic sources}).\\
\item
  Support category identification in qualitative studies with large
  datasets.\\
\end{itemize}

\end{tcolorbox}

Interpretation of topics remains a fundamentally qualitative operation,
requiring theoretical expertise and domain knowledge.\\
\textbf{Topic modeling does not replace interpretive analysis but
extends its scope and reproducibility}.

\subsubsection{Example Schema: Topic Modeling on a News Article
Corpus}\label{example-schema-topic-modeling-on-a-news-article-corpus}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2917}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7083}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Context
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Corpus of 1,000 articles from national newspapers, published between
2020 and 2024, related to the topic of environment and climate policies.
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Objective & To identify the main themes present in the articles,/
without defining them from the start. \\
(1) Text pre-processing & Text cleanup (removal of punctuation,
stopwords, etc.) / Reduction of words to the basic form (lemmatization)
/ Construction of the document-term matrix (which words appear in which
articles, and how often) \\
(2) Application of the model (e.g.~\emph{LDA -- Latent Dirichlet
Allocation}) & The model statistically processes co-occurrences and
returns a series of ``topics'', each consisting of a list of frequent
words. \\
\end{longtable}

\subsubsection{Example of synthetic
output:}\label{example-of-synthetic-output}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4583}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2917}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Topic}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Most Representative Words}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Interpretation (by the Researcher)}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & emissions, CO₂, fuels, industry, coal & Energy transition and
decarbonization \\
2 & drought, extreme events, flooding, heatwave, damage & Impacts of
climate change \\
3 & COP26, agreements, UN, targets, Paris & International climate policy
and conferences \\
4 & mobility, transportation, electric vehicles, incentives, public
transit & Urban sustainability policies \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.2361}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.7639}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
(3) Analysis and visualization & Distribution of topics by year → which
themes increase or decrease over time / Comparison by newspaper → which
newspapers emphasize certain themes / Mapping of topics within political
discourse → e.g.~overlapping with parliamentary discourses \\
(4) Limitations and Critical Use & The model suggests groups of words,
not ``meanings'': the interpretation of the themes is the responsibility
of the researcher. The results depend a lot on the quality of the corpus
and the technical choices (number of topics, filter parameters, etc.) \\
\end{longtable}

\subsection{1.3 Methodological Considerations and
Limitations}\label{methodological-considerations-and-limitations}

Both techniques present critical constraints. We have to pay attention
to:\\
- \textbf{Preprocessing quality} (cleaning, normalization) significantly
affects results\\
- \textbf{Topic interpretation} demands careful, theory-informed human
mediation\\
- \textbf{Parameter choices} (number of topics, filtering thresholds)
are inherently arbitrary and must be transparently justified

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{{\textbf{Methodological Tip}: Document all preprocessing decisions,
triangulate with other data sources, and reflect epistemologically on
the limits of automated social inference.}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{1.4 Practical Applications in SSH
Research}\label{practical-applications-in-ssh-research}

To better understand its use, some concrete areas of application are
suggested, by way of example:\\
- \textbf{Cultural History}: applying topic modeling to 19th-century
correspondence to identify recurring themes among European
intellectuals.\\
- \textbf{Sociology of Communication}: analyzing digital platform
comments to detect discursive patterns and thematic polarization.\\
- \textbf{Political Science}: studying parliamentary speeches to trace
party lexicon evolution and contrast with media framing.\\
- \textbf{Digital Anthropology}: text mining on thematic forums to
extract native categories and semantic maps related to care,
consumption, and identity.

\subsubsection{Recommended Open Source Tools for
SSH}\label{recommended-open-source-tools-for-ssh}

\begin{itemize}
\tightlist
\item
  \href{https://tmtoolkit.readthedocs.io}{tmtoolkit} (Python \& R): The
  most comprehensive for SSH researchers, with direct support for text
  mining and topic modeling workflows, R/Python interoperability,
  consistency measures, and visualizations tmtoolkit.
\item
  \href{https://github.com/MaartenGr/BERTopic}{BERTopic}: Semantic
  embedding + clustering for advanced thematic discovery. Ideal when
  corpora require advanced semantic processing and non-trivial topic
  detection.
\item
  \href{http://mallet.cs.umass.edu}{MALLET}: High-scale LDA
  implementations in Java.
\item
  \href{https://scikit-learn.org}{scikit-learn} +
  \href{https://radimrehurek.com/gensim}{Gensim}: Effective combination
  for educational or grassroots projects, with large community and
  established workflows.
\item
  \href{https://infranodus.com}{InfraNodus}: Recommended if you want
  exploratory visualizations, semantic maps, and narrative analysis.
\item
  \href{https://github.com/ddangelov/Top2Vec}{Top2Vec}: Combine document
  embedding and topic modeling, automatically detect the number of
  topics. Useful in exploratory phases where the thematic structure is
  not known a priori.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{{Some tools (e.g.~Top2Vec, InfraNodus) are less well-established in
mainstream SSH methodology, but are valuable when used critically.Tools
such as BERTopic are based on newer technologies (semantic embedding),
therefore they require more attention in the interpretation
phase.Performance varies based on pre-processing quality and corpus
type. }}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2639}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.4861}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Tool / Model}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Type}
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\textbf{Recommended usage context}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
LDA (via Gensim / scikit-learn) & Probabilistic topic modeling &
Structured corpora, homogeneous language, standard thematic analysis \\
BERTopic & Semantic topic modeling & Complex corpora with semantic
variation, specialized or multidisciplinary discourse \\
Top2Vec & Unsupervised embedding-based topic modeling & Preliminary
exploration of large text corpora, automatic topic count detection \\
MALLET & Gibbs sampling topic modeling & Large-scale datasets requiring
high computational efficiency \\
InfraNodus & Network visualization and analysis & Exploratory phase,
narrative or cultural analysis, conceptual mapping \\
tmtoolkit & Integrated analytical toolkit & Pre-processing, coherence
evaluation, end-to-end Python workflow \\
spaCy & NLP library & Tokenization, lemmatization, syntactic parsing \\
\end{longtable}

\subsection{1.5 Guidelines for use in SSH
Projects}\label{guidelines-for-use-in-ssh-projects}

The use of topic modeling and text mining techniques in the contexts of
SSH requires the \emph{adoption of a series of methodological measures
that guarantee the quality, transparency and reproducibility of the
analyses}.\\
The main aspects to consider include:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  Textual pre-processing phase.\\
  The preliminary processing of textual data is a necessary condition
  for the reliability of the results. Operations such as
  \emph{tokenization, elimination of stopwords, lemmatization and
  lexical normalization} must be carried out rigorously and explicitly
  documented. Tools such as \href{https://spacy.io/}{spaCy} (for
  language processing) and tmtoolkit (for integrated management of
  analytical pipelines) allow you to automate these steps, reducing the
  variability introduced by manual interventions.
\item
  Model selection and appropriateness with respect to the corpus.\\
  The choice of the topic modeling algorithm must be consistent with the
  \emph{nature of the corpus} and with the \emph{analytical objectives
  of the project}. Traditional probabilistic models such as LDA,
  available through libraries such as Gensim or scikit-learn, are
  appropriate for well-structured and linguistically homogeneous corpus
  analyses. Models based on semantic embeddings (e.g.~BERTopic, Top2Vec)
  offer greater sensitivity to lexical nuances and are suitable for
  complex corpora or corpora characterized by high discursive
  variability. In computationally intensive scenarios, tools such as
  MALLET stand out for their efficiency and scalability. For research
  oriented towards the networked visualization of emerging topics,
  InfraNodus provides an innovative interface useful for the exploratory
  phase.
\item
  Evaluation of the quality of the model.\\
  The quality of the results cannot be taken for granted and requires a
  multi-level evaluation. From a quantitative point of view, it is
  advisable to use thematic consistency metrics
  \href{https://aclanthology.org/D11-1024.pdf}{Mimno, Wallach et
  al.,2011}, many of which are implemented directly in tmtoolkit.
  However, these metrics must always be accompanied by
  \textbf{qualitative validation by the researcher, based on the
  critical reading of the topics and their interpretability with respect
  to the theoretical context and the empirical field of reference}.
\end{enumerate}

\subsubsection{References}\label{references}

\emph{General references on topic modeling and text mining}\\
\textgreater{} See:
\href{https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf}{Blei, D.
M., Ng, A. Y., \& Jordan, M. I. (2003). Latent dirichlet allocation.
Journal of machine Learning research, 3(Jan), 993-1022.}\\
➤ \emph{The foundational paper on the LDA model, the theoretical basis
for most of the current topic modeling}.\\
\textgreater{} See: \href{https://doi.org/10.1093/pan/mps028}{Grimmer,
J., \& Stewart, B. M. (2013). Text as data: The promise and pitfalls of
automatic content analysis methods for political texts. Political
analysis, 21(3), 267-297.}\\
➤ \emph{Excellent methodological overview of the use of text mining in
political and social sciences}.\\
\textgreater{} See:
\href{https://proceedings.neurips.cc/paper_files/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html}{Chang,
J., Gerrish, S., Wang, C., Boyd-Graber, J., \& Blei, D. (2009). Reading
tea leaves: How humans interpret topic models. Advances in neural
information processing systems, 22.}\\
➤ \emph{The paper introduces new quantitative methods, validated by
large studies with users, to measure the semantic significance of topics
extracted from probabilistic topic models}.

\emph{Technical references and specific tools}\\
\textgreater{} See:
\href{https://is.muni.cz/repo/884893/lrec2010-rehurek-sojka.pdf}{Řehůřek,
R., \& Sojka, P. (2010). Software framework for topic modelling with
large corpora.}\\
\textgreater{} See:
\href{https://doi.org/10.48550/arXiv.2008.09470}{Angelov, D. (2020).
Top2vec: Distributed representations of topics. arXiv preprint
arXiv:2008.09470.}\\
\textgreater{} See:
\href{https://doi.org/10.48550/arXiv.2203.05794}{Grootendorst, M.
(2022). BERTopic: Neural topic modeling with a class-based TF-IDF
procedure. arXiv preprint arXiv:2203.05794.}

\emph{Recommended for courses or self-training}\\
\textgreater{} See:
\href{https://doi.org/10.1007/s10439-023-03272-4}{Jockers, M. L. (2013).
Macroanalysis: Digital methods and literary history. University of
Illinois Press.}\\
➤ \emph{Application of topic modeling and other digital techniques in
the humanities}.\\
\textgreater{} See:
\href{http://dx.doi.org/10.18637/jss.v083.b01}{Silge, J., Robinson, D.,
\& Robinson, D. (2017). Text mining with R: A tidy approach (p.~194).
Boston (MA): O'reilly}\\
➤ \emph{Introductory but comprehensive, widely used for teaching in
digital humanities courses}.

\section{2. Assisted Qualitative Analysis: Automatic Coding and
Sentiment
Analysis}\label{assisted-qualitative-analysis-automatic-coding-and-sentiment-analysis-1}

The use of AI tools in qualitative analysis is progressively changing
the way textual material is processed and interpreted in the SSH
context. Qualitative analysis assisted by NLP tools can \emph{expand the
scale and efficiency of analytical work}, but requires a \textbf{high
level of methodological control, transparency in operational choices and
critical reflection on the results produced}. Two relevant applications
in this area are automatic \textbf{content coding} and \textbf{sentiment
analysis}, both intended as forms of support, and not a replacement, for
the researcher's interpretative activity.

\subsection{2.1 Automatic Coding}\label{automatic-coding}

It consists of assigning labels or thematic categories to segments of
text based on learned rules (through supervised training) or lexical
correspondences (unsupervised approaches).\\
This is particularly useful in projects based on \emph{interviews, focus
groups, testimonials, or open-ended responses}, where the analyst has to
handle large volumes of data.\\
Tools such as \emph{spaCy, tmtoolkit} or \emph{Transformers by
HuggingFace} allow you to automate the semantic annotation phase,
facilitating the construction of replicable and systematic encodings.
However, analytical validity depends on the precision of the models and
the consistency between the categories produced and the theoretical
framework of reference.

\textbf{References}:\\
\textgreater{} See: Saldana, J. (2025). The Coding Manual for
Qualitative Researchers. SAGE Publications Limited\\
➤ \emph{Theoretical-methodological manual for qualitative coding, with
reflections on automatic integration}.\\
\textgreater{} See: \href{https://doi.org/10.21105/joss.00774}{Benoit,
K., Watanabe, K., Wang, H., Nulty, P., Obeng, A., Müller, S., \& Matsuo,
A. (2018). quanteda: An R package for the quantitative analysis of
textual data. Journal of Open Source Software, 3(30), 774-774. 8}\\
➤ \emph{R tool that supports complete workflows for text encoding and
classification}.

\subsection{2.2 Sentiment Analysis}\label{sentiment-analysis}

Traditionally more widespread in commercial fields, it now also finds
relevant applications in social research. It makes it possible to
identify the emotional or evaluative polarity expressed in the texts
(positive, negative, neutral), or to detect more complex emotions
(anger, trust, anxiety, etc.).\\
Classical sentiment analysis methods are based on predefined
dictionaries of words marked with polarity (e.g.~\emph{``happy'' → +1,
``disappointed'' → -1}).\\
More recently, models based on neural networks (e.g.~\emph{BERT,
\href{https://doi.org/10.48550/arXiv.1907.11692}{RoBERTa}}) are able to
grasp polarity by considering the semantic context of the sentence, with
greater robustness on long or ambiguous texts.\\
Tools such as \href{https://doi.org/10.4224/21270984}{NRC Emotion
Lexicon} or
\href{https://hal.univ-grenoble-alpes.fr/hal-02526412v1/document}{EmoLex}
allow you to detect complex emotions (joy, fear, anger, trust\ldots),
not just positive or negative feelings.\\
This approach is useful for the analysis of narratives, testimonies or
political speeches, in which the affective dimension is articulated in a
more nuanced way. In \emph{qualitative research}, it can be used to
analyze attitudes towards social phenomena, public policies,
institutions or public figures, in contexts such as social media,
interviews or historical archives.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Warning}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

However, it should be emphasized that sentiment analysis, in particular,
suffers from linguistic ambiguities, irony, and dependence on the
textual domain. For this reason, many studies recommend its triangulated
use: as a support for manual analysis, as a preliminary exploratory
filter or as an integrated technique in mixed designs.

\end{tcolorbox}

\textbf{References}:\\
\textgreater{} See:
\href{https://doi.org/10.1111/j.1467-8640.2012.00460.x}{Mohammad, S. M.,
\& Turney, P. D. (2013). Crowdsourcing a word--emotion association
lexicon. Computational intelligence, 29(3), 436-465. 8}\\
\textgreater{} See: \href{http://dx.doi.org/10.1561/1500000011}{Pang,
B., \& Lee, L. (2008). Opinion mining and sentiment analysis.
Foundations and Trends® in information retrieval, 2(1--2), 1-135.}

\chapter{3. Multilevel translation and linguistic adaptation for
academic
environments}\label{multilevel-translation-and-linguistic-adaptation-for-academic-environments-1}

The use of advanced language models in the academic field is not limited
to the generation of original content, but finds increasing application
in the multi-level reformulation and translation of texts intended for
scie\emph{ntific publications, calls for papers, project proposals or
specialized dissemination materials}.\\
The concept of multilevel translation here refers to the ability to
transform content on multiple levels: \emph{linguistic, stylistic,
cultural and rhetorical}.\\
In the \textbf{SSH context}, this translates into the possibility of
adapting a text for different audiences (\emph{editorial boards, funding
bodies, general public}) while maintaining the conceptual integrity of
the content.\\
Unlike traditional machine translation, which is limited to
word-for-word linguistic transfer,GAI enables adaptive interventions on
the text---modulating register, tone, and argumentative cohesion.\\
This makes it possible to transform an informal draft into a version
that complies with the rhetorical and stylistic standards expected in
international settings, for example when preparing \emph{abstracts,
letters of intent, scholarly articles, or competitive grant proposals}.
In multilingual and collaborative contexts, the use of LLMs can support
non-native English authors by providing lexical suggestions, stylistic
reformulations, and terminology-consistent translations aligned with the
discipline's specialized vocabulary. Some tools, such as \emph{DeepL
Write}, \emph{ChatGPT-4}, or \emph{Claude}, allow you to handle
progressive rewrites with control over tone (\emph{formal/informal,
concise/explanatory}) and level of specificity.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

From an operational standpoint, the most effective approach combines
\textbf{generative AI with the researcher's critical review}, following
a co-authoring model that ensures both efficiency and epistemological
oversight. It is also advisable to document any substantial AI-assisted
interventions---particularly during editorial revision or peer
review---to maintain scientific transparency.

\end{tcolorbox}

\chapter{4. Practical Examples and Implementation
Scenarios.}\label{practical-examples-and-implementation-scenarios.}

The adoption of \textbf{GAI tools in SSH research} does not end in the
exploratory or writing support phase, but finds concrete application in
a variety of methodological and design contexts.\\
Below are some emblematic use scenarios, taken from documented research
experiences or in the experimental phase.

\textbf{a) Automated Qualitative Analysis}\\
- \emph{Interview transcription and summarisation}: automatic
transcription of audio and video interview recordings, producing text
organized according to themes that emerge during the conversation.\\
- \emph{Thematic coding}: use of AI to identify and organize predominant
themes across large collections of qualitative texts (e.g.,
\emph{diaries, memoirs, interviews}).

\textbf{b) Source exploration and correlation}\\
- \emph{Historiographical or literary research}: use of AI to analyze
digitized archives, suggesting linkages among historical sources,
annotations, and alternative document interpretations.\\
- \emph{Pattern detection in sources}: us of AI to highlight trends or
anomalies in collected data (e.g., \emph{temporal clusters, recurring
themes), thereby facilitating the formulation of new research
questions}.

\textbf{c) Survey instrument design}\\
- \emph{Questionnaire generation}: assist in drafting survey items and
questionnaire questions by proposing inclusive wording and plausible
response options tailored to the target population.\\
- \emph{Dynamic survey personalization}: adapt question order, phrasing,
and layout in real time based on participants' previous responses.

\textbf{d) Social Media Analysis}\\
- \emph{Online discussion summarization}: use of AI to condense large
volumes of social media conversations into concise overviews, isolating
prevailing opinions and emergent topics.\\
- \emph{Sentiment Analysis}: automatically detect emotions and polarity
in public debates on social or political issues.

\textbf{e) Automated content production}\\
- \emph{Scientific article summaries}: generate abstracts or automated
reviews from collections of publications on a given topic.\\
- \emph{Educational materials}: create tailored lecture notes, quiz
items, or interactive simulations designed for student learning or
broader public outreach.

\textbf{f) Research dissemination and public engagement}\\
- \emph{Custom case-study creation}: produce practical examples or
role-play scenarios that reflect real or hypothetical situations to
explore social, psychological, or educational dynamics.\\
- \emph{Data simplification and accessibility}: translate complex data
into accessible outputs for non-specialist audiences, thereby enhancing
comprehension and dissemination of research findings.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\textbf{Bibliographic references}

\begin{quote}
See: \href{http://dx.doi.org/10.1016/j.isci.2024.110192}{Ho, E.,
Schneider, M., Somanath, S. et al (2024). Sentiment and semantic
analysis: Urban quality inference using machine learning algorithms.
iScience, 27(7).}\\
See: \href{https://aclanthology.org/2021.nlp4dh-1.pdf}{Proceedings of
the Workshop on Natural Language Processing for Digital Humanities
(NLP4DH), December 16-19, 2021, Silchar, India. ©2021 NLP Association of
India (NLPAI)}\\
See: Jockers, M. L. (2013). Macroanalysis: Digital methods and literary
history. University of Illinois Press.\\
\textgreater{} See:
\href{https://doi.org/10.1371/journal.pone.0276367}{Rozado D, Hughes R,
Halberstadt J (2022) Longitudinal analysis of sentiment and emotion in
news media headlines using automated labelling with Transformer language
models. PLOS ONE 17(10): e0276367}
\end{quote}

\chapter{Artificial Intelligence for Academic Writing: Strategies,
Applications, and
Limitations}\label{artificial-intelligence-for-academic-writing-strategies-applications-and-limitations}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{First Draft Generation: Title, Abstract,
Introduction}\label{first-draft-generation-title-abstract-introduction}

\paragraph{Co-editing and Stylistic
Refinement}\label{co-editing-and-stylistic-refinement}

\paragraph{Guided Drafting for calls and grants: example
prompts}\label{guided-drafting-for-calls-and-grants-example-prompts}

\end{tcolorbox}

\section{1. Integration of LLM-based Tools in academic
writing}\label{integration-of-llm-based-tools-in-academic-writing}

The integration of tools based on advanced language models (LLMs) into
academic writing is significantly transforming the practices of
scientific composition, from exploratory phases to text production.\\
Although writing remains an irreplaceable skill in the process of
knowledge construction, AI can be employed as a \textbf{co-authorial
tool} to assist researchers with specific tasks, while maintaining human
control over content and argumentation.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={Transparency and traceability in the use of AI in academic contexts}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

In recent years, the use of GAI in the production of scientific content
has raised significant issues regarding research \emph{ethics},
\emph{authorship attribution} and \emph{methodological transparency}.\\
As a result, several International Institutions, Funding Agencies, and
Scientific Journals \textbf{have issued guidelines that recommend---or
in some cases mandate---explicit disclosure of the use of automated
language models such as ChatGPT within research outputs}.

\end{tcolorbox}

\subsubsection{Key Policies and
Guidelines}\label{key-policies-and-guidelines}

The main legislative and regulatory references include:

\begin{itemize}
\item
  \textbf{COPE -- Committee on Publication Ethics}\\
  It published a guideline in 2023 stating that authors should clearly
  state whether, how and at what stage of writing they used AI tools,
  specifying that models cannot be credited as co-authors.
  (\href{https://doi.org/10.24318/cCVRZBms}{COPE position -- Authorship
  and AI, 2023}
\item
  \textbf{European University Institute (EUI)}\\
  The 2024 document \emph{Guidelines for the Responsible Use of AI in
  Research} requires that any substantial use of AI in the writing,
  summarizing or editing of academic texts must be explicitly
  documented, at least in metadata, acknowledgments, or a dedicated
  methodological section.
  (\href{https://www.eui.eu/Documents/ServicesAdmin/DeanOfStudies/ResearchEthics/2024.06-Ethics-Commitee-EUI-GENAI-DIGITAL.pdf}{EUI
  Ethics Committee 2024}
\item
  \textbf{Nature, Science, Springer, Elsevier}\\
  Leading international scientific journals, including \emph{Nature},
  \emph{Science} and \emph{Elsevier}, prohibit the attribution of
  co-authorship to AI models and require, in methods or
  acknowledgements, a technical note specifying whether parts of the
  text (e.g., abstract, bibliography, reformulations) were generated or
  assisted through LLMs tools.
\item
  \textbf{European Funding Bodies
  (e.g.~\href{https://erc.europa.eu/homepage}{ERC},
  \href{https://commission.europa.eu/funding-tenders/find-funding/eu-funding-programmes/horizon-europe_en}{Horizon
  Europe},
  \href{https://marie-sklodowska-curie-actions.ec.europa.eu}{MSCA -
  Marie Skłodowska‑Curie}})\\
  While not yet enforcing strict rules, some funding agencies include
  the disclosure of automated tools used in the preparation of proposals
  within ethical guidelines, in line with FAIR (\emph{Findable,
  Accessible, Interoperable, Reusable}) principles and the European Code
  of Conduct for Research Integrity
  (\href{https://allea.org/portfolio-item/european-code-of-conduct-2023/}{ALLEA
  2023}.)
\end{itemize}

In this scenario, the use of AI for academic writing \textbf{cannot be
considered neutral or implicitly accepted}: \emph{researchers must
transparently state the extent and nature of technological involvement,
clarifying whether AI served as linguistic support, a paraphrasing tool,
or contributed to the generation of structured portions of the text}.

This new responsibility reflects a broader transformation in
traceability criteria within contemporary scientific research, where
tools---as well as results---are subject to \textbf{accountability}.
(\href{https://doi.org/10.1007/s00146-023-01635-y}{Novelli, Taddeo,
Floridi, AI \& Society, 2024)}.

\subsection{\texorpdfstring{1.1 Generation of the `\emph{First Draft}':
title, abstract,
introduction}{1.1 Generation of the `First Draft': title, abstract, introduction}}\label{generation-of-the-first-draft-title-abstract-introduction}

The elaboration of a \emph{first draft} constitutes one of the most
critical and often burdensome phases of the academic writing process.\\
In this context, GAI can offer significant support by facilitating the
initiation of text production through the automated generation of
initial drafts related to standardized sections of a scientific article,
such as the \emph{title, abstract, and introduction}.\\
This intervention is configured as a form of \textbf{structural assisted
writing}, in which the model does not provide conceptually autonomous
content but proposes plausible textual templates based on data provided
by the user, such as \emph{disciplinary field, research objective,
employed methodology, or research question}.

For example:

\begin{itemize}
\item
  For a \textbf{title}, AI can suggest alternatives with varying degrees
  of specificity, synthesis and attractiveness, while respecting
  disciplinary style conventions.
\item
  For an \textbf{abstract}, generation can follow predefined structures
  (e.g.,
  \href{https://libguides.umn.edu/StructureResearchPaper}{IMRaD}), or
  adapt to specific calls (e.g., Horizon Europe, ERC), incorporating key
  elements: \emph{problem, methodology, expected results, and
  implications}.
\item
  For an \textbf{introduction}, AI can assist in setting up a
  logical-argumentative sequence, articulating the relevance of the
  topic, a synthetic state of the art, and an initial statement of the
  objectives or hypothesis.
\end{itemize}

The value of an AI-generated \emph{first draft} does not lie in its
final quality---which generally remains inferior to that produced by an
experienced researcher---but rather in its heuristic and propulsive
function: it helps overcome the initial creative block, offers a textual
skeleton to work from, and suggests coherent linguistic structures, also
useful for non-native authors.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{It must be emphasized, however, that the automatic first draft should be
considered an unvalidated product, subject to full scientific and
stylistic revision.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

The greatest risk is the generation of text that is formally plausible
but conceptually vacuous (\emph{synthetic plausibility}), which may
include generic statements, theoretical gaps or fabricated
citations*(``\textbf{hallucinations}'').

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{Therefore, the use of a first draft must be accompanied by
metalinguistic and methodological skills that enable the researcher to
critically assess its epistemic coherence, rhetorical adequacy, and
disciplinary relevance.}\vspace{3mm}

\end{tcolorbox}

\subsubsection{Comparison diagram of first draft with AI and by the
researcher's}\label{comparison-diagram-of-first-draft-with-ai-and-by-the-researchers}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2316}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3729}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3955}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Aspect}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{AI-Generated First Draft}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Researcher-Reviewed Version}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\emph{Argumentative structure } & Formally coherent, but tends to be
generic & Coherent with the project's theoretical and logical
framework \\
\emph{Disciplinary vocabulary } & Adequate in general terms, but often
superficial & Aligned with the vocabulary of the specific discipline \\
\emph{Consistency with the research project} & Risk of irrelevant
generalizations & Aligned with objectives, context, and research
questions \\
\emph{Methodological accuracy} & Standard methodological descriptions,
not contextualized & Accurate, with reference to methods actually
used \\
\emph{Style and linguistic register} & Uniform and readable, but not
always discipline-appropriate & Tailored to the target (journal, grant
call, academic audience) \\
\emph{Citations and references} & Sometimes missing or generated
imprecisely & Properly inserted and verifiable \\
\emph{Originality of contribution} & Low: tends to reproduce frequent
and neutral patterns & Explicit articulation of the original
contribution to the literature \\
\end{longtable}

\subsection{1.2 Key differences between AI-generated drafts and
researcher-reviewed academic
writing}\label{key-differences-between-ai-generated-drafts-and-researcher-reviewed-academic-writing}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \textbf{Argumentative Structure}\\
  The AI‐generated draft often reproduces standard rhetorical patterns
  but frequently lacks conceptual grounding. The revised version
  establishes a logically coherent structure aligned with the project's
  hypothesis and theoretical framework.
\item
  \textbf{Disciplinary Language}\\
  Although language models mimic an academic register, they tend to rely
  on generic or overused terms. The researcher refines the vocabulary to
  adhere strictly to the conventions and epistemological precision
  required by the discipline.
\item
  \textbf{Alignment with Research Design}\\
  The AI draft may introduce unwarranted generalizations or assumptions.
  Human revision restores internal consistency by confining the text to
  the actual objectives, methods, and research questions of the study.
\item
  \textbf{Methodological Accuracy}\\
  AI often defaults to generic methodological descriptions (e.g.,
  ``qualitative interviews,'' ``thematic analysis'') without contextual
  detail. The researcher amends these sections to reflect the specific
  methodological choices actually employed.
\item
  \textbf{Stylistic Appropriateness}\\
  While the automated draft is syntactically fluent, its tone is
  stylistically neutral. The human editor introduces modulations of
  register, emphasis, and tone according to the target audience (e.g.,
  scholarly journal readers, funding panel, academic committee).
\item
  \textbf{Citations and Source Integrity}\\
  Models can omit references or generate them inaccurately. The
  researcher verifies each citation's accuracy and integrates all
  sources coherently into the narrative.
\item
  \textbf{Originality of Contribution}\\
  AI outputs tend to default to safe, conventional formulations. The
  researcher highlights the original contribution, theoretical novelty,
  or methodological innovation that distinguishes the work.
\end{enumerate}

\subsection{2. Co-editing and stylistic refinement: advanced linguistic
assistance in academic
writing}\label{co-editing-and-stylistic-refinement-advanced-linguistic-assistance-in-academic-writing}

Beyond the automatic generation of content, one of the most impactful
applications of AI in scholarly writing lies in the \textbf{co-editing
phase}, understood as targeted support for the linguistic and rhetorical
polishing of pre-existing text.\\
In this role, AI does not function as an autonomous knowledge generator
but as a \textbf{parametric editorial assistant}, capable of
\emph{proposing localized revisions or comprehensive reformulations
depending on the usage context and communicative objectives}.

Co-editing proves especially effective in two critical sections of
academic production: the methodological description and the
discussion.\\
In the \emph{methodological section}, AI can enhance expository clarity
by eliminating lexical ambiguities and smoothing the presentation of
adopted methods and techniques.\\
In the \emph{discussion section}, it can facilitate the articulation of
inferences and the linkage between results, literature and theoretical
implications---thereby improving argumentative coherence and syntactic
readability.

Advanced assisted writing tools allow users to parameterize the
rewriting process by specifying desired levels of \emph{formality},
\emph{target length}, \emph{scientific register} or \emph{communicative
tone} (e.g., assertive, descriptive, popular).\\
This makes the AI intervention highly adaptable to different
communication contexts, whether preparing a peer-review journal
abstract, a public presentation, or a policy brief for institutional
stakeholders.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{It is, however, essential that these operations not be regarded as
neutral automations: every AI-generated suggestion must undergo critical
evaluation, taking into account conceptual consistency, terminological
fidelity, and adherence to the original communicative intent.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

The collaboration between author and system must remain reflective and
deliberate, ensuring human oversight over argumentative density,
epistemic alignment, and the rhetorical identity of the text.

\end{tcolorbox}

\subsubsection{Operational features of automated
co-editing}\label{operational-features-of-automated-co-editing}

The AI platforms available today for academia offer a growing range of
advanced features.

It's notable to remember:

\begin{itemize}
\item
  \textbf{Controlled rewriting (\emph{constrained paraphrasing})}: the
  user can request rewrites with specific stylistic or rhetorical
  constraints, such as increased conciseness, variation in tone or
  translation from technical to popular language. This feature is useful
  for adapting the same content to \emph{different audiences} (e.g.,
  specialist journal, European call, internal communiqué).
\item
  \textbf{Selective synthesis}: AI is able to detect redundant or
  excessively dense passages-for example, verbose methodological
  sections or scattershot theoretical descriptions-and propose a more
  essential version, while maintaining informational relevance and
  respecting any editorial space constraints.
\item
  \textbf{Textual cohesion and logical transitions}: by analyzing
  thematic and rhetorical progression, the system can suggest the
  addition or modification of connectives, transitions, and textual
  markers, improving the internal fluency of academic discourse,
  especially in texts intended for international reviewers or in
  multilingual contexts.
\end{itemize}

\subsection{3. Guided drafting for calls and grants: examples of
applicable
prompts}\label{guided-drafting-for-calls-and-grants-examples-of-applicable-prompts}

The use of LLMs in the \emph{drafting phase of project proposals},
\emph{application forms} or \emph{grant abstracts} is today one of the
most strategic areas for the academic and competitive research sector.\\
These tools are configured as \textbf{semi-automatic writing
assistants}, capable of generating preliminary versions (\emph{first
drafts}) of complex textual sections, starting from suitably calibrated
prompts. This functionality is particularly effective in supporting
strategic writing, that is, writing geared toward calls with specific
formal and rhetorical requirements, where \emph{clarity of objectives},
\emph{measurability of impacts}, \emph{methodological relevance}, and
\emph{compliance with the language of the funder} are decisive elements.

\paragraph{Structured prompts: how to drive textual
generation}\label{structured-prompts-how-to-drive-textual-generation}

The effectiveness of the result depends largely on the \textbf{quality}
and \textbf{accuracy} of the prompt.\\
The following are some effective prompts in \textbf{grant
writing}:\footnote{\emph{Grant writing is the structured process of
  writing a project proposal aimed at obtaining funding from public
  bodies, private foundations, international organizations, or research
  agencies. It is a highly specialized form of writing, combining
  rhetorical, design, normative and strategic skills.\\
  Operationally, grant writing is not limited to writing the text, but
  also involves: - the analysis of the relevant call for proposals and
  its eligibility and evaluation criteria; - the ability to translate a
  scientific idea into a clear and convincing project narrative; - the
  structuring of content according to predefined formats (e.g.,
  abstract, state of the art, methodology, impacts, budget, work
  packages); - the adaptation of style and vocabulary to the
  expectations of the funding body (policy-driven, evidence-based,
  stakeholder-oriented).\\
  In academia, grant writing is a strategic cross-cutting skill, as it
  conditions access to resources critical to research, career, and
  scientific visibility. The ability to write effective proposals is now
  considered, for all intents and purposes, an integral part of the
  researcher profile, particularly in national and international
  competitive contexts (e.g., Horizon Europe, ERC, Marie Skłodowska
  Curie, PRIN, PNRR)}.}

✏️ Prompt for project title definition (concise and focused)\\
\emph{``Propose five possible titles for a European project exploring
the impact of digital platforms on youth political participation. The
title should be short, clear, evocative and suitable for a Horizon
Europe call''}

✏️ Prompt for generating project abstract (\emph{first draft})\\
\emph{``Write an abstract of up to 250 words for a project that aims to
promote social cohesion through digital interventions in marginalized
urban settings. The text should include objectives, methodological
approach, expected impacts and relevance to the call.''}

✏️ Prompt for academic calls (e.g., ERC, Marie Skłodowska-Curie)\\
\emph{``Draft a scholarly synthesis for an MSCA application studying the
building of language capital among migrants and educational institutions
in Europe. The text should be consistent with the European format and
use a formal but accessible tone.''}

✏️ Prompt for methodological sections\\
\emph{``Reformat this methodological paragraph (paste text) in a more
technical way, with academic vocabulary, while maintaining clarity and
avoiding redundancy. Specify that this is a qualitative design based on
semi-structured interviews.''}

✏️ Prompt for language adaptation\\
\emph{``Rewrite this text (paste) in formal academic English, suitable
for a submission in the humanities. Maintain conceptual precision and
disciplinary vocabulary, avoiding literal translations.''}

✏️ Prompt for call for paper or announcement\\
\emph{``Draft a short description (max 250 words) for a call for paper
on ``Ethics and AI in Social Research.'' The paper should attract
theoretical and empirical contributions, with an authoritative and
inclusive tone.''}

\subsection{3.1 Ethical considerations and statement of
use.}\label{ethical-considerations-and-statement-of-use.}

It is also essential to distinguish between \textbf{linguistic
assistance} and the \textbf{generation of original scientific content}:
only the former can be delegated, while the construction of the
argumentation, the selection of sources, and the definition of the
thesis remain tasks proper to scientific authorship.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Usage considerations}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

It is essential to remember that these texts should not be considered
final products, but \textbf{intermediate working tools}: drafts on which
to critically intervene to correct, deepen, position.\\
In addition, templates can be gradually ``trained'' to better meet user
needs through iterative prompts and progressive refinements of context
(e.g., \emph{by providing pre-written sections or bullet points with
project data}).\\
The use of AI in academic writing, particularly in evaluation (grant,
peer review), requires \textbf{methodological transparency}.\\
It is recommended to state, in the methodological notes or metadata of
the proposal, the possible use of AI tools, especially when intervening
in substantial stages of writing.

\end{tcolorbox}

\subsection{Tools for academic
writing}\label{tools-for-academic-writing}

🔎 \href{https://jenni.ai/it/for-researchers}{JENNI}\\
🔎 \href{https://rytr.me/}{RYTR}\\
🔎 \href{https://www.scalenut.com/}{SCALENUT}\\
🔎 \href{https://www.jasper.ai/}{JASPER}\\
🔎 \href{https://prowritingaid.com/}{PROWRITINGAID}\\
🔎 \href{https://textcortex.com/en}{TEXTCORTEX}\\
🔎 \href{https://quillbot.com/}{QUILLBOT}\\
🔎 \href{https://www.hyperwriteai.com/}{HYPERWRITEAI}\\
🔎 \href{https://www.copy.ai/}{COPY}\\
🔎 \href{https://paperpal.com/home}{PAPERPAL}

\subsubsection{Comparison of the features of the suggested
tools}\label{comparison-of-the-features-of-the-suggested-tools}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1071}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2214}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1786}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.3143}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1786}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Tool}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Free Plan/Trial Available}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Supported Languages}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Best for}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Access Type}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rytr & Free plan & More than 30 languages & Plagiarism and coherence
check & Web, Chrome extension \\
Scalenut & Free trial & English only & Thesis rewriting and editing &
Web \\
Jenni AI & Free plan & Multiple languages & Creative writing solutions &
Web \\
Jasper AI & Free trial & More than 30 languages & Multilingual thesis
writing & Web \\
ProWritingAid & Free plan & English only & Citations and references &
Web, browser extensions \\
TextCortex & Free trial & More than 25 languages & Strengthening
arguments & Web, Chrome extension \\
Writesonic & Free trial & More than 25 languages & Advanced thesis
writing with GPT-4 & Web \\
Quillbot & Free plan & More than 30 languages & Language refinement and
enhancement & Web, extensions \\
HyperWriteAI & Free trial & Any language & Thesis rewriting and editing
& Web \\
Copy.ai & Free trial & More than 30 languages & Thesis generation and
argument enhancement & Web \\
Paperpal & Free version & More than 30 languages & Academic translations
and coherence check & Web, MS Word add-in \\
\end{longtable}

\subsection{References}\label{references-1}

\begin{quote}
See: \href{https://doi.org/10.1093/jamia/ocae139}{Pividori M, Greene CS.
(2024) A publishing infrastructure for Artificial Intelligence
(AI)-assisted academic authoring.}.\\
See: \href{https://www.nature.com/articles/d41586-025-01463-8}{Kwon, D.
(2025). Is it OK for AI to write science papers? Nature survey shows
researchers are split.}\\
See: \href{https://doi.org/10.1186/s13054-023-04380-2.}{Salvagno M,
Taccone FS, Gerli AG. (2023) Can artificial intelligence help for
scientific writing?} See:
\href{https://doi.org/10.1016/j.cmpbup.2024.100145}{Khalifa, M., \&
Albadawy, M. (2024). Using artificial intelligence in academic writing
and research: An essential productivity tool. Computer Methods and
Programs in Biomedicine Update, 5, 100145.}\\
See: \href{https://doi.org/10.1080/08989621.2023.2168535}{Hosseini, M.,
Rasmussen, L. M., \& Resnik, D. B. (2023). Using AI to write scholarly
publications. Accountability in Research}\\
See: \href{https://doi.org/10.1186/s13040-023-00339-9}{Meyer, JG,
Urbanowicz, RJ, Martin, PCN et al.(2023)ChatGPT and large language
models in academia: opportunities and challenges.}\\
See: \href{https://doi.org/10.1016/j.softx.2024.101784}{Godwin, R. C.,
DeBerry, J. J., Wagener, B. M., Berkowitz, D. E., \& Melvin, R. L.
(2024). Grant drafting support with guided generative AI software.}\\
See: \href{https://doi.org/10.1145/3641237.3691693}{Kasierski, B., \&
Fagnano, E. (2024, October). Optimizing the Grant Writing Process: A
Framework for Creating a Grant Writing Assistant Using ChatGPT 4.}\\
See: \href{https://doi.org/10.18231/j.ijlsit.2024.003}{Panda, S., \&
Kaur, D. N. (2024). Exploring the role of generative AI in academia:
Opportunities and challenges}
\end{quote}

\section{\texorpdfstring{}{ }}\label{section}

\chapter{Mapping the Workflow of an Academic Paper: Integrating AI at
Every
Stage}\label{mapping-the-workflow-of-an-academic-paper-integrating-ai-at-every-stage}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Introduction: why a systemic approach to AI
use}\label{introduction-why-a-systemic-approach-to-ai-use}

\paragraph{Stages of academic writing and corresponding AI
``touchpoints''}\label{stages-of-academic-writing-and-corresponding-ai-touchpoints}

\paragraph{Step-by-step case studies: practical AI applications in the
editorial
workflow}\label{step-by-step-case-studies-practical-ai-applications-in-the-editorial-workflow}

\paragraph{From map to method: recommendations for researcher
autonomy}\label{from-map-to-method-recommendations-for-researcher-autonomy}

\end{tcolorbox}

\section{1. Introduction: why a systemic approach to AI
use}\label{introduction-why-a-systemic-approach-to-ai-use-1}

Integrating GAI into scholarly writing --- given its capabilities,
limitations, and constraints --- cannot be reduced to the occasional use
of stand-alone tools.\\
The proliferation of applications that \emph{automate}, \emph{assist} or
\emph{augment} various phases of scientific production demands a
\textbf{comprehensive methodological reflection} on the overall
structure of intellectual work. In research, especially within the
Social Sciences and Humanities (SSH), writing is not merely a final step
but a cognitive device through which analytical results are
consolidated, articulated, and debated.\\
Accordingly, adopting LLM-based technologies capable of \emph{generating
text, reformulating concepts, synthesizing sources or suggesting
alternative phrasings} can fundamentally \textbf{reshape the editorial
process}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={Systematically mapping AI--writing interactions is essential to ensure
transparency, epistemological control, and effective valorization of the
human contribution.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

A systemic approach enables researchers to:

\begin{itemize}
\tightlist
\item
  Pinpoint where AI can be employed both effectively and responsibly\\
\item
  Avoid inappropriate delegation that risks originality or theoretical
  coherence\\
\item
  Develop a sustainable, replicable strategy guiding scholars from
  project design to final publication.
\end{itemize}

\section{2. Stages of academic writing and AI
``Touchpoints''}\label{stages-of-academic-writing-and-ai-touchpoints}

Academic writing unfolds as a multi-stage process rather than a single,
linear task. Each stage entails distinct \emph{cognitive, linguistic},
and \emph{organizational demands}, which can be supported --- if
methodologically integrated --- by AI tools.

A structured map of principal AI \textbf{``touchpoints''} across the
editorial workflow is given.\\
This section aims to provide a structured mapping of the main points of
interaction (`\textbf{touchpoints}') between GAI-based technologies and
the various stages of the academic writing process.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={When used critically and in context, these tools can support, optimise,
or strengthen scientific writing activities, while preserving the
irreplaceable role of theoretical reflection and epistemological control
by the researcher.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

The GAI should be integrated at \emph{specific points in the editorial
process}, with differentiated functions --- from suggestions to
assistance, partial automation or validation --- \textbf{avoiding a
totalising} or \textbf{automatic approach}. Its value lies in its
ability to intervene at targeted stages of the process, acting as a
methodological ally in the most critical or time-consuming steps,
without compromising scientific rigour.

The proposed structure adopts a \textbf{logical-procedural approach} and
is developed through 6 operational segments (\emph{editorial workflow}),
corresponding to \emph{six strategic junctures in the cycle of
elaboration and formalisation of the academic text}. It is a composite
process, and each step involves conceptual, operational and stylistic
choices.

Although these phases do not necessarily follow a strictly linear order
(as they may involve returns, revisions or restructuring), it is
possible to identify a \textbf{shared procedural grid} that allows the
writing cycle to be mapped from initial design to publication.

\subsection{a. Defining scope and formulating the research
question}\label{a.-defining-scope-and-formulating-the-research-question}

The first phase involves identifying the relevant subject area, defining
the \emph{research problem} and \emph{preliminarily structuring the
objectives}.\\
👉🏻 \emph{In this phase, AI can be useful as an exploratory tool for
generating provisional titles, summarising areas of interest that emerge
from the literature or comparing alternative formulations of the same
hypothesis}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{LLM-based tools can help refine search queries, provided that human
intervention is geared towards verifying their epistemological
consistency, originality and disciplinary relevance.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{b. Finding, selecting and summarising scientific
literature}\label{b.-finding-selecting-and-summarising-scientific-literature}

One of the fundamental components of academic writing is the
construction of a theoretical framework.

👉🏻 Recent applications of AI in the field of bibliography allow for the
automation, at least in part, of certain operations: \emph{searching for
primary and secondary sources, automatic extraction of abstracts and
keywords, construction of concept maps, identification of related or
contrasting studies}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{However, the critical selection of sources, the analysis of references
and the assessment of relevance to one's project remain highly cognitive
activities that cannot be delegated.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{c.~Planning the argumentative structure
(outline)}\label{c.-planning-the-argumentative-structure-outline}

Once the field of investigation has been defined and the bibliographic
material acquired, the text is structured by defining an outline.\\
This step requires the \emph{ability to logically organise the sections}
(e.g.~IMRaD or narrative structure), \emph{assign argumentative
functions to each paragraph} and \emph{anticipate consistency between
passages}.\\
👉🏻 \emph{AI can assist in generating outlines from a summary description
of the project, suggesting coherent internal structures}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{It is the researcher's responsibility to adapt the generated proposal to
the specifics of their theoretical and methodological framework.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{\texorpdfstring{d.~Composition of the \emph{first
draft}}{d.~Composition of the first draft}}\label{d.-composition-of-the-first-draft}

The drafting of the \emph{first draft} is the moment when analyses,
references and hypotheses are consolidated. Starting from refined
prompts, GAI allows you to obtain preliminary versions of text sections,
with a certain adherence to formal and structural criteria.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{However, it is essential to emphasise that the quality of the content
produced depends largely on the clarity of the input and the
researcher's ability to integrate, modify or reject what is proposed. In
this perspective, AI takes on the role of editorial assistant, not
author.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{e. Content review and stylistic
refinement}\label{e.-content-review-and-stylistic-refinement}

This fifth phase involves editing, rephrasing and improving
readability.\\
AI can be used to \emph{rephrase complex sentences, harmonise the
linguistic register, suggest logical transitions} or \emph{optimise
information density}.\\
Some tools also allow you to set specific parameters such as level of
formality, tone, length or type of audience.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{However, any proposed stylistic or syntactic changes must be evaluated
in relation to the function that the text performs within the scientific
discourse.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{f.~Final check and preparation for
submission}\label{f.-final-check-and-preparation-for-submission}

The final stage includes activities such as checking the accuracy of
citations, consistency between the text and bibliography, adaptation to
specific editorial styles (APA, MLA, Chicago, etc.), final linguistic
verification and, where applicable, adaptation of the text to the
standards required for submission.\\
GAI can also provide support to facilitate \emph{formal standardisation,
suggest target journals based on the content covered, and generate short
accompanying texts} (cover letters, abstracts for online submission).

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{Even at this stage, there is still a need for accurate human checking,
especially in highly formalised contexts.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\section{3. Step-by-step case studies: practical applications of AI in
the editorial
workflow}\label{step-by-step-case-studies-practical-applications-of-ai-in-the-editorial-workflow}

To encourage the informed adoption of GAI in the academic context, it is
useful to propose a \textbf{series of case studies}, each focusing on a
\emph{strategic moment in the writing cycle}.\\
These examples are not prescriptive models, but rather \emph{operational
scenarios that illustrate the potential applications of AI tools},
highlighting their advantages, limitations and optimal conditions of
use.\\
👉 Each case is presented as a sequence of operations with an indication
of the type of tool that can be used, the type of prompt or input
required, and the expected contribution to the production or revision of
the content.

\subsubsection{Case studies}\label{case-studies}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

1️⃣ -- \textbf{Automatic Extraction of Key SSH Articles}\\
\textbf{Objective}: Quickly identify an initial selection of relevant
sources to define the state of the art.\\
\textbf{Procedure}:\\
1. Query a semantic AI engine (e.g., \emph{Elicit, Scite Assistant})
with a natural-language prompt (e.g.,\emph{``Key debates on digital
inclusion in education''})\\
2. Evaluate returned items---titles, abstracts, reliability metrics\\
3. Manually confirm relevance; archive full texts.\\
\textbf{Output}: An initial systematic map of key sources, useful for
building the theoretical background.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

2️⃣ -- \textbf{Guided generation of structured outlines}\\
\textbf{Objective}: Build a coherent argumentative structure for the
scientific article, following the IMRaD format or equivalent.\\
\textbf{Procedure}:\\
1. Provide a prompt containing a provisional title, research objectives
and expected output type (e.g.~\emph{``Create an outline for an
empirical social science paper on X''}).\\
2. Request a division into sections (Introduction, Methods, Results,
Discussion) with brief descriptions of the contents of each.\\
3. Verify that the proposals are consistent with the research design and
adapt the structure according to the target (call for proposals,
journal, conference).\\
\textbf{Output}: Flexible outline, consistent with the editorial
standards of the discipline.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

3️⃣ -- \textbf{Draft introductory paragraph with critical review}\\
\textbf{Objective}: Produce a first draft of the introductory paragraph
to be used as a working basis.\\
\textbf{Procedure}:\\
1. Enter the main research questions, theoretical references and
empirical context into the prompt.\\
2. Request a controlled generation, indicating length, tone and level of
formality (e.g.~``Generate a formal academic introductory paragraph, max
150 words'').\\
3. Critically evaluate the text produced: relevance, quality of
vocabulary, accuracy of statements.\\
4. Modify, rewrite or integrate according to your own style and
theoretical framework.\\
\textbf{Output}: A text that is consistent in form, to be refined in
content to ensure originality and rigour.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

4️⃣ -- \textbf{Automatic verification of logical consistency between
sections}\\
\textbf{Objective}: Check the consistency between the introduction,
objectives and conclusions, highlighting any logical discrepancies or
redundancies.\\
\textbf{Procedure}:\\
1. Upload the partial or complete text to an AI environment (e.g.~Claude
or ChatGPT with document upload mode).\\
2. Enter a prompt such as: 'Assess whether the conclusions are
consistent with the objectives stated in the introductory section.
Indicate any omissions or inconsistencies.\\
3. Analyse the feedback provided and verify the validity of the
observations, adapting the relevant sections.\\
\textbf{Output}: Suggestions for strengthening the linearity of
argumentation and logical clarity of scientific texts.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

5️⃣ -- \textbf{Generation of a cover letter for submission to an academic
journal}.\\
\textbf{Objective}: Write a formal cover letter, in accordance with
editorial standards, to be sent together with the manuscript.\\
\textbf{Procedure}:\\
1. Enter the main data (article title, journal name, summary of the
contribution, authors' affiliations).\\
2. Request a formal cover letter, using a prompt such as: \emph{``Create
a cover letter for the submission of a scientific article in the field
of sociology, addressed to the editorial board of {[}journal
name{]}}.''\\
3. Review the proposed text, customising it according to the specifics
of the manuscript and the target journal.\\
\textbf{Output}: A concise, professional letter, consistent with
academic editorial practices.

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

6️⃣ -- \textbf{Stylistic adaptation of the text to an international
target audience}\\
\textbf{Objective}: Rewrite an article written in Italian into
standardised scientific English, suitable for international
publication.\\
\textbf{Procedure}:\\
1. Translate the text into English using specialised tools (e.g.~DeepL
Write, Papercup, Paperpal).\\
2. Enter selected sections of the text into the AI platform and indicate
the desired stylistic parameters: level of formality, length,
disciplinary terminology.\\
3. Review the proposals, checking for terminological accuracy, adherence
to international standards and syntactic fluency.\\
\textbf{Output}: A coherent and readable version in English, ready for
human proofreading or editorial review.

\end{tcolorbox}

\section{4. From map to method: recommendations for researcher
autonomy}\label{from-map-to-method-recommendations-for-researcher-autonomy-1}

The representation of touchpoints between AI and the editorial process
should not be understood as a simple descriptive diagram.\\
On the contrary, it represents the start of a methodological reflection
that needs to be translated into conscious and intentional operational
practices.\\
A map is useful insofar as it becomes a \textbf{method}: \emph{a
structured set of choices, procedures and checks that allow the
researcher to interact with AI tools in a manner consistent with the
principles of scientific research}.\\
From this perspective, the adoption of GAI cannot be interpreted as an
automatic delegation of editorial skills, but as an opportunity to
develop a new form of \textbf{epistemic agency}.\\
This agency refers to the \emph{ability of the research subject to
consciously, reflectively and responsibly guide the process of knowledge
production, selecting tools, interpreting data and evaluating content}
in light of explicit theoretical and methodological goals.\\
It implies critical autonomy in governing technical mediations, without
relinquishing conceptual and ethical control over one's scientific work.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{Epistemic agency is a form of cognitive responsibility that
distinguishes the producer of knowledge (the researcher) from a passive
executor of technical automatisms.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

It involves:\\
• \emph{not delegating the construction of scientific argumentation
entirely to AI or other external tools}\\
• \emph{knowing how to interpret and filter the information and
suggestions generated independently}\\
• \emph{preserving theoretical intentionality, i.e.~consistency between
operational choices and the cognitive objectives of the research}.

\end{tcolorbox}

This results in an active and reflective approach, based on a balance
between technical automation and theoretical control.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={GAI can play an advanced supporting role in scientific production only
if it is part of a solid methodological framework capable of preserving
the integrity, authorship and originality of scientific contributions.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

The challenge, therefore, is to transform the use of AI into a cognitive
alliance guided by methodological awareness, rather than a standardised,
opaque or disempowering process.\\
Only in this way will it be possible to integrate technological
innovation without compromising the critical and design value of
academic writing.

\end{tcolorbox}

\subsection{Recommendations}\label{recommendations}

❗️ \textbf{Esplicitare il ruolo dell'AI nel flusso di lavoro}\\
👉🏻 Annotare in quali fasi e per quali scopi si è ricorso a strumenti
generativi, contribuendo alla trasparenza metodologica.\\
\emph{Tale documentazione, integrata nel protocollo metodologico,
contribuisce a garantire la riproducibilità, la trasparenza e
l'integrità scientifica dell'elaborato, in linea con le raccomandazioni
dei principali enti di finanziamento e riviste peer-reviewed.}

❗️ \textbf{Valutare criticamente ogni output prodotto}\\
👉🏻 Nessun contenuto generato dall'AI dovrebbe essere accettato in modo
automatico, ma analizzato in termini di coerenza con il progetto,
adeguatezza scientifica e rigore formale.\\
\emph{L'adozione acritica di contenuti sintetici o stilisticamente
corretti, ma privi di profondità teorica o coerenza argomentativa, può
compromettere la qualità complessiva del testo e alterarne il valore
scientifico}.

❗️ \textbf{Coltivare l'ibridazione tra competenze tecniche e conoscenze
disciplinari}\\
👉🏻 Un uso efficace dell'AI nella scrittura accademica richiede una
doppia alfabetizzazione: da un lato, la familiarità con le logiche di
funzionamento dei modelli generativi (es. prompt design, temperature,
contesto), dall'altro, la padronanza delle convenzioni linguistiche e
argomentative della propria area di studio.\\
\emph{Solo attraverso questa integrazione il ricercatore può operare
scelte consapevoli, selezionare strumenti appropriati e orientare l'AI
verso risultati epistemicamente validi}.

❗️ \textbf{Garantire la tracciabilità delle revisioni}\\
👉🏻 È buona prassi mantenere un archivio delle modifiche apportate ai
contenuti generati dall'AI, indicando quali porzioni sono state
riscritte, adattate o validate.\\
\emph{Ciò consente non solo di conservare il controllo autoriale sul
testo, ma anche di ricostruire a posteriori il processo redazionale in
caso di valutazioni, revisioni o verifiche etiche. La tracciabilità si
configura, in questo senso, come un criterio fondamentale di
responsabilità scientifica e integrità editoriale}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{References}\label{references-2}

\begin{quote}
See: \href{https://doi.org/10.1001/jama.2023.12500}{Flanagin, A.,
Kendall-Taylor, J., \& Bibbins-Domingo, K. (2023). Guidance for Authors,
Peer Reviewers, and Editors on Use of AI, Language Models, and
Chatbots.}\\
See: \href{https://doi.org/10.37256/ser.6220256517}{Rodafinos, A.
(2025). The Integration of Generative AI Tools in Academic Writing:
Implications for Student Research.}\\
See: \href{https://doi.org/10.21608/ijeasou.2025.349520.1041}{Hanafi, A.
M., Al-mansi, M. M., \& Al-Sharif, O. A. (2025). Generative AI in
Academia: A Comprehensive Review of Applications and Implications for
the Research Process.}\\
See: \href{https://doi.org/10.46743/2160-3715/2024.7634}{Johnson, C. W.,
\& Paulus, T. (2024). Generating a Reflexive AI-Assisted Workflow for
Academic Writing.}\\
See: \href{https://doi.org/10.2991/978-94-6463-712-0_6}{Bairagi, M., \&
Lihitkar, S. R. (2025). Empowering Research Workflows and Information
Retrieval in Academic Libraries through AI Tools.}
\end{quote}

\part{Part 2: Advanced applications of AI in Research and Creativity}

\chapter{AI as a Creative Partner}\label{ai-as-a-creative-partner}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Advanced Brainstorming}\label{advanced-brainstorming}

\paragraph{Multi-Level Argumentative
Frameworks}\label{multi-level-argumentative-frameworks}

\paragraph{Step-by-step case studies: practical AI applications in the
editorial
workflow}\label{step-by-step-case-studies-practical-ai-applications-in-the-editorial-workflow-1}

\end{tcolorbox}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\section{1. Advanced Brainstorming}\label{advanced-brainstorming-1}

\subsection{1.1 Definition and Potential of Advanced
Prompting}\label{definition-and-potential-of-advanced-prompting}

The \textbf{brainstorming} stage is a strategic moment in research
design and development processes, permitting the initial exploration and
comparison of a wide spectrum of conceptual and operational
possibilities.\\
Generative AI (GAI) serves as a tool for \textbf{cognitive
amplification} by offering researchers original proposals based on
prompts composed in natural language.\\
The success of this procedure depends critically on the quality of the
prompt that is, on the \emph{precision and clarity of the textual
instructions provided to the model}.

We refer to \textbf{advanced prompting} when the input text incorporates
structural elements that guide the model towards a targeted and relevant
output.\\
Specifically, a meticulously constructed prompt details:\\
- The \textbf{objective} of the proposal\\
- The \textbf{method} envisaged for its implementation\\
- The \textbf{expected impact} within the application context.

This methodological approach transcends generic or unguided
brainstorming, steering the AI--researcher interaction towards a
structured co-design process rooted in clear aims and explicit
methodological criteria.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Advanced prompting thus functions as an epistemic instrument, orienting
the model to produce conceptually rigorous and operationally viable
outcomes.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{1.2 Practical Application}\label{practical-application}

Structured advanced brainstorming involves directing the AI
(e.g.~\emph{ChatGPT}) to generate ideas within strategic parameters,
using precise instructions that channel its creative capacities.\\
This is not free-form or arbitrary ideation but a focused and purposeful
exercise.

\textbf{a.} An advanced prompt does not simply request ``ideas'' but it
\emph{formulates a composite query} specifying:\\
- The \textbf{theme or problem} (e.g.~\emph{the central concept under
investigation})\\
- The \textbf{constraints} (e.g.~\emph{budgetary limits, available
tools, contextual boundaries})\\
- The \textbf{role} (e.g.~\emph{``respond as a researcher specialising
in social pedagogy''}).

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={This compels the AI to \emph{produce pertinent and inventive proposals}
within a defined framework, akin to a genuine design workshop.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\textbf{b.} Upon submission of the \emph{carefully crafted prompt}, the
AI returns a series of proposals, which may include:\\
- An original research question\\
- A feasible pilot project - A novel theoretical hypothesis\\
- A hybrid methodological approach.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={In effect, this mirrors \emph{traditional brainstorming} but is enhanced
by the model's capacity to synthesise vast sources, registers, and
logical structures.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\textbf{c.} As part of an \emph{iterative dialogue}, the researcher can
then:\\
- Select and elaborate on particular ideas\\
- Request alternative proposals\\
- Impose new constraints (e.g.~\emph{``Exclude approaches already
detailed in the literature'', ``Focus only on qualitative-visual
methods''})\\
- Combine multiple suggestions.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Thus a dynamic, generative conversation unfolds between researcher and
AI---reminiscent of peer brainstorming but conducted at high speed with
great diversity.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\emph{In this way, AI becomes a co-designer, generating hypotheses,
scenarios, and strategies that enrich the researcher's repertoire and
stimulate critical reflection}.

\end{tcolorbox}

\subsection{1.3 Construction of prompts with objective, method and
expected
impact}\label{construction-of-prompts-with-objective-method-and-expected-impact}

When using GAI to generate project ideas or research questions, the
\textbf{formulation of the prompt} is a crucial step.

A prompt is not a simple question, but a strategic linguistic artefact,
whose effectiveness depends on the user's ability to translate a project
intention into understandable and stimulating textual instructions for
the model.

A particularly \textbf{effective structure} for generating relevant and
coherent content involves articulating the prompt into three fundamental
components:

1️⃣ \textbf{Objective}\\
\emph{Definition of the purpose of the proposal to be generated}.

It can be educational (e.g.~\emph{promoting critical thinking in primary
school}), social (e.g.~\emph{promoting the inclusion of students with
special educational needs}), technological (e.g.~\emph{experimenting
with immersive environments for subject teaching}) or scientific
(e.g.~\emph{exploring new variables in qualitative research}).

👉🏻 The objective clarifies the general purpose towards which the
generation of ideas should be directed, semantically delimiting the
model's field of action.

2️⃣ \textbf{Method}\\
\emph{Illustration of the operational process or methodology to be used
to achieve the objective.}

This may refer to pedagogical strategies (e.g.~\emph{project-based
learning, flipped classroom, gamification}), research approaches
(e.g.~\emph{case study, participant observation, controlled
experimentation}) or theoretical models (e.g.~\emph{situated learning
theory, socio-constructivist approach}).

👉🏻 Including the method in the prompt allows the model to structure
proposals according to a consistent procedural logic, facilitating
executive design.

3️⃣ \textbf{Expected impact}\\
\emph{Define the desired effects of the proposal in educational,
cognitive, social or scientific terms.}

This may refer, for example, to improving engagement, developing
cross-cutting skills, generating new empirical data or validating
theoretical hypotheses.

👉🏻 Specifying the impact encourages the model to generate proposals that
are not only formally consistent but also geared towards an explicit
transformative goal.

\hl{The integration of these three elements within the prompt results in
a more precise semantic definition, allowing the model \emph{to produce
higher quality outputs} that are better aligned with specific contexts
of use. This structure also facilitates the \emph{replicability of the
process}, paving the way for a systematisation of human-machine
interaction in the design field.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title={For example, a prompt structured according to this logic could be as
follows:}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

👉🏻 \emph{``Generate three project ideas for lower secondary school with
the aim of developing digital citizenship skills, using the debate
methodology, with the expected impact of improving critical thinking and
peer argumentation.''}\\
\textbf{Through a prompt of this type, the model is able to propose
solutions that integrate educational objectives, operational tools and
training goals, transforming automatic generation into a guided and
dialogical process.}

\end{tcolorbox}

\subsection{1.4 Types of prompts for generating new
ideas}\label{types-of-prompts-for-generating-new-ideas}

Once they have acquired expertise in formulating structured prompts,
users are able to consciously select from different types of prompts,
each designed to stimulate specific forms of creative generation by the
GAI.\\
The choice of prompt type must be calibrated in relation to the design
requirements, the cognitive processes involved and the exploratory
nature of the task.\\
The targeted adoption of these different modes of interaction allows the
automatic generation to be directed towards specific goals, activating a
dialogical process between AI and human design thinking.

\hl{The ability to select the most appropriate type of prompt for the
context is, in this sense, an indicator of methodological maturity in
the strategic use of artificial intelligence as a creative partner.}

Among the main types of prompts:

🔍 \textbf{Exploratory prompts}\\
Exploratory prompts are designed to increase the conceptual
possibilities on a given topic.\\
They are used in the initial phase of a project or when you want to gain
a broad, flexible and unconventional overview of the options
available.\\
These prompts stimulate AI to generate divergent ideas, going beyond
habitual cognitive paths.

✏️ Example:\\
\emph{``Identify and describe five unconventional theoretical frameworks
or methodological approaches through which to explore the relationship
between environmental education and social justice in school contexts.
Explicitly exclude standard curricular approaches and favour critical,
decolonial or situated paradigms.''}

🧬 \textbf{Transformative prompts}\\
This category of prompts aims to reformulate established practices in an
innovative way.\\
AI is guided towards reconfiguring existing models in order to produce
original solutions based on already known elements.\\
Transformative prompts are particularly useful in contexts of
pedagogical innovation.

✏️ Example:\\
\emph{``Critically rethink the flipped classroom model in light of
educational inequalities linked to the digital divide, with particular
reference to marginalised or fragile school contexts. Develop a
theoretical-methodological proposal that, while maintaining the
dialogical and participatory structure of the original model, transforms
its operating methods to make it culturally sensitive, accessible and
applicable in the absence of stable digital infrastructure.''}

⁉️ \textbf{Hypothetical or conditional prompts}\\
Hypothetical prompts invite the model to explore imaginary scenarios or
contexts that do not yet exist, which are useful for building conceptual
prototypes or anticipating emerging problems.\\
Their strength lies in their ability to activate lateral thinking and
mental simulation.

✏️ Example:\\
\emph{``Imagine a completely decentralised university system, with no
physical locations and based exclusively on immersive environments and
artificial intelligence technologies. What pedagogical models,
evaluation criteria and social interaction devices should be developed
to ensure the fairness, quality and sustainability of the educational
path?''}

⚖️ \textbf{Comparative prompts}\\
Comparative prompts require the model to compare approaches, tools or
strategies, highlighting their advantages, limitations and possible
hybridisations.\\
This type of instruction is useful for stimulating analytical thinking
and identifying areas for improvement in existing models.

✏️ Example:\\
\emph{``Compare the effectiveness of the phenomenological and
experimental approaches in studying the subjective experience of
learning in digital contexts. Highlight strengths, methodological
limitations, and possibilities for integration into a mixed research
design.''}

⛓ \textbf{Restrictive prompts}\\
In some cases, the originality of proposals emerges despite -- or thanks
to -- a series of imposed constraints.\\
Restrictive prompts limit the scope of AI, imposing strict conditions
that force it to come up with novel solutions.\\
This mode is useful for testing creativity under pressure or in contexts
with limited resources.

✏️ Example:\\
\emph{``Design an interdisciplinary research project on the theme of
energy transition, to be carried out in a context with low technological
access, no connectivity and extremely limited economic resources
(maximum budget: £100). Indicate objectives, method, data collection
tools and potential impacts.''}

\subsection{1.5 Practical applications: advanced research,
interdisciplinary design, academic
innovation}\label{practical-applications-advanced-research-interdisciplinary-design-academic-innovation}

The use of advanced prompting in research is not a theoretical exercise
for its own sake, but a strategic tool for stimulating the generation of
hypotheses, tracing design paths and anticipating theoretical and
methodological choices.\\
LLMs, in particular, can support the exploratory phase by expanding the
possibilities for investigation and promoting a critical reorganisation
of the initial paradigms.

In the Academic and Post-Doctoral context, GAI can be used to:

\begin{itemize}
\tightlist
\item
  \textbf{explore} new interdisciplinary configurations, for example by
  formulating hypotheses of contamination between sociological,
  pedagogical and critical technology studies approaches;\\
\item
  \textbf{generate} original research questions based on emerging and
  ambiguous themes that are difficult to address using traditional
  disciplinary logic;\\
\item
  \textbf{simulate} a preliminary mapping of the state of the art,
  highlighting gaps, theoretical overlaps and areas that have not yet
  been systematically addressed;\\
\item
  \textbf{produce} methodological design proposals compatible with field
  constraints, ethnographic contexts, marginal populations or fluid
  digital environments;\\
\item
  \textbf{generate} impact scenarios or speculative hypotheses useful
  for the design of interdisciplinary grants, including in a foresight
  or anticipatory key.
\end{itemize}

The conscious use of prompting also allows the conceptual soundness of a
project proposal to be tested, encouraging comparison between
alternative options and stimulating the reformulation of weak or
implicit passages.

\hl{In this context, AI does not produce knowledge, but organises raw
materials, theoretical languages and hypotheses of connection between
domains of knowledge, acting as a dialogical and generative tool.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={The effectiveness of the interaction depends on the epistemological
maturity of the researcher, who remains responsible for selecting,
validating and transforming the proposals generated. In this sense,
advanced prompting is a cross-cutting skill of high strategic value,
destined to become established in contemporary research as a reflective,
project-based and productive practice.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsubsection{Examples of disciplinary use of
prompting}\label{examples-of-disciplinary-use-of-prompting}

• \textsc{Sociology}\\
Generation of alternative scenarios based on complex qualitative
datasets (interviews, ethnographic observations), or exploration of
hypotheses of correlation between emerging social phenomena
(e.g.~\emph{technologies and inequalities}) from an intersectional
perspective.

• \textsc{History}.\\
Simulation of divergent interpretations of controversial events;
hypotheses for reinterpreting sources according to alternative
theoretical paradigms (e.g.~\emph{environmental history, history from
below}); exploration of the methodological implications of microhistory
in the digital age.

• \textsc{Education sciences}\\
Design of innovative training devices for marginal contexts; exploration
of the educational implications of AI in non-school environments;
hybridisation between critical pedagogies and transformative approaches.

• \textsc{Philosophy}\\
Generation of questions based on contemporary ethical dilemmas related
to artificial intelligence, the posthuman, or deep ecology; comparison
between schools of thought on notions such as autonomy, intelligence,
responsibility.

• \textsc{Cultural studies and media studies}\\
Critical reformulation of key concepts (\emph{identity, agency,
representation}) in the context of digital cultures and algorithms;
simulation of discursive analyses based on multimodal media corpora.

\section{2. Multi-Level Argumentative
Schemes}\label{multi-level-argumentative-schemes}

\subsection{2.1 Text mapping: concepts, relationships and
hierarchies}\label{text-mapping-concepts-relationships-and-hierarchies}

The \emph{representation} and \emph{organisation} of ideas are a
fundamental component in the processes of design, academic writing and
critical thinking. In this context, GAI can be used to \textbf{create
textual concept maps} that can convey the semantic complexity of a topic
or research question in a structured form.

Unlike traditional graphic maps, \textbf{multi-level textual mapping} is
organised into a hierarchical structure of nodes, expressed through
natural language and organised according to levels of depth.

\includegraphics[width=1\linewidth,height=\textheight,keepaspectratio]{images/exmap.png}

Example of a multilevel text mapping scheme

The main node represents the generative idea or central theme; sub-nodes
derive from it, explaining thematic articulations, implications, related
variables, counter-arguments or application examples. The entire map is
configured as an orderly network of logical and semantic relationships,
useful for both theoretical reflection and operational planning.

\hl{GAI is capable of generating this structure from a simple prompt,
provided that the instruction accurately indicates the mapping objective
and the desired level of articulation.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The result can be used in a variety of contexts: designing teaching
units, structuring scientific articles, defining project proposals,
analysing complex issues.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

✏️ Prompt example to generate a multi-level text map:\\
\emph{``As a model language, your main task is to generate a multi-level
text map on the following topic: '{[}Insert topic{]}''. Organise the map
according to this structure: the first node is the central topic; the
first-level nodes represent the main categories; the second-level nodes
contain insights, examples or implications. If necessary, you can add
additional levels.''}

\subsection{2.2 Instructional strategies for developing text
maps}\label{instructional-strategies-for-developing-text-maps}

In order for GAI to generate effective mapping, the user must provide a
prompt with clear, structured, and conscious instructions.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title={The quality of the prompt plays a decisive role in guiding the model's
output towards a coherent, organised form that is functional for its
intended use.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

In particular, it is useful to specify:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  the \textbf{central theme} to be developed
\item
  the \textbf{type of conceptual relationships} to be highlighted
  (\emph{causes, effects, implications, alternatives, etc.})
\item
  the \textbf{level of depth} required for each conceptual node.
\end{enumerate}

✏️ Prompt examples:

\emph{``Develop a multi-level textual map from the concept of
{[}topic{]}, detailing objectives, pedagogical strategies, digital
tools, and potential challenges.''}.

\emph{``Organise the topic of digital citizenship education into a
multi-level textual structure, distinguishing between theoretical
principles, practical applications in schools and ethical
implications.''}

This type of instruction allows the model to generate a map organised
according to logical criteria, reflecting systemic thinking patterns.\\
Furthermore, the flexibility of natural language allows elements typical
of concept maps, such as hierarchies and relationships, to be combined
with elements typical of academic outlines (argumentative sequences,
levels of detail, examples).\\
The request for textual mapping can be repeated iteratively, prompting
the model to refine the structure, add nodes, propose counter-arguments
or make explicit any interconnections between concepts.\\
In this way, the map is not a static product, but an evolving artefact,
generated through a cyclical interaction between human and machine.
Furthermore, automatic text mapping serves a dual function: on the one
hand, it allows for rapid exploration of the possible articulations of a
concept; on the other, it promotes the consolidation of knowledge
through the reformulation and systematisation of the generated content.

\subsection{2.3 Iteration and dialogue with the model: refinement of
patterns}\label{iteration-and-dialogue-with-the-model-refinement-of-patterns}

The construction of multi-level argumentative schemes through the use of
GAI is not limited to a single automatic generation, but is configured
-- as is often the case with other requests -- as an \textbf{iterative}
and \textbf{dialogical process}.\\
The user does not simply passively receive the generated map, but can
(and must) actively interact with the model, prompting it to rework,
deepen, clarify or restructure the content produced.\\
This interaction develops through a sequence of successive prompts that
progressively improve the quality of the initial request.

Requests can usually be:

• \textsc{\textbf{Expansion}}: the user can ask the model to elaborate
on a specific sub-node:

✏️ \emph{``Elaborate on the ``digital tools'' node within the
multi-level text map on formative assessment. Include concrete examples,
emerging methodologies, and comparative application contexts.''}

• \textsc{\textbf{Clarification}}: the user can detect conceptual
ambiguities or generic formulations, asking the model to rephrase or
specify:

✏️ \emph{``Rephrase the explanation regarding the distinction between
``teaching strategies'' and ``assessment methods'', improving
terminological precision and internal consistency.''}

• \textsc{\textbf{Reorganisation}}: if the structure is weak from a
logical or hierarchical point of view, it is possible to request a new
articulation of the nodes:

✏️ \emph{``Restructure the hierarchical map by assigning three main
conceptual axes: theoretical, operational and critical, and redistribute
the second-level nodes according to this logic.''}

• \textsc{\textbf{Comparison}}: to enrich the map, the user can prompt
the model to integrate alternative points of view or competing
approaches:

✏️ \emph{``Integrate sections dedicated to critical perspectives,
emerging alternative approaches and hybrid models with respect to
dominant digital skills into the map on digital citizenship.''}

\hl{Through these successive interactions, the textual map becomes
progressively more robust, coherent and articulated, transforming itself
from a simple thematic list into a true argumentative structure.}

\subsubsection{Iterative prompt engineering: epistemic
cycle}\label{iterative-prompt-engineering-epistemic-cycle}

The coordinated sequence of prompts aimed at expansion, clarification,
reorganisation and comparative analysis transforms interaction with AI
into an \textbf{advanced epistemic process}.\\
It is a model in which the user does not simply receive output, but
iteratively designs, tests and refines content according to criteria of
academic rigour.

\textbf{The cyclical flow}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Thematic expansion\\
  The user asks the model to detail specific conceptual nodes, enriching
  them with concrete examples, comparative contexts or disciplinary
  references.
\item
  Semantic clarification\\
  Potential ambiguities, reformulations or terminologically weak
  concepts are addressed, increasing precision and internal consistency.
\item
  Logical-structural reorganisation\\
  If hierarchical weaknesses emerge, a conceptual redistribution
  consistent with new thematic axes or narrative levels is required.
\item
  Comparison and plurality of perspectives\\
  The model is invited to integrate alternative perspectives, critical
  approaches or emerging voices, enriching the map with plurality of
  arguments.
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={This prompt-driven mode allows an initial draft to be transformed into a
robust argumentative structure, which progressively evolves in terms of
consistency, completeness and depth.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{2.4 Argumentative structures: causes, effects, implications,
limitations}\label{argumentative-structures-causes-effects-implications-limitations}

One of the most significant uses of GAI in the construction of
multi-level textual schemas is the possibility of developing actual
argumentative structures, organised according to logical and relational
categories.

In this case, the textual map is not limited to representing a
conceptual taxonomy, but takes the form of an \textbf{articulated
discursive organisation}, useful for supporting a thesis, exploring a
problem or structuring a critical analysis.

It is possible to orient the model from the outset towards a defined
argumentative grid, for example:

\begin{itemize}
\tightlist
\item
  Causes: structural factors that generate the phenomenon under study\\
\item
  Effects: observed or predicted consequences\\
\item
  Implications: ethical, social, political, pedagogical or technological
  repercussions\\
\item
  Limitations: critical issues, constraints, potential grey areas.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={This structure is particularly useful in the design of academic texts,
scientific articles, research plans, educational interventions or
strategic documents.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

The user can specify the desired argumentative framework from the
outset, e.g.~in a prompt such as this:

✏️ \emph{``As an SSH researcher, generate a multi-level textual map on a
topic such as ``Environmental education and urban justice''. Articulate
the map according to structural causes, educational effects, social
implications and limitations. Respond in Markdown with a heavily
indented list and key points. Include references to critical paradigms
(e.g.~eco-pedagogy, postcolonialism).''}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={The model will return a coherent representation, capable of supporting
complex reasoning and serving as a basis for written or oral
elaboration.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

This mode promotes the development of critical thinking and awareness of
the problematic dimensions of the phenomenon analysed.\\
This approach generates a coherent and solid map, capable of supporting
complex discourse, that becomes both an argumentative support and a
basis for written constructions or oral presentations.\\
Multi-level mapping is inspired by established practices in Social
Science and Humanities (SSH) research, reflecting formal approaches to
academic writing (APA, MHRA, Turabian) and
\href{https://odannyboy.medium.com/notes-on-donald-sh\%C3\%B6ns-the-reflective-practitioner-e67f753879d8}{Donald
Schön}'s models of reflective practice.

\begin{quote}
See \href{https://doi.org/10.4324/9781315237473}{Schön, D. A. (2017).
The reflective practitioner: How professionals think in action}
\end{quote}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The critical treatment of logical structures through the textual map
activates a deep metacognitive process.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\textsc{\textbf{For Researchers}}

The multi-level textual map allows you to systematically explain complex
relationships between causes, effects, implications and future
prospects.\\
This structure is particularly useful for:\\
- \emph{systematically explaining complex relationships between causes,
effects and implications}\\
- \emph{designing chapters of theses and academic articles}\\
- \emph{building funding proposals (grants)}\\
- \emph{organising complex theoretical and methodological structures}.

\textsc{\textbf{For Metacognitive Activities}} (\emph{Students and
Doctoral Candidates})

Incorporating argumentative maps into training exercises promotes:\\
- \emph{the critical reformulation of existing maps}\\
- \emph{the production of interdisciplinary counter-maps}\\
- \emph{the comparison of competing theoretical positions}.

👉🏻 \textbf{These activities promote genuine reflection on the process of
thinking and planning, which is essential in advanced SSH courses}.

\section{3. Self-feedback on generated
content}\label{self-feedback-on-generated-content}

One of the most promising developments in GAI is the possibility of
using language models not only for content production, but also for
internal and iterative critical evaluation.\\
\textbf{Self-feedback}, also known as \emph{self-evaluation}, is a way
of using LLMs that goes beyond mere text generation, involving them in
the systematic critique of their own output.\\
Given clearly defined inputs, the model \emph{performs a
self-referential evaluation of previous outputs and suggests
improvements}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={In computational terms, LLMs do not possess metacognitive awareness, but
they can simulate evaluative processes through the generation of texts
that take the form of critical commentary, review or reasoned
comparison.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

Self-feedback activates a \textbf{reflective chain}: the model analyses
its own output against specific criteria (e.g.~\emph{consistency,
clarity, originality}), generates an internal review, and proposes an
improved version.\\
This cycle of judging--reformulating--judging transforms initial content
into more robust outputs, without the need for
\href{https://platform.openai.com/docs/guides/model-optimization}{fine-tuning}.
This type of output, if well trained, can constitute a first level of
analysis useful for improving the communicative effectiveness, internal
consistency, and originality of the materials generated.

\hl{From an educational and scientific point of view, self-feedback
represents a significant innovation: it introduces an evaluative
instance within the generative interaction itself, enabling a virtuous
cycle of production-reflection-reformulation.}

\subsection{3.1 Main techniques and
evidence}\label{main-techniques-and-evidence}

\textbf{a. Self Refine (Iterative Refinement with Self Feedback)}

The \emph{Self Refine} technique involves a LLM generating an initial
output, critically evaluating it against defined criteria, and then
reformulating it in an \textbf{iterative cycle}: \emph{generate →
feedback → refine}.\\
All this is done with the same model, without the need for supervised
data or a fine-tuning phase.\\
Each iteration keeps \emph{track of the output + feedback history},
which the model draws on to avoid repetition and constantly improve.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Experimental evaluations on GPT 3.5 and GPT 4 show an average
improvement of about 20\% over one-step generation on over seven types
of tasks (reasoning, responses, rewriting)
\href{https://arxiv.org/abs/2303.17651?utm_source=chatgpt.com}{See
article}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

✏️ Prompt example:\\
\emph{``Review the following paragraph according to academic criteria of
terminological accuracy and argumentative rigour. Propose a reworded
sentence that is clearer and more coherent.''}

\textbf{b. Self-Critique Guided Reasoning}

In this strategy, the model guides its own reasoning with \textbf{chain
of thought} steps followed by \emph{critical self-evaluation}.\\
This promotes conceptual consistency, logical precision, and the
reduction of significant omissions.\\
It is useful in complex contexts where internal consistency is crucial.
\href{https://promptengineering.org/llms-learn-humility-how-self-critique-improves-logic-and-reasoning-in-llms-like-chatgpt/?utm_source=chatgpt.com}{See
article}

✏️ Prompt example:\\
\emph{``You have just generated a text/project. Now analyse it
critically. Indicate at least three points of possible improvement in
terms of logical consistency and original content.''}

\textbf{c.~Auto-evaluation (LLM-as-a-Judge)}

Here, the model takes on the \textbf{role of an impartial authority}: it
evaluates output according to explicit disciplinary criteria
(\emph{logical consistency, relevance, accuracy, originality, clarity}),
assigning a score and generating structured feedback.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Studies applied in customer service scenarios show that the
LLM-as-a-Judge approach improves the quality of responses by over 8\%,
with a correlation 3--5 times higher than standard prompts.
\href{https://www.evidentlyai.com/llm-guide/llm-as-a-judge}{See Article
1} and
\href{https://cameronrwolfe.substack.com/p/llm-as-a-judge?utm_source=chatgpt.com}{Article
2}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

✏️ Prompt example:\\
This prompt can be used to monitor and standardise the reliability of
automatic interaction in SSH writing contexts.\\
\emph{``You are an expert academic evaluator. Your task is to judge the
quality of the following output produced by an AI model in response to a
research question. Base your assessment on the following criteria:
logical consistency, relevance to the question, accuracy of data,
originality of reasoning, and clarity of presentation. Provide a score
from 1 to 5 (where 1 = very poor, 5 = excellent) followed by a
bullet-point summary of strengths and weaknesses.}. \emph{Research
question:}\\
\emph{\{input\}}\\
\emph{Model output:}\\
\emph{\{output\}}\\
\emph{Respond with:}\\
*Score: \_\_*\\
\emph{Bullet-point feedback:}\\
• \ldots``*

\textbf{d.~Self Restraint (ReSearch)}

The \textbf{ReSearch technique}, or \emph{self-restraint}, teaches the
model to independently detect its own uncertainty. Through a utility
function and an iterative self-prompting process, the model learns to
refrain from acting when it perceives low confidence.

👉🏻 This significantly reduces hallucinations on complex topics, without
additional inference costs.\\
\href{https://arxiv.org/abs/2405.13022?utm_source=chatgpt.com}{See
article}

✏️ Prompt example:\\
This prompt activates the ReSearch strategy: the model assesses its own
uncertainty and, if necessary, refrains from making predictions or
signals caution. In literature, this approach has been shown to
significantly reduce hallucinations without additional inference costs.
\href{https://arxiv.org/abs/2405.13022?utm_source=chatgpt.com}{See
article}

``\emph{You have just generated a section of theoretical analysis on a
complex interdisciplinary topic. Now critically analyse the text and
reflect on your level of confidence: if there are any uncertain or
potentially incorrect parts, abstract them (`I am not sure'; `I will not
answer'). Report:}\\
\emph{1. Areas where your knowledge is limited or uncertain.}\\
\emph{2. Parts that may be ambiguous or incorrect.}\\
\emph{3. Decision whether to continue or withdraw.}\\
\emph{Generated text:}\\
\emph{\{text\}}\\
\emph{Respond with a bulleted list:}\\
\emph{- Section \ldots{}}\\
\emph{- Confidence: high/medium/low}\\
\emph{- Notes on any errors or missing data}''

\subsection{3.2 Advantages in the SSH
context}\label{advantages-in-the-ssh-context}

\textbf{a. Strengthening internal consistency and originality}

Prompts geared towards internal verification of argumentative sequences
help identify logical gaps, hidden contradictions and misalignments
between objectives and expected results.\\
One of the most important aspects in evaluating a text, whether it is a
project, theoretical or argumentative, concerns its \textbf{internal
consistency}.\\
This term refers to the \emph{logical adherence between the parts of the
text}, the \emph{absence of obvious contradictions}, the \emph{linearity
of reasoning} and the \emph{congruence between stated objectives,
methods used and expected results}.

👉🏻 \emph{Through specific prompts, it is possible to ask the AI to
simulate an internal review of the text itself}.

✏️ Prompt examples:

\emph{``Analyse the following educational project and report any
inconsistencies between objectives, methodology and assessment tools.''}

\emph{``Check whether the following paragraphs are consistent with each
other from a logical and semantic point of view.''}

The model is able to detect structural misalignments, significant
omissions, redundant or ambiguous passages. Although it cannot guarantee
an infallible assessment, its pattern recognition capability allows it
to quickly identify the main formal critical issues, providing a
starting point for manual review.\\
In addition to consistency, a second fundamental evaluation axis
concerns the degree of \textbf{originality} of a proposal or content.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Although AI does not have direct access to up-to-date bibliographic
databases or an autonomous critical sense, it can be trained to compare
a proposal with common approaches, highlighting similarities,
repetitions or possible innovations*.

\end{tcolorbox}

✏️ Prompt examples:

\emph{``Assess how much the following project deviates from traditional
teaching models and indicate any innovative elements.''}

\emph{``Compare the proposed strategy with established educational
practices and point out how it differs.''}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

In response, the model can produce a structured analysis, highlighting
elements of originality (unprecedented combinations, emerging
applications, new contexts) or, conversely, pointing out excessive
similarity with pre-existing models.

\end{tcolorbox}

\textbf{b. Encouraging epistemic reflection}

Designing cycles in which AI suggests revisions involves reflecting on
one's own critical thinking: this is essential in SSH contexts in order
to develop robust methodological awareness.

✏️ Prompt Example 1: Critically review the output

This approach allows the model to assemble a true \emph{metacognitive
cycle}: it identifies gaps, implicit assumptions, reasons at the
epistemic level, and then proposes changes.\\
``\emph{You have just generated a paragraph (or section) on a research
topic. Reread it critically and answer these questions:}\\
\emph{- What implicit assumptions appear and need to be argued or
verified?}\\
\emph{- Which logical steps were unclear or ambiguous?}\\
\emph{- What alternative perspectives or theoretical approaches are
missing?}\\
\emph{- Suggest at least two methodological revisions or additions to
make the text more epistemically robust.}''

✏️ Prompt Example 2: Structured reflection for disciplinary and
comparative purposes

This framework is inspired by frameworks such as
\href{https://www.promptingguide.ai/techniques/reflexion}{Reflexion},
which structure verbalised feedback to reinforce critical skills in LLM
models, including in the epistemic-social context.\\
``\emph{Act as a reflective expert in the field of SSH. Analyse the text
provided in the following points:}\\
\emph{- What underlying theoretical paradigms emerge (explicitly or
implicitly)?}\\
\emph{- Are there any disciplinary biases or implicit ideological
orientations? Where?}\\
\emph{- How consistent is the argumentative position with known
theoretical sources?}\\
\emph{- Indicate two passages where an interdisciplinary or critical
approach could be useful and suggest additions.}''

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Why use these prompts?}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Both templates:\\
- guide the model to take an epistemic stance, not just a
technical-informative one;\\
- promote self-assessment that induces critical awareness of the
generated text;\\
- encourage interdisciplinary integration and the detection of implicit
biases.\\
👉🏻 \emph{You can use them in sequence (first A, then B) for a cycle of
progressive reflection: from logical gaps to disciplinary biases to
structured critical intervention}.

\end{tcolorbox}

\textbf{c.~Scalability and timeliness of feedback}

In collaborative learning or writing processes, AI can provide
personalised feedback in real time, overcoming limitations associated
with limited human resources
\href{https://doi.org/10.1016/j.caeai.2025.100450}{See article}

✏️ Prompt Example 1: Real-time feedback on text drafts.

Ideal for collaborative writing cycles: provides immediate feedback on
paragraphs or drafts, facilitating quick and effective revisions.\\
``\emph{Access the following text immediately and provide structured
feedback on:} \emph{- strengths}\\
\emph{- areas for improvement}\\
\emph{- practical suggestions for revision}\\
\emph{- any methodological or theoretical gaps}\\
\emph{Limit your response to approximately 300 words.}\\
\emph{Text to be evaluated: \{text\}}''

✏️ Prompt Example 2: Rapid assessment with disciplinary criteria

This approach is ideal for collaborative writing cycles in academia: it
allows for immediate feedback on drafts or paragraphs, facilitating
rapid and detailed revisions.\\
It is particularly useful for thesis sections, abstracts or funding
proposals in SSH disciplines, as it offers accurate and replicable
assessments with scientifically rigorous criteria.\\
``\emph{Analyse this paragraph/draft relating to {[}abstract/grant
title/thesis section title{]} according to the following criteria:}\\
\emph{- Consistency between objectives, content and conclusions.}\\
\emph{- Clarity of expression according to disciplinary vocabulary.}\\
\emph{- Originality compared to common writing in the field.}\\
\emph{- Conceptual relevance to the specified SSH context.}\\
\emph{- Respond in bullet points, indicating practical suggestions for a
quick revision}''

✏️ Prompt Example 3: Automated incremental improvement cycle

Great for SSH teaching based on iterative writing: immediate alternation
between feedback and rewriting to refine content.\\
``\emph{For the text provided}:\\
\emph{- Indicate 3 structural or conceptual issues}\\
\emph{- Suggest 3 specific rewrites to resolve them}\\
\emph{- Release a revised version (max 250 words)}\\
\emph{Format:}\\
\emph{- Pointed feedback}\\
\emph{- Revision proposals}\\
\emph{- New summary version}\\
\emph{Text to be revised: \{text\}}''

\textbf{d.~Critical support for reformulation}

\emph{`Self-Refine'} or \emph{`Self-Critique'} prompts help to
reorganise texts while keeping their content intact, but improving their
clarity and argumentative rigour.

✏️ Prompt Example 1 -- Self-Refine (Iterative Refinement with Self
Feedback)

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Note}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Studies indicate that this mode increases output quality by about 20\%,
without any external fine-tuning.

\end{tcolorbox}

``\emph{Examine the following paragraph and report any critical issues
from an argumentative, structural or stylistic point of view. Then
rewrite it incorporating the revisions:}\\
\emph{- Critical feedback}\\
\emph{- Reformulated, clearer and more coherent version}\\
\emph{Original paragraph:}\\
\emph{\{text}\}

✏️ Prompt Example 2 -- Self Critique Guided Reasoning

This mode reinforces conceptual consistency and reduces logical errors
through \emph{guided self-criticism}, in line with recognised practices
in advanced prompting.\\
``\emph{You have generated the following text on a complex academic
topic.}\\
\emph{Now: i)Indicate at least three possible weaknesses or ambiguities
(e.g., unclear reasoning, implicit assumptions, risky logical leaps).
ii)Suggest concrete revisions for each. iii) Finally, rephrase the
paragraph incorporating the suggested improvements.} \emph{Text:}\\
\emph{\{text\}''}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Both strategies can be used sequentially or independently, if the goal
is to review draft chapters, abstracts, articles, or research papers.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsection{3.3 Educational and Academic
applications}\label{educational-and-academic-applications}

In the field of advanced educational and academic applications, the
strategic integration of GAI effectively supports both teachers and
doctoral students in the SSH. Thanks to the use of asymmetric prompts
between production and internal evaluation, it is possible to design
\emph{multi-level argumentative maps, pedagogical analysis structures
and complex thesis chapters}, benefiting from automatic feedback support
that can assist the human author with methodological rigour and
epistemic continuity.\\
Similarly, the paradigm of automated self-evaluation proves to be
fundamental during learning and educational research: students and
doctoral candidates can submit individual sections, drafts or papers to
the AI.\\
The latter, guided by defined evaluation rubrics, identifies critical
issues, proposes structured revisions and transforms the simple
production of text into an active metacognitive experience, reinforcing
critical reflection and epistemic awareness.\\
Furthermore, the \textbf{synergistic combination of prompts} for
production and prompts dedicated to feedback generates an iterative flow
of qualitative improvement in outputs.

\hl{In this configuration, academic writing is no longer a solitary act,
but a continuous dialogue in which AI takes on the role of a
semi-autonomous interlocutor: it generates, evaluates, reformulates and
enriches content in close dialogue with the user. This mechanism is
similar to robust research methodologies, where scientific argumentation
is constructed through successive approximations, revisions, and
structural refinements.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The integration of automatic generation prompts and feedback allows for
an increase in the epistemic quality of written and design production in
the SSH field.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

The systematic application of this approach supports:\\
\emph{- reflective design (argumentative maps, articles, thesis
chapters) with automatic validation}\\
\emph{- a reflective and formative teaching practice, in which students
become autonomous in reviewing their own work}\\
\emph{- the strengthening of coherence, originality and rigour, thanks
to explicit cognitive cycles of generation, evaluation and progressive
reformulation}.\\
This model of interaction with AI respects and values the role of the
human researcher, acting as a true epistemic partner in the construction
of knowledge.

\end{tcolorbox}

\section{Further reading}\label{further-reading}

\begin{quote}
``\emph{In educational settings, self-generated feedback from LLM has
been shown to improve student writing performance and motivation
compared to static feedback}''.\\
\href{https://\%20learnprompting.org/docs/advanced/self_criticism/introduction?srsltid=AfmBOoryJ_qWnv1n-JgMDwS4MAnHyPgKHgyF5F0bHXmzA6ycc_8g-r6q&utm_source=chatgpt.com}{See
Article}\\
``\emph{A study has shown that LLM-driven feedback, when guided by
well-designed prompts, outperforms that of beginners and, in some
categories, even that of experts in the context of teacher training
education, offering faster and more specific feedback}''\\
\href{https://doi.org/10.3390/ai6020035}{See Article}\\
``\emph{The self-contrast paradigm has shown positive effects in
comparing divergent solutions generated by the same model, improving
stability and accuracy}''\\
\href{https://doi.org/10.48550/arXiv.2401.02009}{See Article}\\
``\emph{An analysis of over 2,600 users in tutor/student lessons shows
that LLM-on-demand explanatory feedback improves performance with
significant standardised effects (0.28--0.33), with equivalent response
times and high user satisfaction}''\\
\href{https://arxiv.org/pdf/2506.17006v1}{See Article}\\
``\emph{A systematic review highlights how automated GenAI feedback
systems reduce the teacher's workload, enabling effective cognitive and
emotional interventions, and improve educational interaction with
students in large-scale contexts}''\\
\href{https://doi.org/10.24059/olj.v28i3.4593}{See Article}
\end{quote}

\chapter{GAI as a Design support
tool}\label{gai-as-a-design-support-tool}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{GAI in the construction of the Research
Project}\label{gai-in-the-construction-of-the-research-project}

\paragraph{Structuring calls and grants with the support of
AI}\label{structuring-calls-and-grants-with-the-support-of-ai}

\end{tcolorbox}

\section{Introduction}\label{introduction-1}

In recent years, GAI has established itself in the world of research, in
a position not only as an operational tool, but also as a support for
\textbf{project planning}.\\
Its use goes far beyond automatic writing or text synthesis: it is at
the heart of the Academic process, contributing to the most delicate and
creative phase of \textbf{``planning''}.

In the Social Sciences and Humanities (SSH), where knowledge
construction involves \emph{language}, \emph{interpretation} and
\emph{interdisciplinarity}, AI does not offer definitive answers, but it
can:\\
- suggest \textbf{research directions} that are not immediately
visible\\
- help \textbf{clarify nuanced} or \textbf{theoretical concepts}\\
- offer \textbf{stylistic} and \textbf{structural variations}\\
- stimulate \textbf{new associations} between authors, currents or
approaches.

In these contexts, the value of AI moves away from technicalities and
becomes cognitive and dialogical, acting as a \textbf{generative
interlocutor} that \emph{relaunches}, \emph{expands} and
\emph{compares}.

Unlike STEM fields, where AI is often used to optimise quantitative
processes, analyse structured data or automate complex calculations, in
SSH its value is mainly evident in the \textbf{linguistic, exploratory}
and \textbf{conceptual} dimensions.\\
In these contexts, AI is not so much a tool for ``\emph{solving}'' as it
is for ``\emph{stimulating}'': it helps to generate ideas, formulate new
questions, refine theoretical vocabulary and compare methodological
approaches.\\
In the SSH, AI does not simplify a problem, but \emph{enriches the
thought process} surrounding it, becoming a \textbf{tool for amplifying
the researcher's abilities}, supporting the exploratory, generative and
compositional steps typical of Academic work in this area.

👉🏻 A concrete example is the use of \textbf{structured prompts}, which
allow for guided interaction with the linguistic model. Thanks to these,
it is possible to obtain proposals for research questions, formulations
of hypotheses, methodological alternatives, and even simulations of
different argumentative styles.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={The output is never definitive, but must always be critically analysed,
adapted, and refined.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\emph{GAI thus becomes a silent \textbf{co-designer}, accompanying the
researcher in the initial phase of research, supporting thought without
ever replacing it. When used consciously, it can }enhance
creativity\emph{, }accelerate the production of ideas* and promote
greater \emph{stylistic and methodological awareness}.

\end{tcolorbox}

\section{1. GAI in the construction of the Research
Project}\label{gai-in-the-construction-of-the-research-project-1}

\textbf{Research design} is one of the most delicate and significant
aspects of Academic activity, particularly in the SSH disciplines, where
the construction of the object of study, theoretical elaboration and the
definition of research methodologies take on a \textbf{highly
reflective, linguistic} and \textbf{interpretative dimension}.

GAI can provide valuable support in the initial phase of Research
Design, particularly in this Academic context.

Using \textbf{structured prompts} GAi allows you to:

\textbf{a.} Explore and refine research questions, stimulating
alternative and more precise formulations\\
\textbf{b.} Construct coherent and verifiable hypotheses, consistent
with the chosen theoretical and methodological approach\\
\textbf{c.} Outline a preliminary methodological framework, suggesting
research designs, tools and techniques appropriate to the context.

The effectiveness of the interaction between researcher and GAI, depends
largely on the \emph{quality of the dialogue} established through the
prompts.\\
This process becomes \textbf{iterative}, \textbf{critical} and
\textbf{assisted}, where each output produced by the GAI is subjected to
careful \emph{evaluation}, \emph{reinterpretation} and, if necessary,
\emph{reformulation}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={In this context, GAI never assumes the role of a substitute for
scientific authorship, but rather that of an ``auxiliary tool'' for
reflection and project development.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

The use of GAI in the Research D**\emph{esign phase should not be seen
as a shortcut, but rather as an opportunity to strengthen the logical
structure and internal consistency of the project.\\
While leaving the researcher with }full theoretical and methodological
responsibility*, AI is able to:\\
- facilitate the exploration of alternatives\\
- prompt new hypotheses\\
- identify conceptual inconsistencies or underdeveloped areas\\
- support the reformulation process in a dynamic and productive way.

In order for this potential to be realised in a meaningful way, it is
necessary to adopt an accurate and conscious \textbf{questioning
strategy}.\\
In this sense, the development of structured prompts is an essential
practice for guiding linguistic generation towards relevant,
contextually grounded and scientifically useful answers.

\subsection{1.1 The research question as a fundamental
node}\label{the-research-question-as-a-fundamental-node}

The \textbf{research question} represents the generative core of every
scientific project: it is not only an operational starting point, but a
theoretical and conceptual act that profoundly conditions the entire
research framework.

\hl{In the field of SSH, its formulation is not limited to identifying a
theme or describing a phenomenon, but involves an epistemological
choice, i.e.~an implicit (or explicit) determination of the
\emph{criteria} by which it is defined what is knowable, how and with
what interpretative tools.}

Formulating a research question therefore means positioning oneself in
relation to a disciplinary field, recognising a gap in the literature or
an open question, and \emph{proposing a possible direction} for
exploring it.

This question then leads to:\\
- \emph{the selection of sources}\\
- \emph{the construction of the theoretical framework}\\
- \emph{the choice of method}\\
- \emph{the form of scientific language used.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={In this process, GAI can play a stimulating and supporting role, without
replacing the researcher's epistemic responsibility.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

When queried with appropriate prompts, GAI is able to:\\
- \emph{propose alternative formulations to an initial intuition}\\
- \emph{help to more precisely define an overly broad scope of
investigation}\\
- \emph{generate new angles from which to observe a familiar problem}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={These contributions should not be taken as definitive solutions, but as
material for dialogue, to be critically evaluated within the individual
elaboration process.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title={In the Academic context, and in particular in doctoral training, working
on the quality of the research question is equivalent to strengthening
the logical and conceptual foundations of the project.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Interaction with AI at this stage can take the form of guided
co-construction, in which AI becomes an interlocutor in the exploratory
phase, stimulating clarifications, precisions, and variations that
enrich the depth and relevance of the question.

\end{tcolorbox}

\subsection{1.2 From question to hypothesis: exploring
relationships}\label{from-question-to-hypothesis-exploring-relationships}

Once the research question has been formulated in a clear, outlined and
theoretically grounded manner, the next step in the design process
involves \textbf{constructing the hypothesis}, which is not merely a
technical step, but a \emph{conceptually strategic one}.

\hl{The hypothesis represents a first provisional and reasoned answer to
the question posed, which the researcher intends to test using an
empirical or theoretical approach.}

In the field of SSH, hypotheses do not necessarily follow the rigid
structure of the hypothetical-deductive model, but can take more
\textbf{flexible forms}, such as an \emph{argumentative conjecture}, an
\emph{exploratory hypothesis} or an \emph{interpretative construct},
depending on the epistemological and methodological framework of
reference.

In all cases, however, it performs an \textbf{orientative function}, as
it helps to define \emph{what} is observed, \emph{how} it is observed
and \emph{under what conditions} a given relationship can be considered
significant.

GAI can be a useful support in this phase, especially if it starts from
a well-formulated research question.\\
Thanks to \textbf{structured prompts}, AI is able to suggest:

\begin{itemize}
\tightlist
\item
  hypotheses that are logically compatible with the question posed\\
\item
  distinguish between causal, correlative or descriptive relationships\\
\item
  help to clarify implicit assumptions that the researcher might
  overlook\\
\item
  propose alternative formulations that highlight latent variables,
  contextual influences or mediating factors not immediately considered.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={It is essential, however, that such hypotheses are not accepted
uncritically, but are subjected to theoretical and methodological
scrutiny by the researcher.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

👉🏻 The role of GAI should be understood as a cognitive stimulus and a
tool for comparison, not as a \emph{substitute for the inferential
process}.\\
Furthermore, the plurality of hypotheses obtainable through AI can
itself become a \textbf{resource for exploration}: \emph{comparing
alternative hypotheses allows you to test the logical soundness} and
\emph{internal consistency of your project}.

\subsection{1.3 Methodology development: consistency and
practicality}\label{methodology-development-consistency-and-practicality}

The definition of the \textbf{methodology} constitutes the operational
translation of the theoretical assumptions and hypotheses formulated.

👉🏻 \hl{It involves the conscious and reasoned choice of a set of
strategies, techniques and tools that make the investigation possible,
while ensuring its internal consistency, epistemic relevance and
practicality on an empirical level.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={Methodology is not a technical module to be applied retrospectively, but
a logical and consistent extension of the Conceptual Design of the
Research.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

In the SSH field, \textbf{methodological construction} often deals with
complex, contextualised objects of study that are subject to multiple
interpretations.\\
Therefore, the selection of qualitative, quantitative or mixed
approaches, the identification of the sample, the timing of the
investigation, and the tools for data collection and analysis must be
discussed and justified in relation to the theoretical framework adopted
and the nature of the phenomenon under investigation.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The methodology does not therefore respond to criteria of mechanical
standardisation, but rather to \emph{criteria of epistemological
relevance}, \emph{logical rigour} and \emph{operational sustainability}.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

When queried with \emph{specific} and \emph{detailed} prompts, GAI can
provide \textbf{methodological design hypotheses} \emph{consistent with
the hypotheses formulated}, suggesting sampling strategies, data
collection techniques (\emph{interviews, questionnaires, document
analysis, observation}), validation tools and possible analytical
approaches.

GenAI also allows you to:\\
- simulate different configurations of the same survey\\
- anticipate implementation issues\\
- assess the impact of certain methodological choices on the expected
results.

👉🏻 \hl{Through \emph{iterative} and \emph{critical use of prompting},
the researcher can progressively refine the methodological design,
validating its consistency with the initial question and the hypotheses
to be tested.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={However, the methodology cannot ignore the relationship between means
and ends, between tools and objects, between theoretical intention and
empirical feasibility.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

In this sense, collaboration with a generative system can become an
\emph{opportunity} to question one's own implicit assumptions,
strengthen the argumentative transparency of the choices made, and
increase the epistemological awareness of the design as a whole.

\end{tcolorbox}

\section{2. Structuring calls and grants with the support of
AI}\label{structuring-calls-and-grants-with-the-support-of-ai-1}

In contemporary research, the ability to draft \textbf{competitive
project proposals} is a crucial skill for accessing funding,
participating in international networks and consolidating one's academic
profile.\\
Calls, grants and research tenders require not only high scientific
quality in terms of ``content'', but also \textbf{formal mastery of
project writing}: \emph{effective summarisation}, \emph{clarity of
presentation}, \emph{logical consistency} and \emph{stylistic
adaptation} to the expectations of the funding body.

In this context, GAI can play an important role as a \textbf{linguistic
assistant, rhetorical simulator} and \textbf{generator of textual
variants}.\\
Starting from \emph{concrete examples} or \emph{structured guidelines},
AI can support researchers in drafting abstracts, executive summaries,
impact descriptions and other elements typical of Academic applications.

\hl{There are \emph{prompting techniques} (including those based on the
\textbf{\emph{few-shot paradigm}}) that can be used strategically to
generate preliminary or alternative versions of project texts.}

\hl{The issue of \textbf{\emph{tone-matching}} is important,
i.e.~\emph{adapting the communicative register to the type of call for
proposals, the evaluating audience and the organisational culture of the
funding body}.}

\subsection{2.1 Few-shot approach: learning from examples to generate
design
variants.}\label{few-shot-approach-learning-from-examples-to-generate-design-variants.}

In the context of Academic writing and designing for competitive calls
for proposals, the \textbf{production of short} and \textbf{highly
strategic texts} -- such as \emph{abstracts} or \emph{executive
summaries} -- is a crucial skill.

These texts require not only mastery of the content, but also the
ability to condense, highlight and make the originality and impact of
the proposal immediately readable.

GAI can offer targeted support at this stage through the use of a
technique known as \textbf{few-shot prompting}.

The \textbf{few-shot paradigm}
\href{https://www.promptingguide.ai/techniques/fewshot}{See Article 1}
and \href{https://www.ibm.com/think/topics/few-shot-prompting}{Article
2} is based on \hl{\emph{presenting the language model with one or more
well-formulated examples (abstracts or extracts from previously accepted
project proposals), followed by a prompt asking the AI to generate a new
version on a different content, while maintaining a consistent style,
structure and tone}.}

Unlike the \emph{zero-shot approach}, in which the model is required to
produce a text from scratch without explicit references, \hl{the
\emph{few-shot mode provides a sample text model on which the AI can
calibrate its generation.}}

This approach is particularly effective in supporting researchers who
are less familiar with drafting international proposals or calls for
proposals, where the \textbf{form of the text} is as important as the
content.

Through guided imitation, GAI is able \hl{to replicate not only the
discursive structure of the abstract
(\emph{opening-problem-objective-method-expected results}), but also the
linguistic intonation required by specific programmes}
(e.g.~\href{https://horizoneurope.apre.it/}{Horizon Europe},
\href{https://marie-sklodowska-curie-actions.ec.europa.eu/}{Marie
Skłodowska-Curie},
\href{https://erc.europa.eu/apply-grant/starting-grant}{ERC Starting
Grant}).

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{It is essential to emphasise that the \emph{quality} and
\emph{effectiveness} of the output depend largely on the quality and
relevance of the examples provided.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

The starting abstracts must be \emph{carefully selected}, preferably
relating to the same disciplinary field and \emph{compatible in tone and
purpose} with the new project to be developed.

\end{tcolorbox}

\hl{GAI should therefore be understood as a real tool for
\textbf{authorial relaunch}, capable of proposing variations that the
researcher will have to critically analyse, adapt and refine.}

Few-shot prompting can also be understood as a \textbf{training
practice}.\\
Comparative analysis between the example provided and the variant
generated by GAI can stimulate reflection on the \emph{rhetorical
structure} of the draft text, \emph{effective lexical choice}s, and
\emph{argumentative coherence}.

👉🏻 \emph{In this sense, the linguistic model functions as an
\textbf{imitative interlocutor}, useful not only for writing but also
for learning to write better}.

\subsection{2.2 Tone-matching: adapting style and register to the call
for proposals or the funding
body}\label{tone-matching-adapting-style-and-register-to-the-call-for-proposals-or-the-funding-body}

One of the most underestimated aspects of project writing is the need to
\textbf{adapt} \emph{tone}, \emph{register} and \emph{communicative
rhetoric} to the implicit expectations of the call for proposals and the
identity of the funding body.

In addition to the quality of the ``content'', what often affects the
outcome of the evaluation is the applicant's ability to express their
project in a \textbf{linguistic form} that is consistent with the
language, values and organisational culture of the institutional
interlocutor.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={\hl{GAI becomes an important resource thanks to the conscious use of
prompts geared towards so-called tone-matching, i.e.~the ability to
modulate the communicative style of the text to make it relevant to the
specific context.}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

Unlike simple formal rephrasing, tone-matching implies a deep
understanding of the target audience: an abstract addressed to a private
Foundation with a Humanistic mission will require a different register
than one intended for a European Agency focused on technological
innovation.

Through specific inputs, GAI can be guided to rewrite an existing text
by varying its \emph{tone}, \emph{emphasis}, \emph{technical density}
and \emph{argumentative structure}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title={For example:}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\emph{AI can be asked to transform a highly specialised text into a more
accessible and informative version for a call for proposals with social
purposes, or to increase the formality and terminological precision in
view of a presentation to an international scientific committee.}

\end{tcolorbox}

\emph{Tone-matching} is also particularly useful in the final stages of
writing, when the content is defined but needs to be \emph{refined}
according to \emph{criteria of rhetorical effectiveness}.\\
In this process, GAI acts as a \textbf{simulated editor}, able to
propose \emph{stylistic alternatives}, \emph{reduce ambiguity}, and
\emph{harmonise the register} between the various sections of a project
document.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={However, the effectiveness of tone-matching depends on the researcher's
ability to provide clear guidance on the type of audience, the identity
of the institution and the objectives of the call.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Also in this case, interaction with AI must be understood as an
\textbf{iterative dialogue}: it is the \textbf{quality of the prompt},
combined with the \textbf{critical awareness of the writer}, that
determines the \textbf{relevance} of the output.

\end{tcolorbox}

Finally, tone-matching is not only about the \emph{form of the text},
but also its ability to communicate belonging to a scientific community,
sensitivity to the evaluation criteria adopted, and adherence to the
strategic objectives of the funding body.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={In this respect, AI can promote impact-oriented stylistic refinement,
helping to bridge the gap between scientific content and its persuasive
presentation.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\chapter{Writing calls, grants, abstracts, and intelligent
automations}\label{writing-calls-grants-abstracts-and-intelligent-automations}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{\texorpdfstring{Prompt chaining for titles and abstracts
(\emph{title generation, abstract draft, stylistic
revision})}{Prompt chaining for titles and abstracts (title generation, abstract draft, stylistic revision)}}\label{prompt-chaining-for-titles-and-abstracts-title-generation-abstract-draft-stylistic-revision}

\paragraph{Script/API for bibliographic metadata extraction and
normalisation, format conversion,
summaries}\label{scriptapi-for-bibliographic-metadata-extraction-and-normalisation-format-conversion-summaries}

\paragraph{Proactive workflows: reminders, dynamic checklists and
periodic reports on new
papers}\label{proactive-workflows-reminders-dynamic-checklists-and-periodic-reports-on-new-papers}

\paragraph{\texorpdfstring{Quick quality metrics (\emph{clarity,
methodological rigour,
appeal})}{Quick quality metrics (clarity, methodological rigour, appeal)}}\label{quick-quality-metrics-clarity-methodological-rigour-appeal}

\end{tcolorbox}

\section{Introduction}\label{introduction-2}

In the context of growing pressure for continuous and measurable
scientific productivity, accompanied by the proliferation of competitive
calls for proposals and increasingly tight deadlines, the strategic
integration of AI-based tools represents a concrete opportunity to
streamline and enhance editorial practices in academic research.\\
In this scenario, where the needs for \emph{clarity of expression,
thematic relevance and persuasiveness} converge, AI can act as a lever
to combine operational efficiency and argumentative quality.

The conscious use of intelligent systems in Academic writing flows --
from design to revision -- makes it possible to \textbf{lighten the
executive load} associated with the most repetitive phases of
intellectual work, allowing researchers to focus their attention on
activities with high cognitive value, such as \textbf{critical
analysis}, \textbf{argumentation} and \textbf{theoretical construction}.

👉🏻 \emph{This results in greater reflectiveness in decision-making
processes and better communication in the texts produced}.

In particular, the writing of \textbf{calls for papers} (project
proposals for competitive grants and scientific abstracts) can be
significantly facilitated by \textbf{intelligent automation}, capable of
supporting the entire text production cycle from \emph{title generation
to logical structuring, from stylisation to quality control.}

\textbf{Five priority areas} can be identified in which GAI finds
effective application in the Social Sciences and Humanities (SSH),
promoting not only the \textbf{acceleration of processes}, but also
their \textbf{conceptual and epistemic refinement}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Prompt chaining for titles and abstracts}\\
\item
  \emph{Scripts/APIs for bibliographic metadata and automatic summaries}
\item
  \emph{Proactive workflows and automated reminders}\\
\item
  \emph{Rapid text quality metrics}\\
\item
  \emph{Cognitive offloading to optimise mental resource management}
\end{enumerate}

\begin{figure}[H]

{\centering \includegraphics[width=0.75\linewidth,height=\textheight,keepaspectratio]{images/npl2.png}

}

\caption{Scheme of text production verification areas}

\end{figure}%

\section{1. Prompt chaining for titles and
abstracts}\label{prompt-chaining-for-titles-and-abstracts}

In the process of generating titles and abstracts, one of the most
effective applications of GAI is \textbf{prompt chaining}, i.e.~the
structured concatenation of text commands.

Through the use of \textbf{progressive sequences of controlled prompts},
the researcher can guide the linguistic model through distinct but
interconnected phases, which \emph{simulate the iterative reasoning}
typical of academic writing.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \emph{We start with a \textbf{simple thematic statement} to generate a
  list of titles consistent with the disciplinary domain and style
  required by the editorial context}.
\item
  \emph{Next, the selected titles are \textbf{developed into draft
  abstracts}, structured according to the specific rhetorical
  conventions of the field (objectives, method, expected results,
  implications)}.
\item
  \emph{Finally, again using targeted prompts, the text is
  \textbf{stylistically revised} and \textbf{linguistically optimised}
  to improve readability, impact and adherence to formal requirements}.
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{For example, a typical flow might look like this:}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\begin{itemize}
\tightlist
\item
  Prompt 1: ``\emph{Generate 5 Academic titles for a project on the
  relationship between AI and political discourse analysis}.''\\
\item
  Prompt 2: ``\emph{Write a draft abstract for title X, using a formal
  style and no more than 150 words}.''\\
\item
  Prompt 3: ``\emph{Reformulate the text with a more persuasive tone,
  maintaining the academic register}.''\\
\end{itemize}

\end{tcolorbox}

In the context of SSH, \emph{prompt chaining} is particularly useful for
exploring different interpretative angles, verifying consistency between
the formulation of the problem and the proposed approach, and refining
the tone according to the target audience (Scientific committee, Funder,
Journal).

👉🏻 \hl{To reducing the time needed to produce a satisfactory version,
this methodology encourages \textbf{greater reflection on the editorial
process}, transforming the AI tool into an \textbf{intellectually
stimulating interlocutor} and not just a mere automated assistant.}

\section{2. Scripts and APIs for metadata and
formats}\label{scripts-and-apis-for-metadata-and-formats}

Within the Academic writing workflow, certain tasks such as
\textbf{managing bibliographic metadata}, \textbf{converting document
formats} and \textbf{generating automatic summaries} are operationally
intensive yet cognitively low-impact.

In this context, the integration of \textbf{custom scripts} and
\href{https://www.ibm.com/think/topics/api}{APIs (Application
Programming Interfaces)} enables the automation of repetitive processes,
facilitating standardisation and reducing the risk of errors.

API-based tools such as \href{https://www.zotero.org/}{Zotero},
\href{https://www.crossref.org/}{CrossRef},
\href{https://www.semanticscholar.org/}{Semantic Scholar} or
\href{https://openai.com/it-IT/}{OpenAI} can be queried to
\textbf{extract}, \textbf{normalise}, and \textbf{reformat}
bibliographic metadata according to \emph{specific citation styles}
(APA, MLA, Chicago, etc.), ensuring coherence and accuracy even during
the final revision stages.

Similarly, \textbf{Python scripts} or \textbf{plug-ins for editorial
environments} (such as Word or \href{https://it.overleaf.com/}{LaTeX})
allow for rapid document conversion between formats (e.g., \emph{from
Word to PDF with embedded metadata or from LaTeX to XML for online
submission}).

\begin{quote}
See
\href{https://www.scielo.br/j/eb/a/Rp4XmcdL6Nntks4ZWtNDWQH/?lang=en}{Python
Scripts For Web Scraping Metadata From Descriptions About The Datasets
Of The International Scenario Of Research Data Repositories}\\
See
\href{https://www.sciencedirect.com/science/article/pii/S2352711019300573}{pybliometrics:
Scriptable bibliometrics using a Python interface to Scopus}\\
See \href{https://www.ajol.info/index.php/sej/article/view/274626}{The
Modern Methods of Data Analysis in Social Research: Python Programming
Language and its Pandas Library as an Example- a Theoretic Study}
\end{quote}

In particular, the combined use of APIs and scripts allows you to
automate:

\begin{itemize}
\tightlist
\item
  The \textbf{generation of complete bibliographic references} (in APA,
  MLA, Chicago, etc.);
\item
  The \textbf{retrieval of scientific article abstracts}
\item
  The \textbf{conversion of files} (PDF → text, BibTeX → JSON);
\item
  The \textbf{creation of summaries} of the state of the art.
\item
  The generation of \textbf{automatic summaries} of scientific articles
  or regulatory acts, to be used as study material, as a basis for
  developing original abstracts, or as support for the literature
  analysis phase, with significant savings in time and cognitive load.
\end{itemize}

\hl{In the SSH, where researchers often work with heterogeneous sources
and multi-methodological approaches, these automations facilitate more
robust information management, making it easier to organise sources,
track references, and prepare materials ready for submission.}

\section{3. Proactive workflows and intelligent time
management}\label{proactive-workflows-and-intelligent-time-management}

In today's Academic environment, characterized by increasing
organizational complexity and a multitude of simultaneous tasks
(\emph{teaching, research, dissemination, planning}), the ability to
effectively manage time and priorities is a strategic skill.

👉🏻 In this scenario, AI offers concrete tools for building
\textbf{proactive workflows}, i.e.~\emph{organisational processes in
which technologies}, often based on AI automation, \emph{are able to
anticipate user needs and intervene before problems or explicit needs
arise}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{These systems not only optimize individual organization, but also build
an information ecosystem that reduces the impact of the executive load
and stimulates continuous reflection on scientific priorities.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

👉🏻\hl{Through the integration of \emph{advanced language models},
\emph{task management systems}, and \emph{personal productivity tools},
it is possible to design \textbf{semi-automated workflows} that do not
merely react to deadlines but help to anticipate them and distribute
them in a sustainable manner.}

The adoption of \textbf{prompt scheduling systems}, designed to
proactively generate contextualised reminders and preliminary drafts in
relation to Academic deadlines (e.g.~\emph{calls for papers, project
submissions or article reviews}), is an effective strategy for
mitigating procrastination and supporting the continuity and regularity
of scientific output.

In addition, some AI platforms allow the \textbf{integration of smart
calendars} which, in addition to simply recording events, provide
personalised suggestions on the most suitable time slots for activities
such as \emph{writing}, \emph{data analysis or reading}, taking into
account both the estimated cognitive load and individual productivity
patterns.

Integrated with \textbf{time tracking tools}, these systems promote more
conscious \emph{management of time resources}, facilitating an optimal
balance between \emph{high cognitive value activities} (writing, design,
reflection) and \emph{repetitive operational tasks} (formatting, data
entry, uploading to platforms).

Finally, proactive workflows can be used to \textbf{schedule periodic
text reviews} and incorporate \textbf{automatic feedback} on
consistency, readability, and style.\\
An incremental approach, distributed in short, planned sessions, helps
mitigate the mental overload typical of production concentrated around
deadlines, promoting a measurable improvement in the overall quality of
Academic output.

\section{4. Rapid metrics for text
quality}\label{rapid-metrics-for-text-quality}

In the context of the SSH, where text production is not only a means of
communication but also an expression of theoretical argumentation,
critical analysis and conceptual density, \textbf{linguistic and
rhetorical quality control} takes on strategic importance.

Unlike disciplinary fields characterised by more standardised textual
structures, the SSH field is distinguished by stylistic variety,
semantic complexity and a plurality of rhetorical registers.

In this context, the adoption of \textbf{automated text quality
metrics}, based on linguistic models or Natural Language Processing
(NLP) tools, allows for the insertion of an intermediate phase of
analysis and revision into the writing process, which is useful for
identifying latent critical issues and opportunities for improvement.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={These metrics have no prescriptive or evaluative value in the strict
sense, but can act as ``reflective aids'', increasing stylistic
awareness and promoting greater adherence of the text to the
expectations of the academic audience or evaluation committee.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\textbf{Text quality assessment metrics} can be divided into four main
areas:

\textbf{a.} \emph{Clarity and readability}\\
These include parameters such as average sentence length, frequency of
passive voice, density of subordinate clauses, and readability indices
(e.g.~\href{https://readable.com/readability/flesch-reading-ease-flesch-kincaid-grade-level/}{Flesch-Kincaid}
or \href{https://readable.com/readability/gunning-fog-index/}{Gunning
Fog Index}). These measures are particularly relevant when the text is
written in a language other than the author's mother tongue.

\textbf{b.} \emph{Textual consistency and cohesion}\\
These relate to the recurrence and distribution of key concepts,
semantic consistency between different sections, and the presence and
variety of logical and discursive connectives (\emph{furthermore},
\emph{in contrast}, \emph{consequently}), which are essential indicators
for ensuring a solid flow of argumentation.

\textbf{c.} \emph{Lexical richness and terminological density}\\
These assess lexical diversity, the balance between specialist
terminology and the accessibility of the text, and the frequency of rare
terms. The latter aspect is useful for identifying phenomena of
hyper-specialisation or, conversely, excessive generality.

\textbf{d.} \emph{Tone, register and epistemic markers}\\
These consider the appropriateness of the academic tone, the use of
attenuating formulas (``\emph{it is possible to hypothesise
that}\ldots{}''``), intensifiers (``\emph{clearly}'', ``\emph{without
doubt}'') and implicit evaluations, elements that are of significant
argumentative relevance in the social sciences and humanities.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={Some digital tools, including advanced language models, can provide
concise but detailed assessments based on these criteria, operating both
in real time and on demand. Among other things, these tools allow you to
compare different versions of the same text or evaluate multiple
abstracts, making it easier to choose the most suitable wording for a
specific call.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\subsubsection{Examples of tools for rapid text quality
analysis}\label{examples-of-tools-for-rapid-text-quality-analysis}

\begin{itemize}
\item
  \href{https://hemingwayapp.com/}{Hemingway Editor}\\
  Measures readability, flags complex or passive sentences, and suggests
  stylistic simplifications. It is particularly useful for
  \emph{clarifying argumentative passages} and \emph{introductory
  sections}.
\item
  \href{https://www.writefull.com/writefull-for-overleaf}{Writefull for
  Overleaf}\\
  AI-based plugin that analyses scientific texts, providing feedback on
  academic vocabulary, correct use of prepositions and sentence
  structure. It is a great support for those who \emph{write in English
  as a non-native language}.
\item
  \textbf{GPT-based Quality Assessment} (\emph{GPT-based assessment
  through targeted prompts})\\
  Through calibrated instructions, models such as ChatGPT or Claude can
  return:\\
  • \emph{an analysis of tone and rhetorical effectiveness}\\
  • \emph{an assessment of logical and argumentative coherence}\\
  • \emph{a summary score based on predefined criteria} (clarity,
  relevance, impact)
\item
  \href{https://textstat.org/}{TextStat} or
  \href{https://citius.usc.es/transferencia/software/linguakit}{Linguakit}\\
  They are open-source NLP tools and provide quantitative analyses
  relating to:\\
  • \emph{average sentence length}\\
  • \emph{frequency and distribution of keywords}\\
  • \emph{terminological variety}\\
  • \emph{internal cohesion and coherence of the text}
\item
  \href{https://languagetool.org/dev}{LanguageTool}\\
  Multilingual grammar and style checker that detects spelling, grammar
  and syntax errors, flags complex or overly long sentences, repetitions
  and excessive use of the passive voice. Useful for \emph{improving the
  clarity and readability} of Academic and popular texts, with add-ons
  available for browsers, Word, Google Docs and various text editors.
\end{itemize}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={In the field of SSH, where textual quality is an integral part of
scientific authority and where argumentative rhetoric carries decisive
weight, these metrics represent an opportunity to systematise formal
revision without flattening stylistic originality.They can be adopted
not only for individual production, but also in collaborative contexts,
serving as a neutral interface for stylistic negotiation and the
construction of a shared voice within research groups or collective
editorial teams.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\section{5. Cognitive offloading and selective
attention}\label{cognitive-offloading-and-selective-attention}

In the Academic production cycle of the SSH, traditionally characterised
by a high incidence of iterative activities, such as \emph{annotation,
source verification, syntactic editing and terminological
standardisation}, \textbf{cognitive offloading} to GAI tools represents
a targeted strategy for reallocating attentional resources.

Delegating low-epistemic operations to automated systems not only
preserves cognitive load, but also allows researchers to focus their
attention on conceptually dense phases: \emph{defining research
questions, constructing theoretical frameworks}, and \emph{validating
arguments}.

Among the most significant uses of GAI in SSH are:

\begin{itemize}
\item
  \textbf{Controlled semantic reformulation}, used to test the
  conceptual soundness of a paragraph by subjecting it to lexical
  variations that do not alter its propositional content.
\item
  \textbf{Automatic pre-annotation of qualitative texts}
  (e.g.~\emph{interviews, historical documents, literary sources}),
  aimed at facilitating manual coding according to specific theoretical
  models, such as
  \href{https://journals.sagepub.com/doi/10.1177/2050312118822927}{Grounded
  Theory} or
  \href{https://scholar.ufs.ac.za/items/b0653889-5985-4981-b442-9c1dfa53925d}{Frame
  Analysis}.
\item
  \textbf{Selective verification of intertextual consistency}, using
  models capable of mapping the logical connection between text sections
  (e.g., \emph{between abstracts and conclusions}, or \emph{between
  hypotheses and data}).
\item
  \textbf{Performing meta-editorial tasks}, including checking
  readability, converting to standard editorial formats (APA, MLA) and
  analysing syntactic dependencies to identify opaque constructions.
\end{itemize}

👉 \hl{In such applications, AI acts as an \textbf{attentional
amplifier}: it does not make interpretative decisions, but creates the
conditions for a more targeted selection of cognitively salient
stimuli.}

This approach embodies the logic of selective attention scaffolding, in
which the algorithm provides a neutral, interference-free context,
encouraging the emergence of critical thinking in a clearer form.

Evidence from learning sciences and human--AI interaction studies
indicates that the ability to orchestrate distributed cognitive
environments, integrating artificial agents, digital resources and human
skills, is a qualifying indicator of \textbf{advanced epistemological
literacy}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={Strategic allocation of structural operations to AI not only increases
productivity but also strengthens the quality of conceptual processing
and metacognitive awareness throughout the entire research cycle.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\chapter{Scientific and popular
communication}\label{scientific-and-popular-communication}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Academic blogging}\label{academic-blogging}

\paragraph{\texorpdfstring{Social Academia (structuring
\emph{tweetorials} and \emph{LinkedIn
threads})}{Social Academia (structuring tweetorials and LinkedIn threads)}}\label{social-academia-structuring-tweetorials-and-linkedin-threads}

\paragraph{Summary for non-experts
(TL;DR)}\label{summary-for-non-experts-tldr}

\end{tcolorbox}

\section{Introduction}\label{introduction-3}

The \textbf{Research Communication} is now an essential extension of
Academic work.\\
Whereas in the past the circulation of knowledge was almost exclusively
limited to traditional publishing channels (\emph{peer-reviewed
journals, conference proceedings, monographs}) the current digital
ecosystem has brought about a radical change in \textbf{dissemination
practices}.

The growing demand for transparency, the need to promote open access to
results, and the urgency of engaging with non-specialist audiences are
forcing researchers to experiment with new formats that balance
\emph{scientific rigour} and \emph{readability}. In this context,
writing is no longer just a tool for intra-disciplinary validation, but
also a \emph{means of mediation} that must respond to the logic of
visibility, traceability and social impact.

Hence the centrality of hybrid practices of scientific and popular
communication, which are articulated along three main lines:
\textbf{Academic Blogging, Social Academia} and \textbf{Summaries for
non-experts}.

While specialist writing remains the privileged place for certifying
results, these practices of extended communication represent the
\textbf{infrastructure of impact}, the vehicle through which research
acquires visibility, public relevance and transformative power.

👉🏻 \hl{Far from being ancillary operations, they are at the heart of a
\textbf{new ecology of knowledge}, in which authority no longer derives
solely from citation indices or impact factors, but also from the
ability to \emph{generate dialogue, inform decision-making processes}
and \emph{take root in contemporary digital circuits}.\\
The adoption of GAI as a support for scientific communication imposes an
additional \textbf{critical responsibility}: it is up to the researcher
to ensure that any form of algorithmic mediation does not compromise the
conceptual fidelity or epistemic quality of the text.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

In this way, GAI takes on the role of \textbf{enabling technology}. It
does not replace authorial competence, but amplifies its possibilities,
offering tools for \emph{reformulation, stylistic variation, discourse
network analysis,} and \emph{content optimisation}.\\
In other words, the machine can facilitate the transposition of
knowledge between different registers and audiences, but it remains the
\textbf{researcher's task} to ensure \emph{consistency, accuracy,} and
\emph{integrity}.

\end{tcolorbox}

\section{1. Academic Blogging}\label{academic-blogging-1}

Among the scientific communication practices that have become
established over the last two decades, \textbf{Academic Blogging}
occupies a prominent position as a tool for mediating between the
language of specialist writing and the readability requirements of
digital communication.

Unlike peer-reviewed journals (which represent the main channel of
scientific validation), the primary purpose of Academic Blogs is not the
epistemic certification of results, but their \textbf{dissemination in
broader contexts}, often hybridising discursive registers and visibility
strategies typical of the web.

The goal is therefore not to simplify the complexity of research, but to
``\textbf{refocus}'' it.

👉🏻\hl{\emph{Reformulating a technical abstract into a 400-500 word text
means translating concepts and data into a narrative structure that
preserves methodological accuracy but is accessible to readers who do
not necessarily belong to the narrow disciplinary circle.}}

In this sense, \textbf{blogging} serves a dual purpose:

\begin{itemize}
\tightlist
\item
  it broadens the potential impact of scientific work by making it
  accessible through search engines and digital platforms;
\item
  it promotes the construction of an authorial presence that documents
  the intermediate stages of research over time, fostering transparency
  in the knowledge process and \emph{open science} practices.
\end{itemize}

Regular publications contribute to the creation of a \textbf{coherent
archive} that not only reproduces the final results, but also makes
visible the moments of \emph{reflection, conceptual revision} and
\emph{methodological experimentation}.

From a \textbf{methodological} point of view, ``\emph{rewriting a
technical abstract in the form of a post}'' involves several stages.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \textbf{Identification of the conceptual core}: the researcher
  isolates a key thesis or result and reformulates it in order to answer
  an implicit question from the reader that forms the backbone of the
  work.\\
  AI can act as a heuristic support, generating ``alternative
  headlines'' that can guide the reception of the text as titles
  formulated in an \emph{interrogative, assertive} or \emph{informative
  way} that stimulate the reader's curiosity without sacrificing
  conceptual accuracy.\\
  ⚠️ \hl{The final selection remains the prerogative of the researcher,
  whose task is to critically evaluate the algorithmic proposals in
  light of the disciplinary context and target audience.}

  👉 Example: from the abstract ``\emph{We analysed the impact of open
  peer review practices on the quality of publications in the social
  sciences}'', the headline ``\emph{Open peer review: does it really
  improve the quality of articles in the social sciences}?''
\item
  \textbf{Narrative restructuring}: the task consists of transforming a
  text dense with technical terms into a linear narrative that
  facilitates comprehension.\\
  AI can intervene here as a cognitive offloading tool, producing
  alternative drafts that reduce terminological density or suggest more
  fluid rhetorical patterns, for example by proposing historical
  analogies or controlled metaphors that make the subject accessible
  without distorting it.\\
  ⚠️ \hl{In this case too the researcher's supervision is essential. If
  the algorithm generates excessive simplifications or ambiguous
  formulations, it is up to the author to reintroduce rigour and
  epistemic consistency.}

  👉 Example: a graph in the article can become a \emph{simplified
  infographic} or a \emph{descriptive paragraph} that explains the trend
  in a discursive manner.
\item
  \textbf{Optimisation and dissemination}: blog writing is influenced by
  the logic of the digital ecosystem made by \emph{visibility,indexing}
  and \emph{interaction}.\\
  The calls to action at the end of the text aim to encourage the reader
  to take a specific action (\emph{read the full article, share the
  content, participate in a discussion}) and can be refined with the
  help of GAI tools that suggest \emph{linguistic variations tailored to
  the target audience}.\\
  The same logic applies to the SEO meta description, a short summary of
  150--160 characters that acts as an interface with search engines.\\
  ⚠️ \hl{AI can propose multiple alternatives, optimised for different
  keyword clusters, while the final decision rests with the researcher,
  who verifies their semantic adherence to the original content.}

  👉 Example of a meta description: ``\emph{A study of open peer review
  practices shows how the dynamics of editorial quality in the social
  sciences are changing.}''
\end{enumerate}

Blog writing thus becomes a \textbf{laboratory for reflection} in which
researchers can experiment with new forms of discourse, test the
reception of hypotheses still in the exploratory phase, and interact
with wider communities of readers, including policy-makers, students,
and the general public.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

The use of AI, if kept within the limits of an instrumental support and
never a substitute, \textbf{enhances this process} by offering a range
of expressive and operational solutions that the human author filters,
controls and critically integrates.

\end{tcolorbox}

\paragraph{Examples of blogs}\label{examples-of-blogs}

\begin{itemize}
\tightlist
\item
  \href{https://blogs.lse.ac.uk/impactofsocialsciences/}{LSE Impact Blog
  (London School of Economics)}= \emph{platform that collects
  contributions from researchers, rewritten in accessible language and
  accompanied by titles optimised for online dissemination}.\\
\item
  \href{https://theconversation.com/}{The Conversation}= \emph{offers
  articles written by academics but edited by communication
  professionals, with the explicit aim of mediating between scientific
  rigour and public enjoyment}.\\
\item
  \href{https://scholarlykitchen.sspnet.org/}{Scholarly Kitchen Blog}=
  \emph{a privileged observatory on academic communication practices,
  showing how blogs can become not only a tool for dissemination, but
  also a place for critical reflection on editorial and scientific
  processes themselves}.
\end{itemize}

\section{\texorpdfstring{2. Social Academia: structuring
\emph{tweetorials} and \emph{LinkedIn
threads}}{2. Social Academia: structuring tweetorials and LinkedIn threads}}\label{social-academia-structuring-tweetorials-and-linkedin-threads-1}

The growing centrality of social media in the contemporary communication
ecosystem has also led to a redefinition of \textbf{scientific
dissemination practices}.

What is referred to as \textbf{Social Academia} is not merely an
exercise in personal self-promotion, but rather a set of strategies for
the micro-dissemination of research content that exploit the logic of
digital platforms to broaden the circulation of knowledge.\\
Unlike Academic Blogs, which focus on relatively long and narratively
complex texts, Social Academia \emph{imposes reduced formats, rapid
timing} and \emph{constant competition for the reader's attention}.

👉 \hl{The goal for everyone is to make \textbf{research results
visible}, stimulate critical interaction and consolidate communities of
practice and interest around scientific topics.}

The use of platforms such as \emph{Twitter/X} and \emph{LinkedIn} has
made central the \textbf{tweetorial} or \textbf{thread format}, i.e.~a
sequence of micro-texts arranged in logical succession, the construction
of which requires \emph{specific rhetorical and strategic skills}.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \textbf{Segmenting the topic} into autonomous but connected units of
  meaning, capable of maintaining the reader's attention and gradually
  guiding them towards the central thesis.
\item
  \textbf{Choosing the hashtags} that plays an indexing and positioning
  role, as they connect the content to existing discursive networks,
  facilitating findability and entry into global thematic conversations.
\item
  \textbf{Determing the timing the publication}, important for the
  visibility of content that depends on when it is disseminated, in
  relation to the activity cycles of digital scientific communities.
\end{enumerate}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

\vspace{-3mm}\textbf{AI can be incorporated into these practices in different ways, always
subject to critical control by the researcher.}\vspace{3mm}

\end{tcolorbox}

During the \textbf{thread design phase}, GAI tools can help produce
\emph{multiple drafts of the text sequence}, suggesting alternative
logical orders or identifying transition points between one micro-text
and another.

👉 The author retains the task of verifying epistemic consistency and
fidelity to scientific data, correcting undue simplifications or lexical
slips.

👉 As for the choice of hashtags, AI can analyse industry trends and
propose terminology clusters that optimise content visibility, avoiding
the use of labels that are too generic or, conversely, overly
sector-specific.

👉 Even in the case of timing, predictive analysis algorithms can
provide indications of the moments of maximum engagement probability,
but it will always be up to the author to decide whether these metrics
coincide with the needs of the target community.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{The conscious use of Social Academia is not limited to increasing
individual visibility, but contributes to the creation of collective
discursive spaces in which research results can be discussed,
contextualised and critically evaluated.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

In this sense, social media become true ``\textbf{community
laboratories}'', where scientific knowledge meets diverse audiences and
is measured against the speed and unpredictability of digital circuits.

\end{tcolorbox}

⚠️ \hl{When used as an auxiliary tool for generating drafts and
analysing discursive networks, AI amplifies the researcher's expressive
possibilities, but cannot replace their epistemic and authorial
responsibility.}

\section{3. Summary for non-experts
(TL;DR)}\label{summary-for-non-experts-tldr-1}

The growing complexity of scientific production has highlighted the need
for textual devices capable of acting as an interface between academic
research and audiences who do not share the same level of
specialisation.\\
In this perspective \textbf{short summaries}, frequently referred to by
the acronym TL;DR (\emph{Too Long; Didn't Read}), have taken on a
central role in contemporary knowledge dissemination policies.

Originally created as colloquial formulas within digital communities,
these summaries are now recognised as essential tools for conveying
complex knowledge to audiences such as \emph{policy makers,
administrators, journalists or interested citizens}, who need immediate
and pragmatic access to research results.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-tip-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-tip-color-frame, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{Tip}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

Their function is not limited to simplification, but rather consists in
the \textbf{construction of a cognitive transfer device} capable of
preserving the epistemic validity of the content while making it usable
in heterogeneous decision-making and communication contexts.

\end{tcolorbox}

From a methodological point of view, \textbf{writing a TL;DR} involves a
``rigorous selection of materials'' which requires a few steps.

\begin{itemize}
\item
  \emph{Step 1} = \textbf{Isolate the most significant result}, i.e.~the
  conceptual core that represents the contributory claim of the work and
  which must be understandable without the support of the entire
  argumentative apparatus. This operation requires an act of
  \emph{authorial interpretation}, since not all data or empirical
  evidence has the same degree of communicative transferability.
\item
  \emph{Step 2} = \textbf{Articulate the content in an accessible
  linguistic register}, free of unexplained technicalities, but at the
  same time resistant to the risk of trivialisation.
\item
  \emph{Step 3} = \textbf{Explicit the practical or political
  implications of the research}: not a simple conclusion, but a
  projection that clarifies how the results may affect professional,
  regulatory or cultural practices.
\end{itemize}

👉🏻 \hl{The introduction of GAI in this process opens up new
perspectives, which must nevertheless be evaluated with critical
caution. \textbf{Automatic summarisation algorithms} are capable of
generating \emph{multiple summaries}, with varying degrees of
granularity, from the original text. These outputs can offer researchers
a range of \emph{stylistic and structural possibilities}, acting as
catalysts for the final elaboration.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title={The selection of content to be included cannot be left entirely to the
machine: if left to its own devices, AI tends to favour statistically
recurring information rather than conceptually decisive information,
risking distorting the epistemic hierarchy of the work.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

⚠️ \textbf{For this reason, the role of the author remains essential,
both in \emph{validating the generated content} and in \emph{refining
the language} to ensure semantic consistency and contextual
appropriateness.}

\end{tcolorbox}

In more advanced stages, AI can also support optimisation for different
audiences. For example, a 120-word summary is for a policy brief, a
280-character summary for an informative post, an introductory note for
an institutional portal.

👉🏻 \emph{In any case, the value of the process lies in the
\textbf{critical dialogue} between human and artificial intelligence,
not in the replacement of one with the other}.

The strategic importance of TL;DR summaries can be fully understood by
considering their \textbf{political} as well as communicative function.
A text of just a few lines can guide regulatory choices, influence
public opinion or help define an institution's agenda.

Far from being a limitation, \textbf{brevity} becomes a condition for
effectiveness, since reducing a complex work to 100-150 words means
carrying out a selection process that not only communicates, but also
\emph{interprets and enhances the research}.

👉 \hl{In this sense, short summaries are an \textbf{autonomous text
genre} that requires specific writing skills, rhetorical sensitivity and
awareness of the social and institutional dynamics within which they
will be placed.}

\subsection{Further reading}\label{further-reading-1}

• \href{https://www.oecd.org/policy-briefs/}{OECD Policy Briefs}:
paradigmatic examples of texts that condense complex analyses into
targeted summaries for policy makers, characterised by rigour and
immediacy.\\
• \href{https://www.semanticscholar.org/}{Semantic Scholar -- TLDR
function}: open-access platform that automatically generates
one-sentence summaries for millions of articles in computer science,
biology and medicine, directly in search results.\\
• \href{https://arxiv.org/abs/2210.09932}{Making Science Simple: Corpora
for the Lay Summarisation of Scientific Literature}: study proposing
datasets with biomedical research texts associated with lay summaries
written by experts, offering concrete examples of summaries accessible
to non-specialists.\\
• \href{https://aclanthology.org/2020.findings-emnlp.428.pdf}{TLDR:
Extreme Summarisation of Scientific Documents}: example of extremely
concise summaries --- even of a single sentence --- capable of capturing
the main contribution of a scientific article, accompanied by annotated
and validated TL;DR datasets.\\
•
\href{https://www.agu.org/-/media/files/agu-programs/spgr/science-communication/toolkit_-_plain_language_summary.pdf}{AGU
(American Geophysical Union) Practical Guide to Plain Language
Summaries}: open access PDF guide illustrating how to develop summaries
in plain language, avoiding technical jargon and contextualising
research for a non-expert audience.

\part{Part 3: Ethical aspects and responsibility in the use of AI}

\chapter{Epistemology and
Transparency}\label{epistemology-and-transparency}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{AI and the construction of scientific
``truth''}\label{ai-and-the-construction-of-scientific-truth}

\paragraph{Interpretability and eXplainable Artificial Intelligence
(XAI)}\label{interpretability-and-explainable-artificial-intelligence-xai}

\paragraph{Limits of opaque
architectures}\label{limits-of-opaque-architectures}

\paragraph{Transparency as an epistemic
condition}\label{transparency-as-an-epistemic-condition}

\end{tcolorbox}

Scientific research has historically been based on shared
epistemological principles: \emph{verifiability}, \emph{falsifiability}
and \emph{methodological transparency}.

These criteria, developed within the framework of logical positivism and
subsequently consolidated through Karl Popper's falsificationism, have
ensured that scientific results are accumulable, subject to critical
scrutiny and open to intersubjective control.

The introduction of AI, and in particular generative systems based on
LLMs, now forces us to rethink these assumptions.\\
AI does not merely provide advanced computational tools, but intervenes
directly in the \textbf{production of knowledge} by \emph{selecting},
\emph{synthesising} and \emph{organising sources}.

This function reorients the processes of constructing
``\textbf{scientific truth}'', redefining the relationship between data,
theories and research communities.

\section{1. AI and the construction of ``scientific
truth''}\label{ai-and-the-construction-of-scientific-truth-1}

One of the most significant transformations concerns the way in which AI
participates in the \textbf{selection} and \textbf{synthesis} of
sources.

Generative systems can draw on large text corpora, identify correlations
and propose coherent syntheses, presenting them as information with
scientific value.

\hl{👉 However, the probabilistic logic that governs these models does
not coincide with traditional epistemic criteria: what is produced is
not the result of deductive or inductive reasoning, but the projection
of a statistical distribution learned from the data.}

The notion of ``\emph{scientific truth}'' risks being progressively
replaced by a form of ``\emph{linguistic plausibility}'', a discourse
which, while presenting itself with syntactic coherence and rhetorical
force, does not necessarily guarantee the verifiability of its content.

This dynamic requires a clear distinction between \textbf{scientifically
validated knowledge} and \textbf{output generated by AI systems}, to
prevent the rhetorical power of AI-generated language from being
mistaken for scientific evidence.\\
From this perspective, AI does not merely produce texts, but acts as a
cognitive filtering device that implicitly guides the \emph{hierarchy of
sources, the salience of concepts} and the \emph{interpretative
trajectories} considered relevant.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ The result is a redefinition of the criteria of epistemic relevance,
capable on the one hand of broadening access to knowledge and on the
other of excluding minority perspectives or sources not represented in
the training datasets. }

\end{tcolorbox}

\section{2. Interpretability and eXplainable Artificial Intelligence
(XAI)}\label{interpretability-and-explainable-artificial-intelligence-xai-1}

The problem of the opacity of deep learning algorithms has given rise to
a specific field of study known as \textbf{eXplainable Artificial
Intelligence (XAI)}.

The aim of this approach is to provide methodological and technical
tools that make the \emph{decision-making processes of models
``interpretable''}, allowing researchers to understand why a particular
inference or synthesis has been produced.

\hl{👉 Interpretability is not only about the readability of the model,
but also has epistemological significance: without the ability to
explain the reasons for an output, the traceability necessary to
recognise a result as scientific is lost.}

Key strategies include feature attribution techniques (such as
\href{https://dl.acm.org/doi/pdf/10.1145/3578337.3605138}{LIME} and
\href{https://cgarbin.github.io/machine-learning-interpretability-feature-attribution/}{SHAP}),
which identify which variables have contributed most to a prediction,
and intrinsically interpretable models, designed to prioritise
readability over computational complexity.

Although none of these approaches completely eliminates opacity, they
provide sufficient levels of transparency to reintroduce accountability
and verifiability criteria into research processes.

\section{3. The limits of opaque
architectures}\label{the-limits-of-opaque-architectures}

Despite advances in XAI, the most advanced architectures remain largely
``\textbf{opaque}''.\\
Deep learning models, especially those based on billions of parameters,
cannot be fully interpreted by either developers or users.

This \textbf{black box condition} introduces an epistemological divide.
Science, traditionally anchored in the reconstructibility of processes,
finds itself dependent on systems that produce inferences whose internal
mechanisms cannot be explained.

The problem is not only technical but also ``conceptual''.\\
AI does not operate through \emph{logical reasoning} but through the
\emph{reproduction of statistical patterns}.\\
As a result, it does not distinguish between what is epistemically
grounded and what is only probabilistically plausible.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-warning-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-warning-color-frame, title=\textcolor{quarto-callout-warning-color}{\faExclamationTriangle}\hspace{0.5em}{This characteristic opens up the possibility of systematic errors,
textual hallucinations and bias amplification, phenomena that undermine
scientific credibility if not accompanied by rigorous control and
validation practices.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

\section{4. Transparency as an epistemic
condition}\label{transparency-as-an-epistemic-condition-1}

The issue of \textbf{transparency} is not limited to the technical
readability of algorithms, but concerns the entire cycle of scientific
production.\\
It becomes necessary to make explicit the criteria for data selection,
processing methods and circumstances of AI use, so that the results can
be subjected to intersubjective control.

Transparency assumes an eminently \textbf{epistemic function}, since
only by ensuring the possibility of collective reconstruction can AI
outputs be prevented from turning into opaque products, shielded from
critical scrutiny.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ Alongside the \emph{individual responsibility} of researchers, who
must accurately \textbf{document the use of AI in their work}, there is
also \textbf{institutional responsibility}.}

\end{tcolorbox}

International organisations, funding agencies and Academic communities
have begun to define standards and guidelines aimed at preserving
epistemic integrity.

\hl{👉 These directives require systematic disclosure of AI use,
together with auditing and reporting protocols.\\
Publishing houses are also moving in this direction, requiring precise
declarations on the use of generative systems in writing and editing
processes.}

\section{Further Reading}\label{further-reading-2}

\begin{quote}
See
\href{https://journals.sagepub.com/doi/full/10.1177/2053951715622512}{How
the machine `thinks': Understanding opacity in machine learning
algorithms}
\end{quote}

\begin{quote}
See \href{https://doi.org/10.48550/arXiv.1702.08608}{Towards A Rigorous
Science of Interpretable Machine Learning}
\end{quote}

\begin{quote}
See \href{https://doi.org/10.1007/s00146-022-01617-6}{Connecting ethics
and epistemology of AI}
\end{quote}

\begin{quote}
See
\href{https://ejournal.bamala.org/index.php/yudhistira/article/view/251/49}{Digital
epistemology: evaluating the credibility of knowledge generated by AI}
\end{quote}

\begin{quote}
See \href{https://doi.org/10.48550/arXiv.2508.02760}{Towards a Manifesto
for Cyber Humanities: Paradigms, Ethics, and Prospects}
\end{quote}

\begin{quote}
See \href{https://dl.acm.org/doi/pdf/10.1145/3236386.3241340}{The mythos
of model interpretability}
\end{quote}

\begin{quote}
See
\href{https://www.sciencedirect.com/science/article/pii/S0004370218305988?via\%3Dihub}{Explanation
in Artificial Intelligence: Insights from the Social Sciences}
\end{quote}

\chapter{Implications of the use of AI in
research}\label{implications-of-the-use-of-ai-in-research}

The question of epistemology and transparency in the use of AI in
research processes is a decisive factor in the very legitimacy of
contemporary science.

The adoption of Generative Systems is not merely an instrumental update,
but has a profound impact on the logic of knowledge production, altering
the criteria by which knowledge is constructed, validated and shared.

The GAI, in its ability to \emph{select}, \emph{organise} and
\emph{synthesise sources}, directly intervenes in the definition of
``\textbf{scientific truth}'', expanding the possibilities of access to
information but at the same time introducing new areas of opacity and
fragility in terms of \textbf{verifiability}.

The tools developed in the field of \textbf{Explainable AI (XAI)} are a
significant attempt to restore transparency to otherwise uninterpretable
processes, but they fail to bridge the gap between the epistemic needs
of the scientific community and the opaque complexity of deep
architectures.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-important-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-important-color-frame, title=\textcolor{quarto-callout-important-color}{\faExclamation}\hspace{0.5em}{The relationship between researcher and AI is one of co-agency, in which
humans retain the role of \emph{guarantor of cognitive and ethical
processes}, but must contend with a \emph{technological agent} that
introduces new possibilities and, at the same time, new opacity.}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\end{tcolorbox}

This transformation requires the Academic Community to reflect on the
soundness of the founding principles of modern science:\\
- the verifiability of results\\
- the methodological transparency\\
- the neutrality of sources\\
- the individual and collective responsibility in the evaluation phases.

Introducing AI Systems, particularly their generative applications,
tests these assumptions along four main lines:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{the Epistemological Dimension of Transparency}\\
\item
  \textbf{the issue of Bias and Source quality}\\
\item
  \textbf{the redefinition of Accountability in peer review processes}\\
\item
  \textbf{towards a renewed Operational Ethic}.
\end{enumerate}

The use of GAI in research cannot be considered a simple technical
support, but must be treated as an \textbf{epistemic object in its own
right}, capable of influencing the entire knowledge ecosystem.

👉 On the one hand, AI significantly expands the analytical and
synthetic capabilities of researchers, offering tools capable of
processing huge amounts of data and generating hypotheses.

👉 On the other hand, it introduces concrete risks, such as
\emph{algorithmic opacity, the propagation of errors or biases, the
weakening of traditional accountability mechanisms} and \emph{the
potential erosion of public trust in science}.

Analysing these implications in depth means maintaining a constant
tension between \emph{technological innovation} and \emph{scientific
integrity} as a guiding principle, so that AI can be integrated without
compromising the principles that guarantee the credibility of research.

\section{Key References}\label{key-references}

\begin{itemize}
\item
  \href{https://www.unesco.org/en/articles/recommendation-ethics-artificial-intelligence}{UNESCO
  Recommendation on the Ethics of Artificial Intelligence}\\
  \emph{First global ethical framework on the use of AI, with principles
  on transparency, accountability and inclusion. (2021 International
  recommendation)}
\item
  \href{https://artificialintelligenceact.eu/}{EU Artificial
  Intelligence Act (AI Act)}\\
  \emph{Binding regulations governing AI systems, including those used
  in research, with documentation and monitoring requirements. (2024
  Legislation)}
\item
  \href{https://www.eui.eu/Documents/ServicesAdmin/DeanOfStudies/ResearchEthics/2024.06-Ethics-Commitee-EUI-GENAI-DIGITAL.pdf}{EUI
  - European University Institute - Guidelines for the Responsible Use
  of Artificial Intelligence for Research}\\
  \emph{Document specific to the research context: emphasises
  disclosure, traceability and scientific integrity. (2024 Academic
  guidelinese)}
\item
  \href{https://dl.acm.org/doi/pdf/10.1145/3442188.3445922}{On the
  Dangers of Stochastic Parrots: Can Language Models Be Too Big?}\\
  \emph{Critical analysis of the risks of bias, opacity and epistemic
  impact of large language models. (2021 Conference paper (FAccT))}
\item
  \href{https://www.oecd.org/en/topics/ai-principles.html}{OECD
  Principles on Artificial Intelligence}\\
  \emph{Policy principles for the responsible use of AI, also adopted by
  OECD member countries}
\end{itemize}

\chapter{Bias and source quality}\label{bias-and-source-quality}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Sources of bias in training
data}\label{sources-of-bias-in-training-data}

\paragraph{Strategies for the traceability and verifiability of
algorithmic
decisions}\label{strategies-for-the-traceability-and-verifiability-of-algorithmic-decisions}

\end{tcolorbox}

\section{1. Sources of bias in training
data}\label{sources-of-bias-in-training-data-1}

One of the most problematic aspects of using AI in research processes is
the \textbf{bias} inherent in training data.\\
The data of training of models are never neutral, but reflect
\emph{quantitative} and \emph{qualitative} imbalances that derive from
their very composition.

The prevalence of certain languages, geographical areas or disciplines
leads to an over-representation of specific contexts, while other
perspectives remain marginal or absent.

\hl{👉 The result is \textbf{partial knowledge}, which risks presenting
itself as universal despite being based on incomplete foundations.}

Alongside these quantitative imbalances, AI systems incorporate
\textbf{implicit cultural biases}.\\
The data reflect the \emph{values}, \emph{conventions} and
\emph{symbolic hierarchies} of the communities that generated them.\\
When these perspectives are assumed to be neutral, algorithms end up
replicating \emph{gender stereotypes, ethnocentric views} or
\emph{ideologically oriented representations}, masking them behind the
supposed objectivity of statistical calculation.

A further source of criticism lies in \textbf{methodological biases}.\\
The collection, selection and normalisation of data respond to criteria
that are not always made ``explicit'', but which directly influence the
outcomes of training.\\
Choices relating to \emph{sampling methods}, \emph{corpus cleaning} or
the definition of \emph{conceptual categories} determine an invisible
structure that guides the model's inferences.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ 👉 In this sense, bias is not an accidental residue, but rather a
\textbf{structural consequence} of the dataset construction process. }

\end{tcolorbox}

These different levels of distortion converge to generate a significant
\textbf{epistemic risk}, i.e.~the possibility that scientific research
is based on already compromised knowledge, without these limitations
being immediately recognisable.\\
The apparent authority of AI-generated texts can conceal systematic
imbalances, imposing on the Academic Community the need to develop
\textbf{critical monitoring tools}.

The issue of the \textbf{traceability} of algorithmic decisions
therefore takes on importance. Audit logs, fairness metrics and data
documentation practices are fundamental tools for making the path
leading to a given output recognisable and verifiable.

These mechanisms do not solve the structural problems of datasets, but
they introduce elements of \textbf{accountability} that allow
researchers to evaluate the consistency of results with criteria of
transparency and fairness.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ 👉 The distinction between verified knowledge and probabilistic
inference becomes an essential condition for preventing automation from
compromising the epistemic reliability of research. }

\end{tcolorbox}

Another critical element concerns the \textbf{nature of the content}
produced by generative systems, which may include \emph{non-existent
bibliographic references}, \emph{invented citations}, or \emph{distorted
summaries of articles} that have actually been published.\\
These phenomena, often referred to as algorithmic
\textbf{``hallucinations''}, directly undermine scientific credibility
if they are not promptly recognised and corrected.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-note-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ The responsibility therefore falls on the researcher, who is called
upon to \textbf{rigorously distinguish} between what belongs to the
domain of scientific validity and what remains a statistical projection
without empirical basis. }

\end{tcolorbox}

The problem of bias, therefore, cannot be reduced to a technical issue,
but also has \textbf{ethical} and \textbf{political implications}.\\
Research risks consolidating inequalities already present in society if
shared criteria of inclusivity and fairness are not developed in the
selection and management of data.\\
The GAI, from a potentially emancipatory resource, can become a device
of exclusion if left unchecked.

\hl{👉 For this reason, alongside individual critical vigilance, it is
essential to promote \textbf{institutional policies} and
\textbf{editorial guidelines} that guarantee the reliability of sources,
the transparency of datasets and respect for the principles of pluralism
and neutrality that underpin the scientific community.}

\subsection{Further Readings}\label{further-readings}

\begin{quote}
\emph{See} Types of bias in AI models
\href{https://www.modernpathology.org/article/S0893-3952(24)00266-7/fulltext}{Article
on bias in AI - (data/dev/interaction bias)}\\
\emph{See} Quantification of bias in pre-existing content
\href{https://viterbischool.usc.edu/news/2022/05/thats-just-common-sense-usc-researchers-find-bias-in-up-to-38-6-of-facts-used-by-ai/}{USC
analysis of ``common'' facts used by AI}\\
\emph{See} Bibliographic hallucinations
\href{https://doi.org/10.1038/s41598-023-41032-5}{Nature research on
citations invented by ChatGPT}\\
\emph{See} Frequency of hallucinations in scientific texts
\href{https://www.psypost.org/chatgpt-hallucinates-fake-but-plausible-scientific-citations-at-a-staggering-rate-study-finds/}{Study
on the rate of false citations in psychology}\\
\emph{See} Open-source tools for managing and measuring bias
\href{https://doi.org/10.48550/arXiv.1810.01943}{AI Fairness 360 Toolkit
(IBM)}\\
\emph{See} Generative image production analysis
\href{https://doi.org/10.48550/arXiv.2403.02726}{Bias in Generative
AI}\\
\emph{See} AI and SSH \href{https://doi.org/10.1073/pnas.2314021121}{Can
Generative AI improve social science?}\\
\emph{See} Bias embedded in training data
\href{https://dl.acm.org/doi/abs/10.1145/3442188.3445922}{On the Dangers
of Stochastic Parrots}
\end{quote}

\section{2. Strategies for the traceability and verifiability of
algorithmic
decisions}\label{strategies-for-the-traceability-and-verifiability-of-algorithmic-decisions-1}

One of the key issues in the use of AI systems in scientific research,
is the ability to guarantee the \textbf{reconstruction} and
\textbf{validation} of the decision-making processes that lead to a
given output.

Unlike human work, where the analysis and inference phases can be
explicitly justified and discussed, algorithms operate through chains of
calculations that are often \emph{opaque} and \emph{difficult to
interpret}, even for the developers themselves.

👉 \textbf{To reduce this lack of transparency, it is necessary to
introduce tools that allow the model's performance to be systematically
documented, monitored and evaluated.}

In this perspective, \textbf{audit logs} represent a first fundamental
mechanism.\\
They consist of udetailed records of the steps taken by the algorithm
during data processing, from the input phase to the generation of the
output, including any intermediate transformations.\\
These records not only allow the path followed by the system to be
\emph{traced retrospectively}, but also identify any critical issues,
such as the use of partial sources or the application of undeclared
selection criteria.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ 👉 In Academic context, this traceability has significant
\textbf{epistemic value}, because it allows not only the final results
to be subjected to intersubjective control, but also the entire process
that produced them. }

\end{tcolorbox}

Alongside process documentation, there is the issue of \textbf{verifying
the fairness of results}. Algorithms are not just calculation tools, but
devices that incorporate and convey specific hierarchies of relevance.\\
\textbf{Fairness metrics} have been developed precisely to make these
dynamics ``measurable'', translating dimensions often considered
qualitative, such as \emph{inclusion}, \emph{representativeness} or
\emph{non-discrimination}, into numerical parameters.\\
Through comparative indicators, for example, it is possible to verify
whether a model tends to favour certain categories of data or users over
others, and whether these imbalances are statistically significant.

\hl{👉 The joint application of audit logs and fairness metrics is not
limited to technical monitoring, but opens up the possibility of
developing shared responsibility in AI management.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ This means shifting the focus from isolated output to the
\textbf{production context}, where methodological choices and evaluation
criteria must be made explicit and subjected to collective discussion.\\
In this sense, the verifiability of algorithmic decisions becomes a
structural element of scientific governance, a device aimed not only at
ensuring greater transparency, but also at strengthening the epistemic
legitimacy of the results obtained. }

\end{tcolorbox}

Finally, it is important to emphasise that \textbf{traceability} and
\textbf{fairness assessment} cannot be understood as occasional or
ancillary practices, but must become an integral part of research
procedures.

\hl{The systematic adoption of these tools is a necessary condition for
preserving the reliability of scientific knowledge in the age of
automation, preventing the complexity of generative models from
translating into a deficit of critical control.}

\subsection{Further Readings}\label{further-readings-1}

\begin{quote}
\emph{See}
\href{https://www.acodis.io/blog/from-data-to-insight-why-traceability-is-crucial-for-ai-success}{From
Data to Insight: Why Traceability is Crucial for AI Success}\\
\emph{See}
\href{https://www.aptusdatalabs.com/thought-leadership/the-rise-of-ai-audit-trails-ensuring-traceability-in-decision-making?}{The
Rise of AI Audit Trails: Ensuring Traceability in Decision-Making}\\
\emph{See}
\href{https://data.world/blog/what-is-ai-traceability-benefits-tools-best-practices/}{What
is AI Traceability? Benefits, Tools \& Best Practices}
\end{quote}

\chapter{Accountability in peer review and
responsibility}\label{accountability-in-peer-review-and-responsibility}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Accountability in peer review and
responsibility}\label{accountability-in-peer-review-and-responsibility-1}

\paragraph{Risks of false positives/negatives and real
cases}\label{risks-of-false-positivesnegatives-and-real-cases}

\paragraph{Roles, conflicts of interest and self-audit
practices}\label{roles-conflicts-of-interest-and-self-audit-practices}

\paragraph{Documentation methods}\label{documentation-methods}

\end{tcolorbox}

\section{\texorpdfstring{1. Accountability in peer review and
responsibility (\emph{theoretical
framework})}{1. Accountability in peer review and responsibility (theoretical framework)}}\label{accountability-in-peer-review-and-responsibility-theoretical-framework}

The \textbf{peer review} process has always been one of the main
mechanisms for epistemic regulation in science, ensuring that Academic
contributions meet shared criteria of \emph{rigour}, \emph{transparency}
and \emph{reliability}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ Its function goes far beyond the mere evaluation of content: it
represents an exercise in collective responsibility involving reviewers,
scientific communities and publishing institutions. }

\end{tcolorbox}

Peer review is therefore an exercise in \textbf{responsibility}, both
individually, on the part of the reviewers called upon to evaluate a
contribution, and collectively, on the part of the Academic and
editorial communities that establish \emph{standards}, \emph{procedures}
and \emph{codes of conduct}.

The introduction of GAI in this context substantially changes the
\textbf{traditional framework}.\\
Entrusting algorithmic tools with tasks that support content evaluation
or selection, implies a redistribution of responsibility, which is no
longer exclusively entrusted to human expertise, but depends on a
technical infrastructure that lacks ethical autonomy but capable of
having a concrete impact on evaluation outcomes.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ \textsc{THIS RAISES A CRUCIAL QUESTION ABOUT WHO IS RESPONSIBLE FOR
DECISIONS THAT RESULT, DIRECTLY OR INDIRECTLY, FROM AN AI TOOL.} }

\end{tcolorbox}

The answer cannot be entrusted to the algorithm itself, but must fall on
the individuals and institutions that allow its use, defining
\emph{clear rules of use}, \emph{supervision protocols} and
\emph{operational limits}.

This reconfiguration of the evaluation process highlights the risk of a
\textbf{progressive dilution of responsibility}, with a consequent
compromise of the ``epistemic integrity'' of peer review.

To avoid this drift, \textbf{accountability} must be conceived not as a
mere attribution of individual blame, but as the construction of a
multi-level governance system.

\hl{👉 This implies that publishers, scientific committees, Universities
and funding bodies share responsibility for the choices made through
algorithmic tools, establishing binding editorial policies, codes of
ethics and institutional guidelines.}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ In this sense, peer review is transformed from an exclusively human
device into a hybrid system, in which the role of reviewers is not
replaced but redistributed, in a dynamic balance between human control
and technological support. }

\end{tcolorbox}

A further element concerns \textbf{transparency}.\\
The use of GAI in peer review must be explicitly stated in order to
ensure the \emph{``methodological traceability}'' of the process and to
protect the ``\emph{autonomy of scientific judgement}''.\\
Failure to explicitly state the use of generative intelligent systems
risks undermining the very legitimacy of editorial practices, fuelling
suspicions of \emph{opacity} and \emph{reducing the trust} of the
Academic Community and the public.\\
Some journals and scientific societies have already begun to
\textbf{define guidelines} that require the use of GAI to be made
explicit, placing the human reviewer as the ultimate guarantor of the
decision. Without human oversight, automation would result in a
structural weakening of scientific responsibility.

\subsection{Further Readings}\label{further-readings-2}

\begin{quote}
\emph{See} \href{https://doi.org/10.1111/puar.13293}{Accountable
Artificial Intelligence: Holding Algorithms to Account}\\
\emph{See}
\href{https://doi.org/10.1007/s00146-023-01635-y}{Accountability in
Artificial Intelligence: what it is and how it works}\\
\emph{See}
\href{https://doi.org/10.30574/gscarr.2024.18.3.0088}{Navigating and
reviewing ethical dilemmas in AI development: Strategies for
transparency, fairness, and accountability}\\
\emph{See}
\href{https://www.escienceediting.org/upload/pdf/kcse-352.pdf}{Ethical
guidelines for the use of generative artificial intelligence and
artificial intelligence-assisted tools in scholarly publishing: a
thematic analysis}\\
\emph{See} \href{https://doi.org/10.1007/s11948-015-9625-5}{Ensuring the
Quality, Fairness, and Integrity of Journal Peer Review: A Possible Role
of Editors}\\
\emph{See}
\href{https://dl.acm.org/doi/10.1145/3442188.3445937}{Accountability in
Computer Systems and Artificial Intelligence}\\
\emph{See} \href{https://doi.org/10.48550/arXiv.2001.00973}{Closing the
AI Accountability Gap: Defining an End-to-End Framework for Internal
Algorithmic Auditing}
\end{quote}

\section{\texorpdfstring{2. Risks of false positives/negatives and real
cases (\textbf{empirical
problematisation})}{2. Risks of false positives/negatives and real cases (empirical problematisation)}}\label{risks-of-false-positivesnegatives-and-real-cases-empirical-problematisation}

The use of GAI in peer review processes raises a critical issue related
to the \textbf{reliability of the assessments} produced.\\
Algorithms, as statistical systems trained on historical data, operate
on the basis of probabilistic correlations and not according to
\emph{epistemic criteria}.

This approach entails a \textbf{structural risk of classification
errors}, which can result in false positives and false negatives.

\begin{itemize}
\item
  A false positive occurs when an algorithm attributes scientific value
  to a contribution that lacks real substance, legitimising the
  dissemination of work that does not meet minimum quality criteria.\\
  👉 This introduces \emph{fallacious knowledge} into the scientific
  circuit which, once published, tends to take root and spread,
  compromising the credibility of the disciplines involved.
\item
  A false negative occurs when a valid and innovative article is
  unfairly penalised or excluded due to bias in the training data,
  overly standardised metrics or intrinsic limitations of the model.\\
  👉 These result in a \emph{loss of knowledge opportunities}, as they
  exclude contributions that could have fuelled theoretical or practical
  advances.
\end{itemize}

\hl{In both cases, the systemic result is a weakening of the regulatory
function of peer review and a deterioration of the trust that the
Academic Community and civil society place in the scientific system.\\
These are not mere technical incidents, as they have \textbf{substantial
consequences on an epistemological and institutional level.}}

The \textbf{reliability of the review} depends not only on the technical
sophistication of the algorithms, but also on the \emph{quality of the
training data}, the \emph{transparency of the metrics adopted}, and the
\emph{ability of institutions} to put in place critical oversight
mechanisms.

👉 An empirical approach is needed, that considers specific cases not as
\emph{isolated anomalies} but as indicators of systemic risk, in order
to enable the development of corrective mechanisms and safeguard the
epistemic integrity of the assessment process.

\subsection{Further Readings}\label{further-readings-3}

\begin{quote}
\emph{See} \href{https://doi.org/10.1007/s40979-023-00140-5}{Evaluating
the efficacy of AI content detection tools in differentiating between
human and AI-generated text}\\
\emph{See} \href{https://www.nature.com/articles/d41586-025-00894-7}{AI
is transforming peer review --- and many scientists are worried.}\\
\emph{See} \href{https://doi.org/10.1002/leap.1570}{Artificial
Intelligence to support publishing and peer review: A summary and
review}\\
\emph{See} \href{https://doi.org/10.1186/s13054-024-04933-z}{Generative
Artificial Intelligence is infiltrating peer review process}\\
\emph{See}
\href{https://synapse.koreamed.org/articles/1516090023}{Artificial
Intelligence in Peer Review: Enhancing Efficiency While Preserving
Integrity}
\end{quote}

\section{\texorpdfstring{3. Roles, conflicts of interest and self-audit
practices (\emph{ethical-institutional
issue})}{3. Roles, conflicts of interest and self-audit practices (ethical-institutional issue)}}\label{roles-conflicts-of-interest-and-self-audit-practices-ethical-institutional-issue}

Reflection on the integration of GAI into peer review processes raises
profound questions about the \textbf{roles, responsibilities} and
\textbf{conflicts of interest} that arise when evaluation is no longer
entrusted exclusively to human intervention.

Academic tradition has always assigned reviewers the task of ensuring,
through their scientific and methodological expertise, the quality and
soundness of the contributions submitted for evaluation.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-warning-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ The introduction of algorithmic systems alters this balance, as a
significant part of the decision-making process may depend on automated
procedures, which are free from subjectivity but not exempt from biases
implicit in the training data or operating models. }

\end{tcolorbox}

\hl{👉 In this scenario, there is a potential disconnect between the
\textbf{formal responsibility of the reviewer}, who continues to sign
the judgement, and the \textbf{substantive responsibility}, which is
partly transferred to the technological infrastructure.}

The risk of \textbf{conflict of interest} is amplified when auditors do
not disclose the use of AI tools or use them in an opaque manner,
without making the extent of their intervention transparent in relation
to the final judgement.\\
Failure to disclose not only weakens the reliability of the assessment,
but also raises questions of \textbf{legitimacy}, seeking to establish
to what extent an auditor can be considered the author of a judgement
when part of their argument derives from algorithmic processing.

\hl{👉Clear and shared rules need to be defined that establish the
limits of technology use and identify criteria for attributing
authorship and scientific responsibility.}

\textbf{Self-auditing}, understood as a practice of systematic
self-assessment, becomes important. This implies that reviewers
explicitly declare:\\
- \emph{how GAI is used}\\
- \emph{the selection criteria applied}\\
- \emph{the methodological limitations encountered}\\
- \emph{any critical issues encountered.}

This should not be reduced to a formal or bureaucratic requirement, but
rather represent a \textbf{practice of scientific reflection} capable of
highlighting, at an early stage, possible \emph{epistemic} or
\emph{ethical distortions} generated by the use of algorithmic tools.

\textbf{Self-monitoring} thus takes the form of \textbf{preventive
responsibility}, aimed not only at protecting the individual integrity
of the reviewer, but also at safeguarding the \emph{overall credibility
of the peer review process}.

The \textbf{institutional dimension} emerges strongly alongside the
individual one. Universities, Research institutions and Scientific
publishers have the task of setting up independent auditing mechanisms,
certification tools and binding guidelines to assist reviewers in the
management of AI.

\hl{👉 This \textbf{multi-level approach} allows ethical responsibility
to be distributed fairly, avoiding it falling exclusively on the
individual and instead building an ecosystem regulated by shared
standards.}

It thus becomes a collective governance mechanism:\\
- \emph{reviewers contribute with their own self-audits}\\
- \emph{institutions define regulatory and operational frameworks}\\
- \emph{the scientific community exercises widespread epistemic
control}.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ Only through this \textbf{multi-level architecture} is it possible to
reduce the risk of \emph{technological irresponsibility} and transform
the use of GAI into an opportunity to strengthen the quality and
reliability of scientific judgement.\\
Technological innovation does not become a threat to the integrity of
peer review, but an \emph{opportunity to consolidate its epistemic
function} and \emph{strengthen the link between individual
responsibility, institutional responsibility and collective
responsibility}. }

\end{tcolorbox}

\subsection{Further Readings}\label{further-readings-4}

\begin{quote}
\emph{See}
\href{https://synapse.koreamed.org/upload/synapsedata/pdfdata/0063jkms/jkms-33-e287.pdf}{Integrity
of Authorship and Peer Review Practices: Challenges and Opportunities
for Improvement}\\
\emph{See} \href{https://doi.org/10.1007/s43681-025-00775-9}{The risks
of Artificial Intelligence in research: ethical and methodological
challenges in the peer review process}\\
\emph{See} \href{https://doi.org/10.2147/NSS.S513872}{Peer Review in the
Artificial Intelligence Era: A Call for Developing Responsible
Integration Guidelines}
\end{quote}

\section{\texorpdfstring{4. Documentation methods (\emph{operational
methodological solutions: logs, notes,
metadata})}{4. Documentation methods (operational methodological solutions: logs, notes, metadata)}}\label{documentation-methods-operational-methodological-solutions-logs-notes-metadata}

\textbf{Documentation} is crucial to ensuring the accountability of peer
review in an AI-mediated context, since the legitimacy of the evaluation
process depends not only on the quality of the judgements made, but also
on the possibility of reconstructing and verifying the entire process
leading to those outcomes.

Review cannot therefore be reduced to a final output, but must be
accompanied by tools that ensure \textbf{traceability},
\textbf{transparency} and \textbf{methodological verifiability}.

The adoption of detailed \textbf{audit logs} becomes an indispensable
``safeguard'': they systematically record the interactions between
reviewers and algorithmic systems, including both the \emph{prompts} and
\emph{outputs} generated and the changes and interpretations
subsequently introduced by the human reviewer.

👉 This distinction makes it possible to clearly isolate the human
contribution from the algorithmic one, \emph{preventing opacity} and
\emph{reducing the risk of individual or institutional
irresponsibility}.

In addition to the logs, \textbf{methodological notes} are also
important, not merely as a formal disclosure tool, but as an epistemic
device that explains the degree and methods of AI involvement in the
evaluation, thus allowing the scientific community to measure the
robustness, reliability and limitations of the judgements produced.

Added to this is the value of \textbf{structured metadata}, which
associates contextual information with each algorithmic intervention,
such as:\\
- \emph{the model used}\\
- \emph{the parameters adopted}\\
- \emph{the software versions}\\
- \emph{the reference datasets}.

Structured metadata, if standardised and made accessible, not only
allows for the replicability of procedures, but also for the systematic
comparison of different reviews, constituting an additional quality
control tool.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ The set of \textbf{logs, notes} and \textbf{metadata} does not perform
a purely technical function, but takes on an epistemological and
institutional significance, anchoring peer review to a regime of
\emph{shared responsibility} and strengthening the Academic Community's
confidence in the \emph{legitimacy of evaluation procedures}. }

\end{tcolorbox}

\hl{👉 The development of common \textbf{traceability and verification}
protocols is therefore an essential condition for the sustainable
integration of AI into editorial processes, preventing it from becoming
a factor of \emph{opacity} or \emph{risk} and instead transforming it
into a resource capable of consolidating the regulatory function and
epistemic quality of peer review.}

\subsection{Further Readings}\label{further-readings-5}

\begin{quote}
\emph{See} \href{https://doi.org/10.1007/s10676-023-09725-7}{The
landscape of data and AI documentation approaches in the European policy
context}\\
\emph{See} \href{https://doi.org/10.1007/s00146-025-02320-y}{The
necessity of AI audit standards boards}
\end{quote}

\chapter{Towards a renewed operational
ethics}\label{towards-a-renewed-operational-ethics}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, rightrule=.15mm, colbacktitle=quarto-callout-note-color!10!white, arc=.35mm, opacitybacktitle=0.6, colframe=quarto-callout-note-color-frame, title={{Content}}, toptitle=1mm, breakable, colback=white, opacityback=0, coltitle=black, bottomtitle=1mm, titlerule=0mm, left=2mm, leftrule=.75mm, toprule=.15mm]

\paragraph{Tools and operational
practices}\label{tools-and-operational-practices}

\paragraph{Ethical verification table}\label{ethical-verification-table}

\end{tcolorbox}

The introduction of Artificial Intelligence systems into \emph{peer
review processes} requires the development of an \textbf{operational
ethics} capable of translating abstract principles into \emph{concrete
protocols, verifiable practices} and \emph{standardised procedures}.

Unlike traditional ``ethical frameworks'', which are predominantly
\emph{declarative} and \emph{prescriptive} in nature, often limited to
the enunciation of abstract values, \textbf{operational ethics} takes on
a ``\emph{performative function}'', as it binds the actors involved to
daily practices that give effect to the principles of
\emph{transparency, traceability} and \emph{accountability}.

This perspective allows us to recognise that ethics is not an external
or accessory constraint, but a ``constitutive prerequisite'' for the
epistemic and institutional legitimacy of peer review.

It is clear that the use of algorithmic tools in evaluation processes
introduces elements of \emph{opacity}, \emph{automation} and
\emph{potential disempowerment} which, if unregulated, risk compromising
the regulatory function of peer review.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ Only an ethical framework translated into concrete practices can
ensure that technological innovation does not undermine but rather
strengthens science's ability to subject its knowledge to
intersubjective scrutiny based on shared criteria. }

\end{tcolorbox}

Operational ethics is inherently \textbf{dynamic} and
\textbf{multi-layered}.\\
It is ``\emph{dynamic}'' because it requires \emph{continuous adaptation
to technological changes} in AI tools and to transformations in the
contexts in which they operate.\\
It is ``\emph{multi-layered}'' because it does not end with the
individual responsibility of reviewers, but \emph{extends to the
collective dimension of institutional governance}, which involves
publishers, research institutions and academic communities.

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ \textbf{Mandatory disclosure}, \textbf{supervisory mechanisms} and
\textbf{audit systems} are the first operational manifestations of this
requirement.\\
The aim is not only to prevent abuse or methodological opacity, but also
to promote a culture of shared responsibility, capable of maintaining
and strengthening collective trust in peer review as a fundamental
device for epistemic regulation. }

\end{tcolorbox}

\section{1. Tools and operational
practices}\label{tools-and-operational-practices-1}

In order to define the \textbf{framework} for a \emph{renewed
operational ethics}, there are certain elements that are particularly
important and deserve to be considered as methodological and applicative
pillars.

\begin{itemize}
\item
  \textbf{Mandatory disclosure procedures}: reviewers and publishers
  must clearly report the use of AI systems, specifying the stage of use
  and distinguishing between human and algorithmic contributions.
\item
  \textbf{Ethical compliance checklist}: before validating their
  judgement, reviewers must answer standardised questions that guide
  them in assessing bias, proportionality and responsibility.
\item
  \textbf{Regular training for reviewers}: editorial committees must
  establish ongoing training programmes to ensure understanding of the
  limitations of AI systems and critical supervision techniques.
\item
  \textbf{Editorial codes of conduct}: journals should include sections
  dedicated to the use of AI in their guidelines, defining limits,
  documentation requirements and accountability criteria.
\item
  \textbf{Institutional audit and control systems}: supervisory
  committees should randomly check decisions supported by AI to ensure
  reliability and effective correction.
\item
  \textbf{Multi-level documentation}: logs, methodological notes and
  metadata must be attached to reports to ensure the traceability of
  decisions and the replicability of processes.
\end{itemize}

\section{2. Ethical verification
table}\label{ethical-verification-table-1}

Tables (\emph{see example below}) can be used as an operational
self-audit tool for reviewers and publishing institutions, translating
\emph{ethical principles} into \emph{practical questions} and
\emph{mandatory actions}.

Each domain corresponds to a ``critical point in the evaluation
process'', from initial transparency to final institutional control.\\
👉 In this way, ethics does not remain an abstract reference, but
becomes an integral part of daily review practice, promoting a balance
between \emph{automation} and \emph{human responsibility.}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.1174}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.5223}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3603}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\textbf{Domain}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Verification Questions}
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\textbf{Required Actions}
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Transparency} & \emph{Has the use of AI been explicitly declared
in the review report?} & Include a methodological note distinguishing
human contribution from algorithmic input. \\
\textbf{Bias and Limitations} & \emph{Have potential biases in the data
or models used been considered?} & Document any critical issues and
specify their impact on the evaluation. \\
\textbf{Proportionality} & \emph{Has the intervention of AI been limited
to support tasks rather than replacing human judgment?} & Specify the
role of AI and ensure that the final decision remains with the
reviewer. \\
\textbf{Accountability} & \emph{Who assumes ultimate responsibility for
the judgment (reviewer, editor, committee)?} & Indicate in the report
the figure responsible for the final opinion. \\
\textbf{Documentation} & \emph{Have logs, methodological notes, and
metadata related to the use of AI been produced?} & Attach supporting
materials to ensure traceability and replicability. \\
\textbf{Training} & \emph{Does the reviewer possess the minimum
competencies required to understand the functioning and limitations of
the AI employed?} & Participate in training courses or consult editorial
guidelines. \\
\textbf{Institutional Oversight} & \emph{Is a random verification by the
editorial board foreseen?} & Include the review in a periodic compliance
audit. \\
\end{longtable}

\begin{tcolorbox}[enhanced jigsaw, bottomrule=.15mm, breakable, colback=white, arc=.35mm, leftrule=.75mm, opacityback=0, colframe=quarto-callout-important-color-frame, rightrule=.15mm, left=2mm, toprule=.15mm]

{ A \textbf{renewed operating ethics} should not be seen as an
``additional constraint'', but as a safeguard that allows AI systems to
be integrated into peer review in a sustainable manner.\\
}

\end{tcolorbox}

\hl{Only the combination of \textbf{disclosure practices},
\textbf{continuous training}, \textbf{institutional audits} and
multi-level documentation can transform AI from a potential risk into a
resource for consolidating scientific quality.}

\subsection{Further Readings}\label{further-readings-6}

\begin{quote}
\emph{See} \href{https://doi.org/10.1007/s43681-022-00200-5}{Ethics
Guidelines for Trustworthy}\\
\emph{See} \href{https://ieeexplore.ieee.org/document/9844014}{An
Overview of Artificial Intelligence Ethics}\\
\emph{See} \href{https://doi.org/10.1162/daed_a_01912}{Artificial
Intelligence, Humanistic Ethics}
\end{quote}

\bookmarksetup{startatroot}

\chapter*{References}\label{references-3}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-knuth84}
Knuth, Donald E. 1984. {``Literate Programming.''} \emph{Comput. J.} 27
(2): 97--111. \url{https://doi.org/10.1093/comjnl/27.2.97}.

\end{CSLReferences}




\end{document}
